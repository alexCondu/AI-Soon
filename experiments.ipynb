{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05b087b7-b9c0-4b50-ae38-8bac13bcdfeb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# **EXPERIMENTS**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8ac6ac-28a0-4704-9343-27c60e650bf9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "## **EXPERIMENT 2 OCR VS Visual Language Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93bacaa-54c3-430d-9d63-c6f6a326a7d9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "### TEST-1: Extraction with LLAVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4c0aca0-97cc-4983-9998-f85a62586a82",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5a6b122c-39c1-4581-8c1f-2d6f36a9f8a0_4.png:\n",
      "这是一段中文（汉语）的文本，我无法直接为您提供图像。不过，如果您能够提供一个描述或提供一下您想要了解的内容，我可以帮助您理解这段文本或者回答与中文相关的问题。\n",
      "\n",
      "fe245192-1f9c-4f28-9b32-046fb7ce7e1e_13.png:\n",
      "The text in the image is as follows:\n",
      "```\n",
      "1. 系统测试功能的介绍。\n",
      "2. 前往详细操作指南中的链接页面。\n",
      "3. 如果需要更多关于这个功能的信息，请访问官方网站或联系我们的客户服务部门。\n",
      "```\n",
      "\n",
      "9fe6b262-9944-417d-a0c4-9f2de1de2994_4.png:\n",
      "很抱歉，我不能提供文字的识别或翻译服务。请使用其他资源来获得所需的信息。\n",
      "\n",
      "12756724-394c-4576-b373-7c53f1abbd94_0.png:\n",
      "The Chinese text in the image is:\n",
      "\n",
      "赵玉华教授领导下，我国中医药研究的先进性和实用性得到了显著提升。感谢全国中医师同仁们一直以来对我这个工作的支持和关心，让我能在这里成为一名真正的中医研究人才。在未来，中医护理将继续深入发展，不断提高自身的技术水平和服务能力。\n",
      "\n",
      "1a20ded1-50fc-4153-9a95-e158eeb7199e.png:\n",
      "The image contains a screenshot of a mobile phone with a messaging app displaying a conversation. Here is the Chinese text extracted from the image:\n",
      "\n",
      "```\n",
      "你好呀？我想问你一下。是不是疲了？\n",
      "你懂我在说什么吗？\n",
      "```\n",
      "\n",
      "eda5b003-9250-4913-b724-74cca86240af_14.png:\n",
      "很抱歉，我无法提供文本提取服务。\n",
      "\n",
      "64bba692-d430-440c-9f1e-2575f45770af_1.png:\n",
      "I'm sorry, but I'm unable to provide any assistance with recognizing or transcribing characters or text from images. However, if you need information about Chinese characters or their meanings, feel free to ask me!\n",
      "\n",
      "912204cb-8ab7-48b8-9abf-d803f3804d08_7.png:\n",
      "很抱歉，由于我不能直接识别和提取文本图像中的信息，因为我只是一个基于语言模型的AI，而不是可以操作和分析图像的应用程序。但是，如果你能将这些屏幕的文字直接粘贴到这里，我将非常乐意为你提取和显示中文文本！\n",
      "\n",
      "12756724-394c-4576-b373-7c53f1abbd94_5.png:\n",
      "以下是图片中的文本：\n",
      "\n",
      "请注意，这只是提供所有可见的文字，而不包括任何可能存在于截屏的上下文或其他元素。如果你需要特定部分的内容，请告诉我。\n",
      "\n",
      "b8cea3b1-4dde-4438-9b1a-6faf690bbad0.png:\n",
      "今天是0日，@mikrotiik， @gmail·com?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "import requests\n",
    "import os\n",
    "\n",
    "# List of image file paths\n",
    "image_paths = [\n",
    "    \"0/png/5a6b122c-39c1-4581-8c1f-2d6f36a9f8a0_4.png\", \n",
    "    \"0/png/fe245192-1f9c-4f28-9b32-046fb7ce7e1e_13.png\", \n",
    "    \"0/png/9fe6b262-9944-417d-a0c4-9f2de1de2994_4.png\", \n",
    "    \"0/png/12756724-394c-4576-b373-7c53f1abbd94_0.png\", \n",
    "    \"0/png/1a20ded1-50fc-4153-9a95-e158eeb7199e.png\", \n",
    "    \"0/png/eda5b003-9250-4913-b724-74cca86240af_14.png\", \n",
    "    \"0/png/64bba692-d430-440c-9f1e-2575f45770af_1.png\", \n",
    "    \"0/png/912204cb-8ab7-48b8-9abf-d803f3804d08_7.png\", \n",
    "    \"0/png/12756724-394c-4576-b373-7c53f1abbd94_5.png\", \n",
    "    \"0/png/b8cea3b1-4dde-4438-9b1a-6faf690bbad0.png\"\n",
    "]\n",
    "\n",
    "# Define the prompt\n",
    "prompt = \"EXTRACT AND ONLY GIVE ME THE Chinese text in the given image. NO TRANSLATION, ONLY extract the TEXT IN CHINESE MANDARIN FROM THE PNG FILE\"\n",
    "\n",
    "# Process each image\n",
    "for image_path in image_paths:\n",
    "    with open(image_path, \"rb\") as f:\n",
    "        image_b64 = base64.b64encode(f.read()).decode(\"utf-8\")\n",
    "\n",
    "    response = requests.post(\n",
    "        \"http://localhost:11434/api/generate\",\n",
    "        json={\n",
    "            \"model\": \"llava:13b\",\n",
    "            \"prompt\": prompt,\n",
    "            \"images\": [image_b64],\n",
    "            \"stream\": False\n",
    "        },\n",
    "    )\n",
    "\n",
    "    filename = os.path.basename(image_path)\n",
    "    if response.ok:\n",
    "        output_text = response.json()[\"response\"]\n",
    "    else:\n",
    "        output_text = f\"Error: {response.text}\"\n",
    "\n",
    "    print(f\"{filename}:\\n{output_text.strip()}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619a9689-bcde-4ee7-9949-8372304b8b9e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## **EXPERIMENT 1 DATA TRANSLATION - 3 LLMs**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2292fd54-92d3-4a0e-a35a-d81511f24884",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### TEST-1: gemma3:27b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6be90f4c-0499-4a47-a91d-9ec715ba169a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Translating with Ollama:   7%|▋         | 22/329 [02:06<29:27,  5.76s/it] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[79]\u001b[39m\u001b[32m, line 53\u001b[39m\n\u001b[32m     51\u001b[39m     futures.append(executor.submit(translate_row, index))\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfuture\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mas_completed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mTranslating with Ollama\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m    \u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mfuture\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/IsoonAI/lib/python3.11/site-packages/tqdm/std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.11/concurrent/futures/_base.py:243\u001b[39m, in \u001b[36mas_completed\u001b[39m\u001b[34m(fs, timeout)\u001b[39m\n\u001b[32m    239\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m(\n\u001b[32m    240\u001b[39m                 \u001b[33m'\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m (of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m) futures unfinished\u001b[39m\u001b[33m'\u001b[39m % (\n\u001b[32m    241\u001b[39m                 \u001b[38;5;28mlen\u001b[39m(pending), total_futures))\n\u001b[32m--> \u001b[39m\u001b[32m243\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mevent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    245\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m waiter.lock:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.11/threading.py:629\u001b[39m, in \u001b[36mEvent.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    628\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[32m--> \u001b[39m\u001b[32m629\u001b[39m     signaled = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cond\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    630\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.11/threading.py:327\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    326\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m327\u001b[39m     \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    328\u001b[39m     gotit = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[79]\u001b[39m\u001b[32m, line 49\u001b[39m\n\u001b[32m     46\u001b[39m translations = [\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m] * \u001b[38;5;28mlen\u001b[39m(df)\n\u001b[32m     48\u001b[39m futures = []\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m \u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mThreadPoolExecutor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_workers\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m8\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mexecutor\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     51\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m.\u001b[49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexecutor\u001b[49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtranslate_row\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.11/concurrent/futures/_base.py:647\u001b[39m, in \u001b[36mExecutor.__exit__\u001b[39m\u001b[34m(self, exc_type, exc_val, exc_tb)\u001b[39m\n\u001b[32m    646\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, exc_type, exc_val, exc_tb):\n\u001b[32m--> \u001b[39m\u001b[32m647\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mshutdown\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    648\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.11/concurrent/futures/thread.py:235\u001b[39m, in \u001b[36mThreadPoolExecutor.shutdown\u001b[39m\u001b[34m(self, wait, cancel_futures)\u001b[39m\n\u001b[32m    233\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m wait:\n\u001b[32m    234\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._threads:\n\u001b[32m--> \u001b[39m\u001b[32m235\u001b[39m         \u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.11/threading.py:1119\u001b[39m, in \u001b[36mThread.join\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   1116\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mcannot join current thread\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1118\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1119\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_wait_for_tstate_lock\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1120\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1121\u001b[39m     \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[32m   1122\u001b[39m     \u001b[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[32m   1123\u001b[39m     \u001b[38;5;28mself\u001b[39m._wait_for_tstate_lock(timeout=\u001b[38;5;28mmax\u001b[39m(timeout, \u001b[32m0\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.11/threading.py:1139\u001b[39m, in \u001b[36mThread._wait_for_tstate_lock\u001b[39m\u001b[34m(self, block, timeout)\u001b[39m\n\u001b[32m   1136\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m   1138\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1139\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mlock\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m   1140\u001b[39m         lock.release()\n\u001b[32m   1141\u001b[39m         \u001b[38;5;28mself\u001b[39m._stop()\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ollama error: HTTPConnectionPool(host='localhost', port=11434): Read timed out. (read timeout=90)\n",
      "Ollama error: HTTPConnectionPool(host='localhost', port=11434): Read timed out. (read timeout=90)\n",
      "Ollama error: HTTPConnectionPool(host='localhost', port=11434): Read timed out. (read timeout=90)\n",
      "Ollama error: HTTPConnectionPool(host='localhost', port=11434): Read timed out. (read timeout=90)\n",
      "Ollama error: HTTPConnectionPool(host='localhost', port=11434): Read timed out. (read timeout=90)Ollama error: HTTPConnectionPool(host='localhost', port=11434): Read timed out. (read timeout=90)\n",
      "Ollama error: HTTPConnectionPool(host='localhost', port=11434): Read timed out. (read timeout=90)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "csv_path = 'csvs/10.csv'\n",
    "output_path = '3llms_10.csv'  # Output in project root directory\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "def get_context(df, index, window=5):\n",
    "    start = max(0, index - window)\n",
    "    end = min(len(df), index + window + 1)\n",
    "    return \"\\n\".join(df['Message'].iloc[start:end].dropna())\n",
    "\n",
    "def query_ollama(prompt, model=\"gemma3:27b\"):\n",
    "    url = \"http://localhost:11434/api/generate\"\n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"prompt\": prompt,\n",
    "        \"stream\": False\n",
    "    }\n",
    "    try:\n",
    "        response = requests.post(url, json=payload, timeout=90)\n",
    "        response.raise_for_status()\n",
    "        return response.json()[\"response\"].strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Ollama error: {e}\")\n",
    "        return \"[Translation Error]\"\n",
    "\n",
    "def translate_row(index):\n",
    "    target = df.at[index, 'Message']\n",
    "    if pd.isna(target):\n",
    "        return index, \"\"\n",
    "    context = get_context(df, index)\n",
    "    prompt = (\n",
    "        \"You are translating Chinese messages to English. Below is a series of related messages. \"\n",
    "        \"Use the full context to understand the meaning, but only translate the specific message provided.\\n\\n\"\n",
    "        f\"Context:\\n{context}\\n\\n\"\n",
    "        f\"Message to translate:\\n{target}\\n\\n\"\n",
    "        \"ONLY RETURN the English translation of the message, ANYTHING ELSE IS FORBIDDEN! \"\n",
    "        \"If you encounter a filename or file reference, preserve it exactly as it appears, DON'T add anything!\"\n",
    "    )\n",
    "    translation = query_ollama(prompt)\n",
    "    return index, translation\n",
    "\n",
    "translations = [\"\"] * len(df)\n",
    "\n",
    "futures = []\n",
    "with ThreadPoolExecutor(max_workers=8) as executor:\n",
    "    for index in df.index:\n",
    "        futures.append(executor.submit(translate_row, index))\n",
    "\n",
    "    for future in tqdm(as_completed(futures), total=len(futures), desc=\"Translating with Ollama\"):\n",
    "        idx, result = future.result()\n",
    "        translations[idx] = result\n",
    "\n",
    "translated_df = pd.DataFrame({'gemma3:27b': translations})\n",
    "translated_df.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fcb029-b45f-4604-94c2-677bfa740ef7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "### TEST-2: 7shi/llama-translate:8b-q4_K_M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6bf90173-e773-4d2e-82b2-b1bd0d5e787b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Translating with 7shi/llama-translate:8b-q4_K_M: 100%|██████████| 149/149 [08:52<00:00,  3.57s/it]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "source_csv_path = 'csvs/10.csv'\n",
    "existing_translation_path = '3llms_10.csv'\n",
    "new_model_name = '7shi/llama-translate:8b-q4_K_M'\n",
    "\n",
    "# Load original messages and previously translated file\n",
    "source_df = pd.read_csv(source_csv_path)\n",
    "translated_df = pd.read_csv(existing_translation_path)\n",
    "\n",
    "def get_context(df, index, window=5):\n",
    "    start = max(0, index - window)\n",
    "    end = min(len(df), index + window + 1)\n",
    "    return \"\\n\".join(df['Message'].iloc[start:end].dropna())\n",
    "\n",
    "def query_ollama(prompt, model):\n",
    "    url = \"http://localhost:11434/api/generate\"\n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"prompt\": prompt,\n",
    "        \"stream\": False\n",
    "    }\n",
    "    try:\n",
    "        response = requests.post(url, json=payload, timeout=90)\n",
    "        response.raise_for_status()\n",
    "        return response.json()[\"response\"].strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Ollama error: {e}\")\n",
    "        return \"[Translation Error]\"\n",
    "\n",
    "def translate_row(index):\n",
    "    target = source_df.at[index, 'Message']\n",
    "    if pd.isna(target):\n",
    "        return index, \"\"\n",
    "    context = get_context(source_df, index)\n",
    "    prompt = (\n",
    "        \"Transalte Mandarin to English. Below is a series of related messages. \"\n",
    "        f\"Context:\\n{context}\\n\\n\"\n",
    "        f\"Message to translate:\\n{target}\\n\\n\"\n",
    "    )\n",
    "    translation = query_ollama(prompt, model=new_model_name)\n",
    "    return index, translation\n",
    "\n",
    "# Prepare for parallel processing\n",
    "translations = [\"\"] * len(source_df)\n",
    "futures = []\n",
    "with ThreadPoolExecutor(max_workers=8) as executor:\n",
    "    for index in source_df.index:\n",
    "        futures.append(executor.submit(translate_row, index))\n",
    "\n",
    "    for future in tqdm(as_completed(futures), total=len(futures), desc=f\"Translating with {new_model_name}\"):\n",
    "        idx, result = future.result()\n",
    "        translations[idx] = result\n",
    "\n",
    "translated_df[new_model_name] = translations\n",
    "translated_df.to_csv(existing_translation_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a05ca25-c7b7-48e3-8dd3-e0cc11cd05e4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### TEST-3: yi:34b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77dbb281-778c-45f5-ad91-01309c1b33b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Translating with yi:34b: 100%|██████████| 149/149 [07:20<00:00,  2.96s/it]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# File paths\n",
    "source_csv_path = 'csvs/10.csv'\n",
    "existing_translation_path = '3llms_10.csv'\n",
    "new_model_name = 'yi:34b'\n",
    "\n",
    "# Load original source messages and existing translations\n",
    "source_df = pd.read_csv(source_csv_path)\n",
    "translated_df = pd.read_csv(existing_translation_path)\n",
    "\n",
    "# Context window function\n",
    "def get_context(df, index, window=5):\n",
    "    start = max(0, index - window)\n",
    "    end = min(len(df), index + window + 1)\n",
    "    return \"\\n\".join(df['Message'].iloc[start:end].dropna())\n",
    "\n",
    "def query_ollama(prompt, model):\n",
    "    url = \"http://localhost:11434/api/generate\"\n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"prompt\": prompt,\n",
    "        \"stream\": False\n",
    "    }\n",
    "    try:\n",
    "        response = requests.post(url, json=payload, timeout=90)\n",
    "        response.raise_for_status()\n",
    "        return response.json()[\"response\"].strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Ollama error: {e}\")\n",
    "        return \"[Translation Error]\"\n",
    "\n",
    "# Translate a single row\n",
    "def translate_row(index):\n",
    "    target = source_df.at[index, 'Message']\n",
    "    if pd.isna(target):\n",
    "        return index, \"\"\n",
    "    context = get_context(source_df, index)\n",
    "    prompt = (\n",
    "        \"You are translating Chinese messages to English. Below is a series of related messages. \"\n",
    "        \"Use the full context to understand the meaning, but only translate the specific message provided.\\n\\n\"\n",
    "        f\"Context:\\n{context}\\n\\n\"\n",
    "        f\"Message to translate:\\n{target}\\n\\n\"\n",
    "        \"ONLY RETURN the English translation of the message, ANYTHING ELSE IS FORBIDDEN! \"\n",
    "        \"If you encounter a filename or file reference, preserve it exactly as it appears, DON'T add anything!\"\n",
    "    )\n",
    "    translation = query_ollama(prompt, model=new_model_name)\n",
    "    return index, translation\n",
    "\n",
    "# Run translations in parallel\n",
    "translations = [\"\"] * len(source_df)\n",
    "futures = []\n",
    "with ThreadPoolExecutor(max_workers=8) as executor:\n",
    "    for index in source_df.index:\n",
    "        futures.append(executor.submit(translate_row, index))\n",
    "\n",
    "    for future in tqdm(as_completed(futures), total=len(futures), desc=f\"Translating with {new_model_name}\"):\n",
    "        idx, result = future.result()\n",
    "        translations[idx] = result\n",
    "\n",
    "translated_df[new_model_name] = translations\n",
    "translated_df.to_csv(existing_translation_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13221ced-4314-4437-b0ef-ebae8c59d48d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Levenshtein Distance Between the 3 Translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ccfdd604-2ca9-4caa-be1b-538461f463b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import Levenshtein\n",
    "from itertools import combinations\n",
    "\n",
    "csv_path = '3llms_10.csv'\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Identify all translation columns \n",
    "translation_columns = [col for col in df.columns if not col.startswith('Levenshtein')]\n",
    "\n",
    "# Compute Levenshtein distance for all possible combinations\n",
    "for col1, col2 in combinations(translation_columns, 2):\n",
    "    new_col_name = f\"Levenshtein ({col1} vs {col2})\"\n",
    "    df[new_col_name] = [\n",
    "        Levenshtein.distance(str(a), str(b)) if pd.notna(a) and pd.notna(b) else None\n",
    "        for a, b in zip(df[col1], df[col2])\n",
    "    ]\n",
    "\n",
    "# Save updated DataFrame back to the same CSV\n",
    "df.to_csv(csv_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403fbdea-49cb-409c-956e-9d993213eb47",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# TEST IMG CLASSIFICATION for all file types - 100% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6585046-2add-4e4d-9e3c-bea595e89d41",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying Images: 100%|██████████| 14/14 [03:38<00:00, 15.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12756724-394c-4576-b373-7c53f1abbd94_39.png:\n",
      "3\n",
      "\n",
      "3348953d-66e9-4cac-8675-65bb5f2ef929_4_0.png:\n",
      "1\n",
      "\n",
      "12756724-394c-4576-b373-7c53f1abbd94_47.png:\n",
      "3\n",
      "\n",
      "3348953d-66e9-4cac-8675-65bb5f2ef929_5_0.png:\n",
      "1\n",
      "\n",
      "3348953d-66e9-4cac-8675-65bb5f2ef929_3_0.png:\n",
      "1\n",
      "\n",
      "3348953d-66e9-4cac-8675-65bb5f2ef929_2_0.png:\n",
      "1\n",
      "\n",
      "3348953d-66e9-4cac-8675-65bb5f2ef929_2_1.png:\n",
      "1\n",
      "\n",
      "3348953d-66e9-4cac-8675-65bb5f2ef929_1_0.png:\n",
      "1\n",
      "\n",
      "12756724-394c-4576-b373-7c53f1abbd94_9.png:\n",
      "3\n",
      "\n",
      "12756724-394c-4576-b373-7c53f1abbd94_49.png:\n",
      "3\n",
      "\n",
      "585875ff-f8c5-4a02-acd7-fef37dc9ff11_5.png:\n",
      "3\n",
      "\n",
      "645dfc97-3268-4e1d-920d-4138545456fa.png:\n",
      "4\n",
      "\n",
      "6e9aced1-df28-4e57-b7c8-641609ff4450.png:\n",
      "4\n",
      "\n",
      "6d7fc7b3-c892-4cb5-bd4b-a5713c089d88_0.png:\n",
      "2\n",
      "\n",
      "Completed in 218.12 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "import requests\n",
    "import os\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "\n",
    "# List of image file paths\n",
    "image_paths = [\n",
    "    # Financial Info Here (Employee Salary)\n",
    "    \"0/png/3348953d-66e9-4cac-8675-65bb5f2ef929_1_0.png\",\n",
    "    \"0/png/3348953d-66e9-4cac-8675-65bb5f2ef929_2_0.png\",\n",
    "    \"0/png/3348953d-66e9-4cac-8675-65bb5f2ef929_2_1.png\",\n",
    "    \"0/png/3348953d-66e9-4cac-8675-65bb5f2ef929_3_0.png\",\n",
    "    \"0/png/3348953d-66e9-4cac-8675-65bb5f2ef929_4_0.png\",\n",
    "    \"0/png/3348953d-66e9-4cac-8675-65bb5f2ef929_5_0.png\",\n",
    "\n",
    "    # Product Documentation\n",
    "    \"0/png/12756724-394c-4576-b373-7c53f1abbd94_39.png\",\n",
    "    \"0/png/12756724-394c-4576-b373-7c53f1abbd94_47.png\",\n",
    "    \"0/png/12756724-394c-4576-b373-7c53f1abbd94_9.png\",\n",
    "    \"0/png/12756724-394c-4576-b373-7c53f1abbd94_49.png\",\n",
    "    \"0/png/585875ff-f8c5-4a02-acd7-fef37dc9ff11_5.png\",\n",
    "\n",
    "    # Chats\n",
    "    \"0/png/645dfc97-3268-4e1d-920d-4138545456fa.png\",\n",
    "    \"0/png/6e9aced1-df28-4e57-b7c8-641609ff4450.png\",\n",
    "\n",
    "    # Employee Information\n",
    "    \"0/png/6d7fc7b3-c892-4cb5-bd4b-a5713c089d88_0.png\"\n",
    "]\n",
    "\n",
    "# Define the prompt\n",
    "prompt = \"\"\"You are a cybersecurity expert analyzing various images. You are tasked to classify the images into one of the following categories. Look for titles or any clues that can help with classification:\n",
    "1. Financial Information (if it contains salaries, bonuses, or any other related terms)\n",
    "2. Employee Information (if it contains date of birth, full name, or any other personal information)\n",
    "3. Product Documentation (if it has images of platforms, and presents any documentation related aspects)\n",
    "4. Chats (regular conversations or just message(s))\n",
    "\n",
    "This is aimed at a 0-shot classification. Assign ONLY ONE CATEGORY TO THE FILE. I DONT NEED ANY REASONING, ONLY output the number afferent to the category.\n",
    "\"\"\"\n",
    "\n",
    "# Function to classify a single image\n",
    "def classify_image(image_path):\n",
    "    try:\n",
    "        with open(image_path, \"rb\") as f:\n",
    "            image_b64 = base64.b64encode(f.read()).decode(\"utf-8\")\n",
    "\n",
    "        response = requests.post(\n",
    "            \"http://localhost:11434/api/generate\",\n",
    "            json={\n",
    "                \"model\": \"qwen2.5vl:32b\",\n",
    "                \"prompt\": prompt,\n",
    "                \"images\": [image_b64],\n",
    "                \"stream\": False\n",
    "            },\n",
    "            timeout=1000\n",
    "        )\n",
    "\n",
    "        filename = os.path.basename(image_path)\n",
    "        if response.ok:\n",
    "            output_text = response.json()[\"response\"].strip()\n",
    "        else:\n",
    "            output_text = f\"Error: {response.text}\"\n",
    "\n",
    "        return filename, output_text\n",
    "\n",
    "    except Exception as e:\n",
    "        return os.path.basename(image_path), f\"Exception: {e}\"\n",
    "\n",
    "# Track execution time\n",
    "start_time = time.time()\n",
    "\n",
    "# Run classification in parallel with progress bar\n",
    "results = []\n",
    "with ThreadPoolExecutor(max_workers=8) as executor:\n",
    "    futures = {executor.submit(classify_image, path): path for path in image_paths}\n",
    "    for future in tqdm(as_completed(futures), total=len(futures), desc=\"Classifying Images\"):\n",
    "        filename, result = future.result()\n",
    "        results.append((filename, result))\n",
    "\n",
    "# Output results\n",
    "for filename, result in results:\n",
    "    print(f\"{filename}:\\n{result}\\n\")\n",
    "\n",
    "# Print total time taken\n",
    "total_time = time.time() - start_time\n",
    "print(f\"Completed in {total_time:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50a476ef-5bb2-4939-b601-625e5ca01413",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying Images:   7%|▋         | 1/14 [00:16<03:35, 16.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3348953d-66e9-4cac-8675-65bb5f2ef929_1_0.png:\n",
      "2\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying Images:  14%|█▍        | 2/14 [00:33<03:18, 16.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3348953d-66e9-4cac-8675-65bb5f2ef929_2_0.png:\n",
      "2\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying Images:  21%|██▏       | 3/14 [00:50<03:04, 16.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3348953d-66e9-4cac-8675-65bb5f2ef929_2_1.png:\n",
      "1. Financial Information\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying Images:  29%|██▊       | 4/14 [01:06<02:46, 16.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3348953d-66e9-4cac-8675-65bb5f2ef929_3_0.png:\n",
      "1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying Images:  36%|███▌      | 5/14 [01:23<02:29, 16.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3348953d-66e9-4cac-8675-65bb5f2ef929_4_0.png:\n",
      "2\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying Images:  43%|████▎     | 6/14 [01:39<02:12, 16.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3348953d-66e9-4cac-8675-65bb5f2ef929_5_0.png:\n",
      "2\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying Images:  50%|█████     | 7/14 [01:55<01:55, 16.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12756724-394c-4576-b373-7c53f1abbd94_39.png:\n",
      "3\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying Images:  57%|█████▋    | 8/14 [02:12<01:38, 16.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12756724-394c-4576-b373-7c53f1abbd94_47.png:\n",
      "3\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying Images:  64%|██████▍   | 9/14 [02:28<01:22, 16.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12756724-394c-4576-b373-7c53f1abbd94_9.png:\n",
      "3\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying Images:  71%|███████▏  | 10/14 [02:45<01:05, 16.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12756724-394c-4576-b373-7c53f1abbd94_49.png:\n",
      "3\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying Images:  79%|███████▊  | 11/14 [03:01<00:49, 16.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "585875ff-f8c5-4a02-acd7-fef37dc9ff11_5.png:\n",
      "3\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying Images:  86%|████████▌ | 12/14 [03:09<00:27, 13.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "645dfc97-3268-4e1d-920d-4138545456fa.png:\n",
      "4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying Images:  93%|█████████▎| 13/14 [03:09<00:09,  9.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6e9aced1-df28-4e57-b7c8-641609ff4450.png:\n",
      "4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying Images: 100%|██████████| 14/14 [03:26<00:00, 14.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6d7fc7b3-c892-4cb5-bd4b-a5713c089d88_0.png:\n",
      "2\n",
      "\n",
      "Completed in 206.39 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "import requests\n",
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# List of image file paths\n",
    "image_paths = [\n",
    "    # Financial Info Here (Employee Salary)\n",
    "    \"0/png/3348953d-66e9-4cac-8675-65bb5f2ef929_1_0.png\",\n",
    "    \"0/png/3348953d-66e9-4cac-8675-65bb5f2ef929_2_0.png\",\n",
    "    \"0/png/3348953d-66e9-4cac-8675-65bb5f2ef929_2_1.png\",\n",
    "    \"0/png/3348953d-66e9-4cac-8675-65bb5f2ef929_3_0.png\",\n",
    "    \"0/png/3348953d-66e9-4cac-8675-65bb5f2ef929_4_0.png\",\n",
    "    \"0/png/3348953d-66e9-4cac-8675-65bb5f2ef929_5_0.png\",\n",
    "\n",
    "    # Product Documentation\n",
    "    \"0/png/12756724-394c-4576-b373-7c53f1abbd94_39.png\",\n",
    "    \"0/png/12756724-394c-4576-b373-7c53f1abbd94_47.png\",\n",
    "    \"0/png/12756724-394c-4576-b373-7c53f1abbd94_9.png\",\n",
    "    \"0/png/12756724-394c-4576-b373-7c53f1abbd94_49.png\",\n",
    "    \"0/png/585875ff-f8c5-4a02-acd7-fef37dc9ff11_5.png\",\n",
    "\n",
    "    # Chats\n",
    "    \"0/png/645dfc97-3268-4e1d-920d-4138545456fa.png\",\n",
    "    \"0/png/6e9aced1-df28-4e57-b7c8-641609ff4450.png\",\n",
    "\n",
    "    # Employee Information\n",
    "    \"0/png/6d7fc7b3-c892-4cb5-bd4b-a5713c089d88_0.png\"\n",
    "]\n",
    "\n",
    "# Define the prompt\n",
    "prompt = \"\"\"You are a cybersecurity expert analyzing various images. You are tasked to classify the images into one of the following categories. Look for titles or any clues that can help with classification:\n",
    "1. Financial Information (if it contains salaries, bonuses, or any other related terms)\n",
    "2. Employee Information (if it contains date of birth, full name, or any other personal information)\n",
    "3. Product Documentation (if it has images of platforms, and presents any documentation related aspects)\n",
    "4. Chats (regular conversations or just message(s))\n",
    "\"\"\"\n",
    "\n",
    "# Start timer\n",
    "start_time = time.time()\n",
    "\n",
    "# Process each image with progress bar\n",
    "for image_path in tqdm(image_paths, desc=\"Classifying Images\"):\n",
    "    try:\n",
    "        with open(image_path, \"rb\") as f:\n",
    "            image_b64 = base64.b64encode(f.read()).decode(\"utf-8\")\n",
    "\n",
    "        response = requests.post(\n",
    "            \"http://localhost:11434/api/generate\",\n",
    "            json={\n",
    "                \"model\": \"qwen2.5vl:32b\",\n",
    "                \"prompt\": prompt,\n",
    "                \"images\": [image_b64],\n",
    "                \"stream\": False\n",
    "            },\n",
    "            timeout=90\n",
    "        )\n",
    "\n",
    "        filename = os.path.basename(image_path)\n",
    "        if response.ok:\n",
    "            output_text = response.json()[\"response\"]\n",
    "        else:\n",
    "            output_text = f\"Error: {response.text}\"\n",
    "\n",
    "    except Exception as e:\n",
    "        filename = os.path.basename(image_path)\n",
    "        output_text = f\"Exception: {e}\"\n",
    "\n",
    "    print(f\"{filename}:\\n{output_text.strip()}\\n\")\n",
    "\n",
    "# End timer\n",
    "end_time = time.time()\n",
    "print(f\"Completed in {end_time - start_time:.2f} seconds.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (IsoonAI)",
   "language": "python",
   "name": "isoonai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

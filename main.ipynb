{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08427a84-31f9-4bcf-875e-22b2e6497608",
   "metadata": {
    "user_expressions": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/IsoonAI/bin/python\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "879be4cb",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel is working\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import subprocess\n",
    "import json\n",
    "import pandas as pd\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "import shutil\n",
    "\n",
    "\n",
    "# Paths and model settings\\ nZIP_PATH = 'I-Soon-data.zip'      # Path to your downloaded zip file\n",
    "ZIP_PATH = '0.zip'    # Directory to extract contents\n",
    "EXTRACT_DIR = 'I-Soon-data'        # Directory to extract contents\n",
    "print(\"kernel is working\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e6feb79",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "ename": "BadZipFile",
     "evalue": "File is not a zip file",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mBadZipFile\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.isdir(EXTRACT_DIR):\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mzipfile\u001b[49m\u001b[43m.\u001b[49m\u001b[43mZipFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mZIP_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m zip_ref:\n\u001b[32m      3\u001b[39m         zip_ref.extractall(EXTRACT_DIR)\n\u001b[32m      4\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExtracted archive to \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mEXTRACT_DIR\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.11/zipfile.py:1304\u001b[39m, in \u001b[36mZipFile.__init__\u001b[39m\u001b[34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps, metadata_encoding)\u001b[39m\n\u001b[32m   1302\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1303\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m mode == \u001b[33m'\u001b[39m\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1304\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_RealGetContents\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1305\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[33m'\u001b[39m\u001b[33mw\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mx\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m   1306\u001b[39m         \u001b[38;5;66;03m# set the modified flag so central directory gets written\u001b[39;00m\n\u001b[32m   1307\u001b[39m         \u001b[38;5;66;03m# even if no files are added to the archive\u001b[39;00m\n\u001b[32m   1308\u001b[39m         \u001b[38;5;28mself\u001b[39m._didModify = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.11/zipfile.py:1371\u001b[39m, in \u001b[36mZipFile._RealGetContents\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1369\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m BadZipFile(\u001b[33m\"\u001b[39m\u001b[33mFile is not a zip file\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1370\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m endrec:\n\u001b[32m-> \u001b[39m\u001b[32m1371\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m BadZipFile(\u001b[33m\"\u001b[39m\u001b[33mFile is not a zip file\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1372\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.debug > \u001b[32m1\u001b[39m:\n\u001b[32m   1373\u001b[39m     \u001b[38;5;28mprint\u001b[39m(endrec)\n",
      "\u001b[31mBadZipFile\u001b[39m: File is not a zip file"
     ]
    }
   ],
   "source": [
    "if not os.path.isdir(EXTRACT_DIR):\n",
    "    with zipfile.ZipFile(ZIP_PATH, 'r') as zip_ref:\n",
    "        zip_ref.extractall(EXTRACT_DIR)\n",
    "    print(f\"Extracted archive to '{EXTRACT_DIR}'\")\n",
    "else:\n",
    "    print(f\"Extraction directory '{EXTRACT_DIR}' already exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325a01d8",
   "metadata": {},
   "source": [
    "# **DATA TYPE CATEGORIZATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec65000",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Define the parent directory\n",
    "parent_directory = \"I-Soon-data\"\n",
    "\n",
    "# Full path to the __MACOSX folder\n",
    "macosx_folder = os.path.join(parent_directory, \"__MACOSX\")\n",
    "\n",
    "# Check if __MACOSX exists and remove it\n",
    "if os.path.exists(macosx_folder) and os.path.isdir(macosx_folder):\n",
    "    shutil.rmtree(macosx_folder)\n",
    "    print(f\"Deleted: {macosx_folder}\")\n",
    "else:\n",
    "    print(f\"Folder not found: {macosx_folder}\")\n",
    "\n",
    "# Organize files by extension into subfolders\n",
    "for root, dirs, files in os.walk(parent_directory):\n",
    "    for file in files:\n",
    "        # Skip hidden files and __MACOSX if any reappear\n",
    "        if file.startswith('.') or '__MACOSX' in root:\n",
    "            continue\n",
    "\n",
    "        # Get the file extension (in lowercase, without the dot)\n",
    "        file_extension = os.path.splitext(file)[1].lower().lstrip('.')\n",
    "        if not file_extension:\n",
    "            file_extension = \"no_extension\"\n",
    "\n",
    "        # Define the new subfolder path\n",
    "        subfolder_path = os.path.join(parent_directory, file_extension)\n",
    "\n",
    "        # Create the subfolder if it doesn't exist\n",
    "        os.makedirs(subfolder_path, exist_ok=True)\n",
    "\n",
    "        # Define source and destination paths\n",
    "        source_path = os.path.join(root, file)\n",
    "        destination_path = os.path.join(subfolder_path, file)\n",
    "\n",
    "        # Move the file if source and destination are not the same\n",
    "        if os.path.abspath(source_path) != os.path.abspath(destination_path):\n",
    "            shutil.move(source_path, destination_path)\n",
    "\n",
    "# Remove any empty folders within the parent directory\n",
    "for dirpath, dirnames, filenames in os.walk(parent_directory, topdown=False):\n",
    "    if not dirnames and not filenames:\n",
    "        try:\n",
    "            os.rmdir(dirpath)\n",
    "            print(f\"Removed empty folder: {dirpath}\")\n",
    "        except OSError:\n",
    "            pass  # Ignore errors (e.g., if directory is not empty due to permissions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75417f54",
   "metadata": {},
   "source": [
    "# **Markdown File Classification Using Local LLM (Ollama + LangChain)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9397264",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "import concurrent.futures\n",
    "from langchain.llms import Ollama\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === Step 1: Set up LLM and Prompt ===\n",
    "\n",
    "llm = Ollama(model=\"llama3.1:8b\")\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"content\"],\n",
    "    template=\"\"\"\n",
    "You are analyzing the content of a Markdown (.md) file.\n",
    "\n",
    "Markdown content:\n",
    "\\\"\\\"\\\"\n",
    "{content}\n",
    "\\\"\\\"\\\"\n",
    "\n",
    "1. Classify the content into one of the following categories ONLY: chats, images, other.\n",
    "2. State your confidence in the classification as one of: high, medium, or low.\n",
    "\n",
    "Respond in the following format:\n",
    "Category: <chats|images|other>\n",
    "Confidence: <high|medium|low>\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "\n",
    "# === Step 2: Preprocessing Function ===\n",
    "\n",
    "def preprocess_first_20_lines(file_path):\n",
    "    try:\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            lines = [line.strip() for _, line in zip(range(20), f)]\n",
    "            content = \" \".join(lines)\n",
    "        return os.path.basename(file_path), content\n",
    "    except Exception:\n",
    "        return os.path.basename(file_path), \"\"\n",
    "\n",
    "# === Step 3: Load .md Files ===\n",
    "\n",
    "md_dir = \"I-Soon-data/md\"\n",
    "md_files = glob.glob(os.path.join(md_dir, \"*.md\"))\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    file_data = list(executor.map(preprocess_first_20_lines, md_files))\n",
    "\n",
    "# === Step 4: Classify Each File and Move ===\n",
    "\n",
    "valid_categories = {\"chats\", \"images\", \"other\"}\n",
    "results_log = []\n",
    "\n",
    "for file_name, content in tqdm(file_data, desc=\"Classifying files\"):\n",
    "    if not content:\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        response = chain.run(content=content).strip().lower()\n",
    "        lines = response.splitlines()\n",
    "\n",
    "        category = next((line.replace(\"category:\", \"\").strip() for line in lines if line.startswith(\"category:\")), \"\")\n",
    "        confidence = next((line.replace(\"confidence:\", \"\").strip() for line in lines if line.startswith(\"confidence:\")), \"\")\n",
    "\n",
    "        if category not in valid_categories:\n",
    "            category = \"other\"\n",
    "\n",
    "        # Destination folder *within* the md_dir\n",
    "        category_path = os.path.join(md_dir, category)\n",
    "        os.makedirs(category_path, exist_ok=True)\n",
    "\n",
    "        # Move file into category folder\n",
    "        src_path = os.path.join(md_dir, file_name)\n",
    "        dst_path = os.path.join(category_path, file_name)\n",
    "\n",
    "        if os.path.exists(src_path):\n",
    "            shutil.move(src_path, dst_path)\n",
    "\n",
    "        results_log.append({\n",
    "            \"file\": file_name,\n",
    "            \"category\": category,\n",
    "            \"confidence\": confidence\n",
    "        })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process {file_name}: {e}\")\n",
    "\n",
    "# === Optional: Save results to file ===\n",
    "\n",
    "# import json\n",
    "# with open(\"classification_results.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "#     json.dump(results_log, f, indent=2)\n",
    "\n",
    "# import csv\n",
    "# with open(\"classification_results.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "#     writer = csv.DictWriter(f, fieldnames=[\"file\", \"category\", \"confidence\"])\n",
    "#     writer.writeheader()\n",
    "#     writer.writerows(results_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57fe507e",
   "metadata": {},
   "source": [
    "# **Stage 2: LLM-Based Categorization and File Organization by Description**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29857281",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# import shutil\n",
    "# from langchain.prompts import PromptTemplate\n",
    "# from langchain.chains import LLMChain\n",
    "# from langchain.llms import Ollama\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# # Initialize second LLM\n",
    "# llm2 = Ollama(model=\"taozhiyuai/llama-3-refueled:q4_k_m\")\n",
    "\n",
    "# # Prompt for classification based on description\n",
    "# prompt_template_stage2 = PromptTemplate(\n",
    "#     input_variables=[\"description\"],\n",
    "#     template=\"\"\"\n",
    "# You are a strict content classifier.\n",
    "\n",
    "# Given the following short description of a Markdown (.md) file:\n",
    "\n",
    "# \\\"\\\"\\\"\n",
    "# {description}\n",
    "# \\\"\\\"\\\"\n",
    "\n",
    "# Classify the content into one of these categories only:\n",
    "# - chats\n",
    "# - images\n",
    "# - other\n",
    "\n",
    "# Return only one of those three exact words (in lowercase). Do not use synonyms or explanations. Do not make up new categories.\n",
    "# \"\"\"\n",
    "# )\n",
    "\n",
    "# # Set up LangChain chain\n",
    "# chain2 = LLMChain(llm=llm2, prompt=prompt_template_stage2)\n",
    "\n",
    "# # Directories\n",
    "# original_dir = \"I-Soon-data/md\"\n",
    "# filtered_dir = \"Filtered-markdowns\"\n",
    "# os.makedirs(filtered_dir, exist_ok=True)\n",
    "\n",
    "# # Allowed categories\n",
    "# valid_categories = {\"chats\", \"images\", \"other\"}\n",
    "\n",
    "# # Reclassify and copy files\n",
    "# for file_name, description in tqdm(results.items()):\n",
    "#     try:\n",
    "#         category = chain2.run(description=description).strip().lower()\n",
    "#         if category not in valid_categories:\n",
    "#             category = \"other\"  # fallback to default\n",
    "\n",
    "#         # Create destination folder\n",
    "#         category_path = os.path.join(filtered_dir, category)\n",
    "#         os.makedirs(category_path, exist_ok=True)\n",
    "\n",
    "#         # Copy the file\n",
    "#         src_path = os.path.join(original_dir, file_name)\n",
    "#         dst_path = os.path.join(category_path, file_name)\n",
    "\n",
    "#         if os.path.exists(src_path):\n",
    "#             shutil.copy2(src_path, dst_path)\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"Failed to classify or copy {file_name}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c72754",
   "metadata": {},
   "source": [
    "# **Finding connetions between the MD files - reduced size due to performance issues**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65d0463",
   "metadata": {},
   "source": [
    "Idea: Have the LLM search the markdown files and look for any files linked outside the chats."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf991dca",
   "metadata": {},
   "source": [
    "# *RegEx based identification of linked files within the chat*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0e93fe",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import ast\n",
    "from langchain.llms import Ollama\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "# Step 1: Initialize LLM\n",
    "llm2 = Ollama(model=\"llama3.1:8b\")\n",
    "\n",
    "# Step 2: Define the prompt template\n",
    "prompt_template_file_types = PromptTemplate(\n",
    "    input_variables=[\"content\"],\n",
    "    template=\"\"\"\n",
    "List the top 50 file extensions most commonly found in cybersecurity leaked data, including data from breaches, ransomware leaks, and dark web dumps. THINK LIKE A CYBERSECURITY EXPERT.\n",
    "Focus on file types that typically contain credentials, configurations, databases, personal data, internal documentation, archives, or images (e.g., screenshots of sensitive material). \n",
    "\n",
    "OUTPUT INSTRUCTIONS:\n",
    "ONLY OUTPUT the extensions as a clean Python list format, like [<'file_extension'>, <'file_extension'>, etc.] \n",
    "Don't include \".\" and ALWAYS use \"'\" in the list. \n",
    "Do not include any explanations, comments, or extra text. \n",
    "JUST GIVE THE LIST.\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# Step 3: Run the chain to get extensions\n",
    "chain = LLMChain(llm=llm2, prompt=prompt_template_file_types)\n",
    "llm_response = chain.run(content=\"\")\n",
    "\n",
    "# Step 4: Print the LLM output\n",
    "print(\"🔍 LLM-generated file extensions list:\")\n",
    "print(llm_response)\n",
    "\n",
    "# Step 5: Parse LLM response into a Python list\n",
    "try:\n",
    "    # Extract only the list portion using regex\n",
    "    match = re.search(r\"\\[(.*?)\\]\", llm_response, re.DOTALL)\n",
    "    if match:\n",
    "        list_str = \"[\" + match.group(1) + \"]\"\n",
    "        common_extensions = ast.literal_eval(list_str)\n",
    "    else:\n",
    "        raise ValueError(\"❌ No list found in LLM response.\")\n",
    "except Exception as e:\n",
    "    raise ValueError(\"❌ Failed to parse LLM response into a list.\") from e\n",
    "\n",
    "# Step 6: Build dynamic regex\n",
    "ext_pattern = '|'.join(common_extensions)\n",
    "file_pattern = re.compile(r'[\\w\\-/\\.]{8,}\\.(?:' + ext_pattern + r')', re.IGNORECASE)\n",
    "\n",
    "# Step 7: Define chats path and extract files\n",
    "chats_path = 'I-Soon-data/md/chats'\n",
    "extracted_files_from_chats = {}\n",
    "\n",
    "for filename in os.listdir(chats_path):\n",
    "    if filename.endswith('.md'):\n",
    "        full_path = os.path.join(chats_path, filename)\n",
    "        with open(full_path, 'r', encoding='utf-8') as file:\n",
    "            content = file.read()\n",
    "            matches = file_pattern.findall(content)\n",
    "            if matches:\n",
    "                extracted_files_from_chats[filename] = matches\n",
    "\n",
    "# Step 8: Display results\n",
    "print(\"\\n📄 Extracted filenames from chats:\")\n",
    "for chat, files in extracted_files_from_chats.items():\n",
    "    print(f\"{chat}:\")\n",
    "    for f in files:\n",
    "        print(f\"  - {f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5857059",
   "metadata": {},
   "source": [
    "# *Search which files are in the leaked data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73d6162",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from langchain.llms import Ollama\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Step 1: Load markdown file\n",
    "markdown_file_path = 'I-Soon-data/md/chats/2.md'\n",
    "with open(markdown_file_path, 'r', encoding='utf-8') as file:\n",
    "    md_content = file.read()\n",
    "\n",
    "# Step 2: Split into overlapping chunks\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=200)\n",
    "chunks = splitter.split_text(md_content)\n",
    "\n",
    "# Step 3: Define the prompt\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"content\"],\n",
    "    template=\"\"\"\n",
    "You are a cybersecurity analyst. Think of the top 50 most common file types.\n",
    "Analyze the following markdown content and extract all the file names mentioned. \n",
    "Think based on the structure of the document how could a file be referenced. \n",
    "Look for syntax that indicates a file name (source, reference, \".\" and extension name) or how it can be refenced to another location from the document.\n",
    "ONLY OUTPUT a list of file names with extensions, separated by commas. Do not explain. No additional commentary.\n",
    "\n",
    "Content:\n",
    "{content}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# Step 4: Set up the LLM chain\n",
    "llm = Ollama(model=\"llama3.1:8b\")\n",
    "chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "\n",
    "# Step 5: Collect only valid filenames using regex\n",
    "found_files = []\n",
    "\n",
    "# Basic file name pattern: alphanumerics, dashes, underscores, ending in .ext (2–6 chars)\n",
    "file_regex = re.compile(r'\\b[\\w\\-]+(?:\\.[\\w\\-]+)*\\.\\w{2,6}\\b')\n",
    "\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"\\n🔍 Processing chunk {i+1}/{len(chunks)}...\")\n",
    "    try:\n",
    "        response = chain.run(content=chunk)\n",
    "        print(\"LLM Response:\", response)\n",
    "\n",
    "        # Use regex to extract file names only\n",
    "        matches = file_regex.findall(response)\n",
    "        found_files.extend([m.strip().lower() for m in matches])\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error processing chunk {i+1}: {e}\")\n",
    "\n",
    "# Step 6: Final clean result\n",
    "unique_files = sorted(set(found_files))\n",
    "\n",
    "print(\"\\n🎯 Unique filenames found across all chunks:\")\n",
    "for f in unique_files:\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171d4160-cd27-4d46-82e0-0ad102feb2ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eaa3717-8cb5-4436-bc12-a487d1fb78a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (IsoonAI)",
   "language": "python",
   "name": "isoonai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

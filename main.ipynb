{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08427a84-31f9-4bcf-875e-22b2e6497608",
   "metadata": {
    "user_expressions": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/IsoonAI/bin/python\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "144"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "\n",
    "import os\n",
    "os.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "879be4cb",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkout git\n",
      "kernel is working\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import subprocess\n",
    "import json\n",
    "import pandas as pd\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "import shutil\n",
    "\n",
    "\n",
    "# Paths and model settings\\ nZIP_PATH = 'I-Soon-data.zip'      # Path to your downloaded zip file\n",
    "ZIP_PATH = '0.zip'    # Directory to extract contents\n",
    "EXTRACT_DIR = 'I-Soon-data'        # Directory to extract contents\n",
    "print(\"Checkout git\")\n",
    "print(\"kernel is working\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e6feb79",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted archive to 'I-Soon-data'\n"
     ]
    }
   ],
   "source": [
    "if not os.path.isdir(EXTRACT_DIR):\n",
    "    with zipfile.ZipFile(ZIP_PATH, 'r') as zip_ref:\n",
    "        zip_ref.extractall(EXTRACT_DIR)\n",
    "    print(f\"Extracted archive to '{EXTRACT_DIR}'\")\n",
    "else:\n",
    "    print(f\"Extraction directory '{EXTRACT_DIR}' already exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325a01d8",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "# **DATA TYPE CATEGORIZATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dec65000",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted: I-Soon-data/__MACOSX\n"
     ]
    }
   ],
   "source": [
    "# Define the parent directory\n",
    "parent_directory = \"I-Soon-data\"\n",
    "\n",
    "# Full path to the __MACOSX folder\n",
    "macosx_folder = os.path.join(parent_directory, \"__MACOSX\")\n",
    "\n",
    "# Check if __MACOSX exists and remove it\n",
    "if os.path.exists(macosx_folder) and os.path.isdir(macosx_folder):\n",
    "    shutil.rmtree(macosx_folder)\n",
    "    print(f\"Deleted: {macosx_folder}\")\n",
    "else:\n",
    "    print(f\"Folder not found: {macosx_folder}\")\n",
    "\n",
    "# Organize files by extension into subfolders\n",
    "for root, dirs, files in os.walk(parent_directory):\n",
    "    for file in files:\n",
    "        # Skip hidden files and __MACOSX if any reappear\n",
    "        if file.startswith('.') or '__MACOSX' in root:\n",
    "            continue\n",
    "\n",
    "        # Get the file extension (in lowercase, without the dot)\n",
    "        file_extension = os.path.splitext(file)[1].lower().lstrip('.')\n",
    "        if not file_extension:\n",
    "            file_extension = \"no_extension\"\n",
    "\n",
    "        # Define the new subfolder path\n",
    "        subfolder_path = os.path.join(parent_directory, file_extension)\n",
    "\n",
    "        # Create the subfolder if it doesn't exist\n",
    "        os.makedirs(subfolder_path, exist_ok=True)\n",
    "\n",
    "        # Define source and destination paths\n",
    "        source_path = os.path.join(root, file)\n",
    "        destination_path = os.path.join(subfolder_path, file)\n",
    "\n",
    "        # Move the file if source and destination are not the same\n",
    "        if os.path.abspath(source_path) != os.path.abspath(destination_path):\n",
    "            shutil.move(source_path, destination_path)\n",
    "\n",
    "# Remove any empty folders within the parent directory\n",
    "for dirpath, dirnames, filenames in os.walk(parent_directory, topdown=False):\n",
    "    if not dirnames and not filenames:\n",
    "        try:\n",
    "            os.rmdir(dirpath)\n",
    "            print(f\"Removed empty folder: {dirpath}\")\n",
    "        except OSError:\n",
    "            pass  # Ignore errors (e.g., if directory is not empty due to permissions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75417f54",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "# **Markdown File Classification Using Local LLM (Ollama + LangChain)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9397264",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying files: 100%|██████████| 70/70 [02:37<00:00,  2.24s/it]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "import concurrent.futures\n",
    "from langchain.llms import Ollama\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === Step 1: Set up LLM and Prompt ===\n",
    "\n",
    "llm = Ollama(model=\"llama3.1:8b\")\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"content\"],\n",
    "    template=\"\"\"\n",
    "You are analyzing the content of a Markdown (.md) file.\n",
    "\n",
    "Markdown content:\n",
    "\\\"\\\"\\\"\n",
    "{content}\n",
    "\\\"\\\"\\\"\n",
    "\n",
    "1. Classify the content into one of the following categories ONLY: chats, images, other.\n",
    "2. State your confidence in the classification as one of: high, medium, or low.\n",
    "\n",
    "Respond in the following format:\n",
    "Category: <chats|images|other>\n",
    "Confidence: <high|medium|low>\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "\n",
    "# === Step 2: Preprocessing Function ===\n",
    "\n",
    "def preprocess_first_20_lines(file_path):\n",
    "    try:\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            lines = [line.strip() for _, line in zip(range(20), f)]\n",
    "            content = \" \".join(lines)\n",
    "        return os.path.basename(file_path), content\n",
    "    except Exception:\n",
    "        return os.path.basename(file_path), \"\"\n",
    "\n",
    "# === Step 3: Load .md Files ===\n",
    "\n",
    "md_dir = \"I-Soon-data/md\"\n",
    "md_files = glob.glob(os.path.join(md_dir, \"*.md\"))\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    file_data = list(executor.map(preprocess_first_20_lines, md_files))\n",
    "\n",
    "# === Step 4: Classify Each File and Move ===\n",
    "\n",
    "valid_categories = {\"chats\", \"images\", \"other\"}\n",
    "results_log = []\n",
    "\n",
    "for file_name, content in tqdm(file_data, desc=\"Classifying files\"):\n",
    "    if not content:\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        response = chain.run(content=content).strip().lower()\n",
    "        lines = response.splitlines()\n",
    "\n",
    "        category = next((line.replace(\"category:\", \"\").strip() for line in lines if line.startswith(\"category:\")), \"\")\n",
    "        confidence = next((line.replace(\"confidence:\", \"\").strip() for line in lines if line.startswith(\"confidence:\")), \"\")\n",
    "\n",
    "        if category not in valid_categories:\n",
    "            category = \"other\"\n",
    "\n",
    "        # Destination folder *within* the md_dir\n",
    "        category_path = os.path.join(md_dir, category)\n",
    "        os.makedirs(category_path, exist_ok=True)\n",
    "\n",
    "        # Move file into category folder\n",
    "        src_path = os.path.join(md_dir, file_name)\n",
    "        dst_path = os.path.join(category_path, file_name)\n",
    "\n",
    "        if os.path.exists(src_path):\n",
    "            shutil.move(src_path, dst_path)\n",
    "\n",
    "        results_log.append({\n",
    "            \"file\": file_name,\n",
    "            \"category\": category,\n",
    "            \"confidence\": confidence\n",
    "        })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process {file_name}: {e}\")\n",
    "\n",
    "# === Optional: Save results to file ===\n",
    "\n",
    "# import json\n",
    "# with open(\"classification_results.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "#     json.dump(results_log, f, indent=2)\n",
    "\n",
    "# import csv\n",
    "# with open(\"classification_results.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "#     writer = csv.DictWriter(f, fieldnames=[\"file\", \"category\", \"confidence\"])\n",
    "#     writer.writeheader()\n",
    "#     writer.writerows(results_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57fe507e",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "# **Stage 2: LLM-Based Categorization and File Organization by Description**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29857281",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# import shutil\n",
    "# from langchain.prompts import PromptTemplate\n",
    "# from langchain.chains import LLMChain\n",
    "# from langchain.llms import Ollama\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# # Initialize second LLM\n",
    "# llm2 = Ollama(model=\"taozhiyuai/llama-3-refueled:q4_k_m\")\n",
    "\n",
    "# # Prompt for classification based on description\n",
    "# prompt_template_stage2 = PromptTemplate(\n",
    "#     input_variables=[\"description\"],\n",
    "#     template=\"\"\"\n",
    "# You are a strict content classifier.\n",
    "\n",
    "# Given the following short description of a Markdown (.md) file:\n",
    "\n",
    "# \\\"\\\"\\\"\n",
    "# {description}\n",
    "# \\\"\\\"\\\"\n",
    "\n",
    "# Classify the content into one of these categories only:\n",
    "# - chats\n",
    "# - images\n",
    "# - other\n",
    "\n",
    "# Return only one of those three exact words (in lowercase). Do not use synonyms or explanations. Do not make up new categories.\n",
    "# \"\"\"\n",
    "# )\n",
    "\n",
    "# # Set up LangChain chain\n",
    "# chain2 = LLMChain(llm=llm2, prompt=prompt_template_stage2)\n",
    "\n",
    "# # Directories\n",
    "# original_dir = \"I-Soon-data/md\"\n",
    "# filtered_dir = \"Filtered-markdowns\"\n",
    "# os.makedirs(filtered_dir, exist_ok=True)\n",
    "\n",
    "# # Allowed categories\n",
    "# valid_categories = {\"chats\", \"images\", \"other\"}\n",
    "\n",
    "# # Reclassify and copy files\n",
    "# for file_name, description in tqdm(results.items()):\n",
    "#     try:\n",
    "#         category = chain2.run(description=description).strip().lower()\n",
    "#         if category not in valid_categories:\n",
    "#             category = \"other\"  # fallback to default\n",
    "\n",
    "#         # Create destination folder\n",
    "#         category_path = os.path.join(filtered_dir, category)\n",
    "#         os.makedirs(category_path, exist_ok=True)\n",
    "\n",
    "#         # Copy the file\n",
    "#         src_path = os.path.join(original_dir, file_name)\n",
    "#         dst_path = os.path.join(category_path, file_name)\n",
    "\n",
    "#         if os.path.exists(src_path):\n",
    "#             shutil.copy2(src_path, dst_path)\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"Failed to classify or copy {file_name}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c72754",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "# **Finding connetions between the MD files - reduced size due to performance issues**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65d0463",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "Idea: Have the LLM search the markdown files and look for any files linked outside the chats."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf991dca",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "# *RegEx based identification of linked files within the chat*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff0e93fe",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 LLM-generated file extensions list:\n",
      "[txt, json, cfg, db, mp3, wav, mp4, flv, jpg, jpeg, png, gif, pdf, docx, xlsx, pptx, rar, zip, 7z, tar, gz, bz2, sqlite, mdb, accdb, xml, html, css, js, sql, mdf, bak, dat, log, eml, pst, msg, odt, odp, odg, docs, xls, xla, ppt, xlsm]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "❌ Failed to parse LLM response into a list.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mSyntaxError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 40\u001b[39m\n\u001b[32m     39\u001b[39m     list_str = \u001b[33m\"\u001b[39m\u001b[33m[\u001b[39m\u001b[33m\"\u001b[39m + match.group(\u001b[32m1\u001b[39m) + \u001b[33m\"\u001b[39m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m     common_extensions = \u001b[43mast\u001b[49m\u001b[43m.\u001b[49m\u001b[43mliteral_eval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlist_str\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.11/ast.py:64\u001b[39m, in \u001b[36mliteral_eval\u001b[39m\u001b[34m(node_or_string)\u001b[39m\n\u001b[32m     63\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(node_or_string, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m     node_or_string = \u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_or_string\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlstrip\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m \u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43meval\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(node_or_string, Expression):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.11/ast.py:50\u001b[39m, in \u001b[36mparse\u001b[39m\u001b[34m(source, filename, mode, type_comments, feature_version)\u001b[39m\n\u001b[32m     49\u001b[39m \u001b[38;5;66;03m# Else it should be an int giving the minor version for 3.x.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcompile\u001b[39m(source, filename, mode, flags,\n\u001b[32m     51\u001b[39m                _feature_version=feature_version)\n",
      "\u001b[31mSyntaxError\u001b[39m: invalid decimal literal (<unknown>, line 1)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 44\u001b[39m\n\u001b[32m     42\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33m❌ No list found in LLM response.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33m❌ Failed to parse LLM response into a list.\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m     46\u001b[39m \u001b[38;5;66;03m# Step 6: Build dynamic regex\u001b[39;00m\n\u001b[32m     47\u001b[39m ext_pattern = \u001b[33m'\u001b[39m\u001b[33m|\u001b[39m\u001b[33m'\u001b[39m.join(common_extensions)\n",
      "\u001b[31mValueError\u001b[39m: ❌ Failed to parse LLM response into a list."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import ast\n",
    "from langchain.llms import Ollama\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "# Step 1: Initialize LLM\n",
    "llm2 = Ollama(model=\"llama3.1:8b\")\n",
    "\n",
    "# Step 2: Define the prompt template\n",
    "prompt_template_file_types = PromptTemplate(\n",
    "    input_variables=[\"content\"],\n",
    "    template=\"\"\"\n",
    "List the top 50 file extensions most commonly found in cybersecurity leaked data, including data from breaches, ransomware leaks, and dark web dumps. THINK LIKE A CYBERSECURITY EXPERT.\n",
    "Focus on file types that typically contain credentials, configurations, databases, personal data, internal documentation, archives, or images (e.g., screenshots of sensitive material). \n",
    "\n",
    "OUTPUT INSTRUCTIONS:\n",
    "ONLY OUTPUT the extensions as a clean Python list format, like [<'file_extension'>, <'file_extension'>, etc.] \n",
    "Don't include \".\" and ALWAYS use \"'\" in the list. \n",
    "Do not include any explanations, comments, or extra text. \n",
    "JUST GIVE THE LIST.\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# Step 3: Run the chain to get extensions\n",
    "chain = LLMChain(llm=llm2, prompt=prompt_template_file_types)\n",
    "llm_response = chain.run(content=\"\")\n",
    "\n",
    "# Step 4: Print the LLM output\n",
    "print(\"🔍 LLM-generated file extensions list:\")\n",
    "print(llm_response)\n",
    "\n",
    "# Step 5: Parse LLM response into a Python list\n",
    "try:\n",
    "    # Extract only the list portion using regex\n",
    "    match = re.search(r\"\\[(.*?)\\]\", llm_response, re.DOTALL)\n",
    "    if match:\n",
    "        list_str = \"[\" + match.group(1) + \"]\"\n",
    "        common_extensions = ast.literal_eval(list_str)\n",
    "    else:\n",
    "        raise ValueError(\"❌ No list found in LLM response.\")\n",
    "except Exception as e:\n",
    "    raise ValueError(\"❌ Failed to parse LLM response into a list.\") from e\n",
    "\n",
    "# Step 6: Build dynamic regex\n",
    "ext_pattern = '|'.join(common_extensions)\n",
    "file_pattern = re.compile(r'[\\w\\-/\\.]{8,}\\.(?:' + ext_pattern + r')', re.IGNORECASE)\n",
    "\n",
    "# Step 7: Define chats path and extract files\n",
    "chats_path = 'I-Soon-data/md/chats'\n",
    "extracted_files_from_chats = {}\n",
    "\n",
    "for filename in os.listdir(chats_path):\n",
    "    if filename.endswith('.md'):\n",
    "        full_path = os.path.join(chats_path, filename)\n",
    "        with open(full_path, 'r', encoding='utf-8') as file:\n",
    "            content = file.read()\n",
    "            matches = file_pattern.findall(content)\n",
    "            if matches:\n",
    "                extracted_files_from_chats[filename] = matches\n",
    "\n",
    "# Step 8: Display results\n",
    "print(\"\\n📄 Extracted filenames from chats:\")\n",
    "for chat, files in extracted_files_from_chats.items():\n",
    "    print(f\"{chat}:\")\n",
    "    for f in files:\n",
    "        print(f\"  - {f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4106970-b30f-464e-96ce-4f787d3d2722",
   "metadata": {
    "tags": []
   },
   "source": [
    "# *Search which files are in the leaked data with Threads*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a73d6162",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔍 Processing:   0%|                                                         | 0/65 [00:00<?, ?it/s]/tmp/ipykernel_57667/2074056792.py:56: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.\n",
      "  llm = Ollama(model=\"qwen2.5:14b\")\n",
      "/tmp/ipykernel_57667/2074056792.py:57: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chain = LLMChain(llm=llm, prompt=prompt_template)\n",
      "/tmp/ipykernel_57667/2074056792.py:61: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = chain.run(content=content)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Starting with 72 threads and batch size 7 on 449 lines...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔍 Processing:   2%|▊                                                | 1/65 [00:32<34:21, 32.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Thread-140575202334272] ✅ Batch starting at line 8 done in 32.20s | Matches: 0\n",
      "[Thread-140575177156160] ✅ Batch starting at line 29 done in 32.21s | Matches: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔍 Processing:   5%|██▎                                              | 3/65 [00:35<09:47,  9.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Thread-140574581569088] ✅ Batch starting at line 71 done in 35.25s | Matches: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔍 Processing:   6%|███                                              | 4/65 [00:36<06:42,  6.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Thread-140575210726976] ✅ Batch starting at line 1 done in 36.40s | Matches: 0\n",
      "[Thread-140574573176384] ✅ Batch starting at line 78 done in 36.49s | Matches: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔍 Processing:   9%|████▌                                            | 6/65 [00:38<03:43,  3.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Thread-140574564783680] ✅ Batch starting at line 85 done in 38.30s | Matches: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔍 Processing:  11%|█████▎                                           | 7/65 [00:39<02:58,  3.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Thread-140571930785344] ✅ Batch starting at line 288 done in 39.36s | Matches: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔍 Processing:  12%|██████                                           | 8/65 [00:40<02:24,  2.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Thread-140570303387200] ✅ Batch starting at line 449 done in 40.40s | Matches: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔍 Processing:  14%|██████▊                                          | 9/65 [00:41<01:58,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Thread-140573533005376] ✅ Batch starting at line 148 done in 41.50s | Matches: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔍 Processing:  15%|███████▍                                        | 10/65 [00:42<01:43,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Thread-140573516219968] ✅ Batch starting at line 162 done in 42.76s | Matches: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔍 Processing:  17%|████████                                        | 11/65 [00:44<01:31,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Thread-140572987741760] ✅ Batch starting at line 204 done in 44.00s | Matches: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔍 Processing:  18%|████████▊                                       | 12/65 [00:44<01:18,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Thread-140570815080000] ✅ Batch starting at line 421 done in 44.92s | Matches: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔍 Processing:  20%|█████████▌                                      | 13/65 [00:46<01:11,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Thread-140572996134464] ✅ Batch starting at line 197 done in 46.06s | Matches: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔍 Processing:  22%|██████████▎                                     | 14/65 [00:47<01:10,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Thread-140571897214528] ✅ Batch starting at line 316 done in 47.47s | Matches: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔍 Processing:  23%|███████████                                     | 15/65 [00:48<01:02,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Thread-140571880429120] ✅ Batch starting at line 330 done in 48.42s | Matches: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔍 Processing:  25%|███████████▊                                    | 16/65 [00:49<01:02,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Thread-140574606747200] ✅ Batch starting at line 50 done in 49.78s | Matches: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔍 Processing:  26%|████████████▌                                   | 17/65 [00:51<01:06,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Thread-140574027912768] ✅ Batch starting at line 134 done in 51.41s | Matches: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔍 Processing:  28%|█████████████▎                                  | 18/65 [00:52<01:01,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Thread-140573541398080] ✅ Batch starting at line 141 done in 52.51s | Matches: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔍 Processing:  29%|██████████████                                  | 19/65 [00:53<01:01,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Thread-140570311779904] ✅ Batch starting at line 442 done in 53.88s | Matches: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔍 Processing:  31%|██████████████▊                                 | 20/65 [00:55<00:56,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Thread-140573507827264] ✅ Batch starting at line 169 done in 55.02s | Matches: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔍 Processing:  32%|███████████████▌                                | 21/65 [00:56<01:01,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Thread-140572417300032] ✅ Batch starting at line 281 done in 56.72s | Matches: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔍 Processing:  34%|████████████████▏                               | 22/65 [00:57<00:57,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Thread-140574061483584] ✅ Batch starting at line 106 done in 57.91s | Matches: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔍 Processing:  35%|████████████████▉                               | 23/65 [00:58<00:51,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Thread-140573491041856] ✅ Batch starting at line 183 done in 58.87s | Matches: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔍 Processing:  37%|█████████████████▋                              | 24/65 [01:00<00:54,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Thread-140575185548864] ✅ Batch starting at line 22 done in 60.50s | Matches: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔍 Processing:  38%|██████████████████▍                             | 25/65 [01:02<00:57,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Thread-140571385521728] ✅ Batch starting at line 344 done in 62.11s | Matches: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔍 Processing:  40%|███████████████████▏                            | 26/65 [01:03<00:54,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Thread-140570831865408] ✅ Batch starting at line 407 done in 63.42s | Matches: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔍 Processing:  42%|███████████████████▉                            | 27/65 [01:04<00:48,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Thread-140572459263552] ✅ Batch starting at line 246 done in 64.42s | Matches: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔍 Processing:  43%|████████████████████▋                           | 28/65 [01:05<00:43,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Thread-140572954170944] ✅ Batch starting at line 232 done in 65.35s | Matches: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔍 Processing:  45%|█████████████████████▍                          | 29/65 [01:05<00:32,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Thread-140574615139904] ✅ Batch starting at line 43 done in 65.61s | Matches: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔍 Processing:  46%|██████████████████████▏                         | 30/65 [01:07<00:40,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Thread-140571360343616] ✅ Batch starting at line 365 done in 67.40s | Matches: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔍 Processing:  48%|██████████████████████▉                         | 31/65 [01:08<00:39,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Thread-140571913999936] ✅ Batch starting at line 302 done in 68.58s | Matches: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔍 Processing:  49%|███████████████████████▋                        | 32/65 [01:13<01:13,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Thread-140572450870848] ✅ Batch starting at line 253 done in 73.31s | Matches: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔍 Processing:  51%|████████████████████████▎                       | 33/65 [01:14<01:01,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Thread-140573524612672] ✅ Batch starting at line 155 done in 74.47s | Matches: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔍 Processing:  52%|█████████████████████████                       | 34/65 [01:15<00:53,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Thread-140573499434560] ✅ Batch starting at line 176 done in 75.78s | Matches: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔍 Processing:  54%|█████████████████████████▊                      | 35/65 [01:16<00:44,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Thread-140572425692736] ✅ Batch starting at line 274 done in 76.69s | Matches: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔍 Processing:  55%|██████████████████████████▌                     | 36/65 [01:17<00:38,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Thread-140571343558208] ✅ Batch starting at line 379 done in 77.64s | Matches: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔍 Processing:  58%|████████████████████████████                    | 38/65 [01:19<00:26,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Thread-140574053090880] ✅ Batch starting at line 113 done in 78.98s | Matches: 0\n",
      "[Thread-140572442478144] ✅ Batch starting at line 260 done in 79.16s | Matches: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔍 Processing:  60%|████████████████████████████▊                   | 39/65 [01:20<00:29,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Thread-140571888821824] ✅ Batch starting at line 323 done in 80.69s | Matches: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔍 Processing:  62%|█████████████████████████████▌                  | 40/65 [01:21<00:29,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Thread-140570848650816] ✅ Batch starting at line 393 done in 81.87s | Matches: 0\n",
      "[Thread-140574078268992] ✅ Batch starting at line 92 done in 81.92s | Matches: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔍 Processing:  65%|███████████████████████████████                 | 42/65 [01:23<00:23,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Thread-140574589961792] ✅ Batch starting at line 64 done in 83.71s | Matches: 0\n",
      "[Thread-140572434085440] ✅ Batch starting at line 267 done in 83.69s | Matches: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔍 Processing:  68%|████████████████████████████████▍               | 44/65 [01:25<00:19,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Thread-140574598354496] ✅ Batch starting at line 57 done in 85.16s | Matches: 0\n",
      "[Thread-140573004527168] ✅ Batch starting at line 190 done in 85.23s | Matches: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔍 Processing:  71%|█████████████████████████████████▉              | 46/65 [01:26<00:16,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Thread-140570806687296] ✅ Batch starting at line 428 done in 86.58s | Matches: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔍 Processing:  72%|██████████████████████████████████▋             | 47/65 [01:27<00:16,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Thread-140572467656256] ✅ Batch starting at line 239 done in 87.70s | Matches: 0\n",
      "[Thread-140570823472704] ✅ Batch starting at line 414 done in 87.69s | Matches: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔍 Processing:  75%|████████████████████████████████████▏           | 49/65 [01:29<00:14,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Thread-140574036305472] ✅ Batch starting at line 127 done in 89.54s | Matches: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔍 Processing:  77%|████████████████████████████████████▉           | 50/65 [01:30<00:14,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Thread-140571905607232] ✅ Batch starting at line 309 done in 90.68s | Matches: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔍 Processing:  78%|█████████████████████████████████████▋          | 51/65 [01:31<00:14,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Thread-140575193941568] ✅ Batch starting at line 15 done in 91.93s | Matches: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔍 Processing:  80%|██████████████████████████████████████▍         | 52/65 [01:32<00:13,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Thread-140572962563648] ✅ Batch starting at line 225 done in 92.91s | Matches: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔍 Processing:  82%|███████████████████████████████████████▏        | 53/65 [01:34<00:12,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Thread-140571377129024] ✅ Batch starting at line 351 done in 93.97s | Matches: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔍 Processing:  83%|███████████████████████████████████████▉        | 54/65 [01:35<00:12,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Thread-140570840258112] ✅ Batch starting at line 400 done in 95.44s | Matches: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔍 Processing:  85%|████████████████████████████████████████▌       | 55/65 [01:36<00:11,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Thread-140574069876288] ✅ Batch starting at line 99 done in 96.64s | Matches: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔍 Processing:  86%|█████████████████████████████████████████▎      | 56/65 [01:37<00:09,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Thread-140571922392640] ✅ Batch starting at line 295 done in 97.47s | Matches: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔍 Processing:  88%|██████████████████████████████████████████      | 57/65 [01:38<00:08,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Thread-140570320172608] ✅ Batch starting at line 435 done in 98.40s | Matches: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔍 Processing:  89%|██████████████████████████████████████████▊     | 58/65 [01:39<00:07,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Thread-140571351950912] ✅ Batch starting at line 372 done in 99.38s | Matches: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔍 Processing:  91%|███████████████████████████████████████████▌    | 59/65 [01:42<00:09,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Thread-140575168763456] ✅ Batch starting at line 36 done in 102.34s | Matches: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔍 Processing:  92%|████████████████████████████████████████████▎   | 60/65 [01:43<00:07,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Thread-140570857043520] ✅ Batch starting at line 386 done in 103.88s | Matches: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔍 Processing:  94%|█████████████████████████████████████████████   | 61/65 [01:45<00:05,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Thread-140571368736320] ✅ Batch starting at line 358 done in 104.97s | Matches: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔍 Processing:  95%|█████████████████████████████████████████████▊  | 62/65 [01:46<00:04,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Thread-140572970956352] ✅ Batch starting at line 218 done in 106.16s | Matches: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔍 Processing:  97%|██████████████████████████████████████████████▌ | 63/65 [01:48<00:03,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Thread-140574044698176] ✅ Batch starting at line 120 done in 108.90s | Matches: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔍 Processing:  98%|███████████████████████████████████████████████▎| 64/65 [01:49<00:01,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Thread-140571393914432] ✅ Batch starting at line 337 done in 109.80s | Matches: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔍 Processing: 100%|████████████████████████████████████████████████| 65/65 [01:50<00:00,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Thread-140572979349056] ✅ Batch starting at line 211 done in 110.74s | Matches: 2\n",
      "\n",
      "🎯 Unique filenames found:\n",
      "0-4ea07c23-a1a6-411b-bcfb-552d095b66c9.png\n",
      "0-5a84cde3-7175-4044-8c88-d4c883a8fd38.png\n",
      "0-6bcc0131-e4ad-421e-bb1f-d8ebe5eeec7b.png\n",
      "0-79d9b7f2-cfe4-4615-9b75-8fea33fc0c9d.png\n",
      "0-e705d192-90ee-4fd1-9dcd-061958d1817f.png\n",
      "12756724-394c-4576-b373-7c53f1abbd94.md\n",
      "4ea07c23-a1a6-411b-bcfb-552d095b66c9.png\n",
      "5a84cde3-7175-4044-8c88-d4c883a8fd38.png\n",
      "6bcc0131-e4ad-421e-bb1f-d8ebe5eeec7b.png\n",
      "79d9b7f2-cfe4-4615-9b75-8fea33fc0c9d.png\n",
      "e705d192-90ee-4fd1-9dcd-061958d1817f.png\n",
      "安洵.7z\n",
      "\n",
      "✅ Total unique files found: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import threading\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from langchain.llms import Ollama\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "\n",
    "# Load and clean lines\n",
    "with open('I-Soon-data/md/chats/10.md', 'r', encoding='utf-8') as f:\n",
    "    lines = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "# Split lines into batches\n",
    "def batch_lines(lines, batch_size):\n",
    "    for i in range(0, len(lines), batch_size):\n",
    "        yield i, lines[i:i+batch_size]\n",
    "\n",
    "# Parameters\n",
    "n_threads = 72  \n",
    "batch_size = math.ceil(len(lines)/n_threads)\n",
    "        \n",
    "# Regex and shared resources\n",
    "file_regex = re.compile(r'\\b[\\w\\-]+(?:\\.[\\w\\-]+)*\\.\\w{2,6}\\b')\n",
    "found_files = []\n",
    "lock = threading.Lock()\n",
    "\n",
    "# Prompt template (adjusted for batches)\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"content\"],\n",
    "    template=\"\"\"\n",
    "You are a cybersecurity analyst with expert knowledge of file types and syntax used to reference files in certain documents and related contexts.\n",
    "Your task is to analyze the given content and extract all explicit file names with extensions.\n",
    "Follow these guidelines:\n",
    "    • Only include file names that explicitly contain a valid extension.\n",
    "    • Consider common patterns such as filename.ext, [text](filename.ext), src=\"filename.ext\", path/to/filename.ext, etc.\n",
    "    • Recognize contextual clues like source, reference, include, or links that point to files.\n",
    "    • Use your knowledge of the top 50 most common file extensions to guide detection.\n",
    "    • Do not infer or fabricate file names based on ambiguous text. Do not extract names without a clear extension.\n",
    "    •  Use your knowledge of the top 50 most common file extensions to guide detection.\n",
    "    • Output only: a single line list of the detected file names with extensions, separated by commas. No explanation or commentary.\n",
    "Content:\n",
    "{content}\n",
    "\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# Progress bar\n",
    "progress_bar = tqdm(total=(len(lines) // batch_size) + 1, desc=\"🔍 Processing\", ncols=100)\n",
    "\n",
    "# Worker function for each batch\n",
    "def process_batch(start_idx: int, lines_batch: list[str]):\n",
    "    thread_id = threading.get_ident()\n",
    "    try:\n",
    "        llm = Ollama(model=\"qwen2.5:14b\")\n",
    "        chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "\n",
    "        content = \"\\n\".join(lines_batch)\n",
    "        start_time = time.time()\n",
    "        response = chain.run(content=content)\n",
    "        duration = time.time() - start_time\n",
    "\n",
    "        matches = file_regex.findall(response)\n",
    "        match_count = len(matches)\n",
    "\n",
    "        if matches:\n",
    "            with lock:\n",
    "                found_files.extend([m.strip().lower() for m in matches])\n",
    "\n",
    "        print(f\"[Thread-{thread_id}] ✅ Batch starting at line {start_idx + 1} done in {duration:.2f}s | Matches: {match_count}\")\n",
    "    except Exception as e:\n",
    "        print(f\"[Thread-{thread_id}] ❌ Error on batch starting at line {start_idx + 1}: {e}\")\n",
    "    finally:\n",
    "        progress_bar.update(1)\n",
    "\n",
    "# Start threaded batch processing\n",
    "print(f\"\\n🚀 Starting with {n_threads} threads and batch size {batch_size} on {len(lines)} lines...\\n\")\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=n_threads) as executor:\n",
    "    futures = [executor.submit(process_batch, i, batch) for i, batch in batch_lines(lines, batch_size)]\n",
    "    for future in as_completed(futures):\n",
    "        future.result()\n",
    "\n",
    "progress_bar.close()\n",
    "\n",
    "# Output results\n",
    "print(\"\\n🎯 Unique filenames found:\")\n",
    "unique_files = sorted(set(found_files))\n",
    "for f in unique_files:\n",
    "    print(f)\n",
    "\n",
    "print(f\"\\n✅ Total unique files found: {len(unique_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55a603e-103a-46c0-9dcc-8c72023cacb8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import shutil\n",
    "# import os\n",
    "\n",
    "# # Directory to delete\n",
    "# EXTRACT_DIR = 'I-Soon-data'\n",
    "\n",
    "# # Check if the directory exists and delete it\n",
    "# if os.path.isdir(EXTRACT_DIR):\n",
    "#     shutil.rmtree(EXTRACT_DIR)\n",
    "#     print(f\"Directory '{EXTRACT_DIR}' has been deleted.\")\n",
    "# else:\n",
    "#     print(f\"Directory '{EXTRACT_DIR}' does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c242f8e-af9c-488e-9a4a-92bdc06a8ec7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (IsoonAI)",
   "language": "python",
   "name": "isoonai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

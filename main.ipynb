{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "08427a84-31f9-4bcf-875e-22b2e6497608",
   "metadata": {
    "user_expressions": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/IsoonAI/bin/python\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "\n",
    "import os\n",
    "os.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "879be4cb",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkout git\n",
      "kernel is working\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import subprocess\n",
    "import json\n",
    "import pandas as pd\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "import shutil\n",
    "\n",
    "\n",
    "# Paths and model settings\\ nZIP_PATH = 'I-Soon-data.zip'      # Path to your downloaded zip file\n",
    "ZIP_PATH = '0.zip'    # Directory to extract contents\n",
    "EXTRACT_DIR = 'I-Soon-data'        # Directory to extract contents\n",
    "print(\"Checkout git\")\n",
    "print(\"kernel is working\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5e6feb79",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted archive to 'I-Soon-data'\n"
     ]
    }
   ],
   "source": [
    "if not os.path.isdir(EXTRACT_DIR):\n",
    "    with zipfile.ZipFile(ZIP_PATH, 'r') as zip_ref:\n",
    "        zip_ref.extractall(EXTRACT_DIR)\n",
    "    print(f\"Extracted archive to '{EXTRACT_DIR}'\")\n",
    "else:\n",
    "    print(f\"Extraction directory '{EXTRACT_DIR}' already exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325a01d8",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "# **DATA TYPE CATEGORIZATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dec65000",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted: I-Soon-data/__MACOSX\n"
     ]
    }
   ],
   "source": [
    "# Define the parent directory\n",
    "parent_directory = \"I-Soon-data\"\n",
    "\n",
    "# Full path to the __MACOSX folder\n",
    "macosx_folder = os.path.join(parent_directory, \"__MACOSX\")\n",
    "\n",
    "# Check if __MACOSX exists and remove it\n",
    "if os.path.exists(macosx_folder) and os.path.isdir(macosx_folder):\n",
    "    shutil.rmtree(macosx_folder)\n",
    "    print(f\"Deleted: {macosx_folder}\")\n",
    "else:\n",
    "    print(f\"Folder not found: {macosx_folder}\")\n",
    "\n",
    "# Organize files by extension into subfolders\n",
    "for root, dirs, files in os.walk(parent_directory):\n",
    "    for file in files:\n",
    "        # Skip hidden files and __MACOSX if any reappear\n",
    "        if file.startswith('.') or '__MACOSX' in root:\n",
    "            continue\n",
    "\n",
    "        # Get the file extension (in lowercase, without the dot)\n",
    "        file_extension = os.path.splitext(file)[1].lower().lstrip('.')\n",
    "        if not file_extension:\n",
    "            file_extension = \"no_extension\"\n",
    "\n",
    "        # Define the new subfolder path\n",
    "        subfolder_path = os.path.join(parent_directory, file_extension)\n",
    "\n",
    "        # Create the subfolder if it doesn't exist\n",
    "        os.makedirs(subfolder_path, exist_ok=True)\n",
    "\n",
    "        # Define source and destination paths\n",
    "        source_path = os.path.join(root, file)\n",
    "        destination_path = os.path.join(subfolder_path, file)\n",
    "\n",
    "        # Move the file if source and destination are not the same\n",
    "        if os.path.abspath(source_path) != os.path.abspath(destination_path):\n",
    "            shutil.move(source_path, destination_path)\n",
    "\n",
    "# Remove any empty folders within the parent directory\n",
    "for dirpath, dirnames, filenames in os.walk(parent_directory, topdown=False):\n",
    "    if not dirnames and not filenames:\n",
    "        try:\n",
    "            os.rmdir(dirpath)\n",
    "            print(f\"Removed empty folder: {dirpath}\")\n",
    "        except OSError:\n",
    "            pass  # Ignore errors (e.g., if directory is not empty due to permissions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75417f54",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "# **Markdown File Classification Using Local LLM (Ollama + LangChain)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b9397264",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 70/70 [05:53<00:00,  5.04s/it]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "import concurrent.futures\n",
    "from langchain.llms import Ollama\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === Step 1: Set up LLM and Prompt ===\n",
    "\n",
    "llm = Ollama(model=\"llama3.1:8b\")\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"content\"],\n",
    "    template=\"\"\"\n",
    "You are analyzing the content of a Markdown (.md) file.\n",
    "\n",
    "Markdown content:\n",
    "\\\"\\\"\\\"\n",
    "{content}\n",
    "\\\"\\\"\\\"\n",
    "\n",
    "1. Classify the content into one of the following categories ONLY: chats, images, other.\n",
    "2. State your confidence in the classification as one of: high, medium, or low.\n",
    "\n",
    "Respond in the following format:\n",
    "Category: <chats|images|other>\n",
    "Confidence: <high|medium|low>\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "\n",
    "# === Step 2: Preprocessing Function ===\n",
    "\n",
    "def preprocess_first_20_lines(file_path):\n",
    "    try:\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            lines = [line.strip() for _, line in zip(range(20), f)]\n",
    "            content = \" \".join(lines)\n",
    "        return os.path.basename(file_path), content\n",
    "    except Exception:\n",
    "        return os.path.basename(file_path), \"\"\n",
    "\n",
    "# === Step 3: Load .md Files ===\n",
    "\n",
    "md_dir = \"I-Soon-data/md\"\n",
    "md_files = glob.glob(os.path.join(md_dir, \"*.md\"))\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    file_data = list(executor.map(preprocess_first_20_lines, md_files))\n",
    "\n",
    "# === Step 4: Classify Each File and Move ===\n",
    "\n",
    "valid_categories = {\"chats\", \"images\", \"other\"}\n",
    "results_log = []\n",
    "\n",
    "for file_name, content in tqdm(file_data, desc=\"Classifying files\"):\n",
    "    if not content:\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        response = chain.run(content=content).strip().lower()\n",
    "        lines = response.splitlines()\n",
    "\n",
    "        category = next((line.replace(\"category:\", \"\").strip() for line in lines if line.startswith(\"category:\")), \"\")\n",
    "        confidence = next((line.replace(\"confidence:\", \"\").strip() for line in lines if line.startswith(\"confidence:\")), \"\")\n",
    "\n",
    "        if category not in valid_categories:\n",
    "            category = \"other\"\n",
    "\n",
    "        # Destination folder *within* the md_dir\n",
    "        category_path = os.path.join(md_dir, category)\n",
    "        os.makedirs(category_path, exist_ok=True)\n",
    "\n",
    "        # Move file into category folder\n",
    "        src_path = os.path.join(md_dir, file_name)\n",
    "        dst_path = os.path.join(category_path, file_name)\n",
    "\n",
    "        if os.path.exists(src_path):\n",
    "            shutil.move(src_path, dst_path)\n",
    "\n",
    "        results_log.append({\n",
    "            \"file\": file_name,\n",
    "            \"category\": category,\n",
    "            \"confidence\": confidence\n",
    "        })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process {file_name}: {e}\")\n",
    "\n",
    "# === Optional: Save results to file ===\n",
    "\n",
    "# import json\n",
    "# with open(\"classification_results.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "#     json.dump(results_log, f, indent=2)\n",
    "\n",
    "# import csv\n",
    "# with open(\"classification_results.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "#     writer = csv.DictWriter(f, fieldnames=[\"file\", \"category\", \"confidence\"])\n",
    "#     writer.writeheader()\n",
    "#     writer.writerows(results_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57fe507e",
   "metadata": {},
   "source": [
    "# **Stage 2: LLM-Based Categorization and File Organization by Description**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29857281",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# import shutil\n",
    "# from langchain.prompts import PromptTemplate\n",
    "# from langchain.chains import LLMChain\n",
    "# from langchain.llms import Ollama\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# # Initialize second LLM\n",
    "# llm2 = Ollama(model=\"taozhiyuai/llama-3-refueled:q4_k_m\")\n",
    "\n",
    "# # Prompt for classification based on description\n",
    "# prompt_template_stage2 = PromptTemplate(\n",
    "#     input_variables=[\"description\"],\n",
    "#     template=\"\"\"\n",
    "# You are a strict content classifier.\n",
    "\n",
    "# Given the following short description of a Markdown (.md) file:\n",
    "\n",
    "# \\\"\\\"\\\"\n",
    "# {description}\n",
    "# \\\"\\\"\\\"\n",
    "\n",
    "# Classify the content into one of these categories only:\n",
    "# - chats\n",
    "# - images\n",
    "# - other\n",
    "\n",
    "# Return only one of those three exact words (in lowercase). Do not use synonyms or explanations. Do not make up new categories.\n",
    "# \"\"\"\n",
    "# )\n",
    "\n",
    "# # Set up LangChain chain\n",
    "# chain2 = LLMChain(llm=llm2, prompt=prompt_template_stage2)\n",
    "\n",
    "# # Directories\n",
    "# original_dir = \"I-Soon-data/md\"\n",
    "# filtered_dir = \"Filtered-markdowns\"\n",
    "# os.makedirs(filtered_dir, exist_ok=True)\n",
    "\n",
    "# # Allowed categories\n",
    "# valid_categories = {\"chats\", \"images\", \"other\"}\n",
    "\n",
    "# # Reclassify and copy files\n",
    "# for file_name, description in tqdm(results.items()):\n",
    "#     try:\n",
    "#         category = chain2.run(description=description).strip().lower()\n",
    "#         if category not in valid_categories:\n",
    "#             category = \"other\"  # fallback to default\n",
    "\n",
    "#         # Create destination folder\n",
    "#         category_path = os.path.join(filtered_dir, category)\n",
    "#         os.makedirs(category_path, exist_ok=True)\n",
    "\n",
    "#         # Copy the file\n",
    "#         src_path = os.path.join(original_dir, file_name)\n",
    "#         dst_path = os.path.join(category_path, file_name)\n",
    "\n",
    "#         if os.path.exists(src_path):\n",
    "#             shutil.copy2(src_path, dst_path)\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"Failed to classify or copy {file_name}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c72754",
   "metadata": {},
   "source": [
    "# **Finding connetions between the MD files - reduced size due to performance issues**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65d0463",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "Idea: Have the LLM search the markdown files and look for any files linked outside the chats."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf991dca",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "# *RegEx based identification of linked files within the chat*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ff0e93fe",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç LLM-generated file extensions list:\n",
      "['docx', 'ods', 'odt', 'pdf', 'jpg', 'jpeg', 'png', 'gif', 'bmp', 'txt', 'log', 'cfg', 'ini', 'reg', 'dbf', 'mdb', 'accdb', 'sqlite', 'sql', 'bak', 'mdf', 'ndf', 'ldf', 'db', 'mdb', 's3db', 'xml', 'json', 'yaml', 'csv', 'xls', 'xlsx', 'xlsm', 'xlt', 'ppt', 'pptx', 'doc', 'dot', 'rtf', 'msg', 'eml', 'vcf', 'jpg', 'jpeg', 'tiff', 'tif', 'gif', 'bmp', 'pcapng', 'pcap', 'csv', 'json', 'ods', 'xlsx', 'xlsm', 'zip', 'rar', '7z', 'tar', 'gz', 'bz2']\n",
      "\n",
      "üìÑ Extracted filenames from chats:\n",
      "1.md:\n",
      "  - ÂÆâÊ¥µÈ°πÁõÆ-ÊäïËµÑÊÑèÂêë‰π¶-200730.DOCX\n",
      "  - ËØæÁ®ãË°®2020_Ë•øÂÆâ_ÂÜÖÁâà.docx\n",
      "  - c404_indictment_0.docx\n",
      "  - wong_indictment_redacted_0.docx\n",
      "  - zhr_indictment_redacted_0.docx\n",
      "  - ‰∫ßÊïôËûçÂêàÂª∫ËÆæÈ°πÁõÆÁî≥Êä•‰π¶20201028.docx\n",
      "  - tpyrced_ÊâìÂáªÊï¥Ê≤ªÊ∂âÁΩëÁäØÁΩ™ÊäÄÊúØÊúçÂä°ÂêàÂêå0201-Â§ßÁêÜ.docx\n",
      "  - 202063ÁÆÄÊä•-Ê®°ÊùøÂ±ïÁ§∫.pdf\n",
      "  - ÊØîÁâπ‰ø°ÂÆâÊï∞ÊçÆËÑ±ÊïèÁ≥ªÁªüsaasÊúçÂä°‰∏öÂä°Ê®°Âºè‰∏ªÊâìËÉ∂Áâá.pdf\n",
      "  - ‰∏™‰∫∫ÁÆÄÂéÜË°®-ÂæêÂ≠êËØë.docx\n",
      "  - Â§™ÊûÅÂÖ¨Âè∏Âü∫Êú¨ÊÉÖÂÜµ‰ªãÁªç20210809.ppt\n",
      "  - 20220110.doc\n",
      "  - -2021Âπ¥1ÊúàÁâà.pdf\n",
      "  - Â∏ÇÂú∫ÂØπÂ§ñ2022-Êµ∑ÂçóÂÆâÊ¥µ.ppt\n",
      "  - ÂõõÂ∑ù‰∏§Âú∞È°πÁõÆÂêà‰ΩúÊ°ÜÊû∂ÂçèËÆÆ.pdf\n",
      "  - ÂõõÂ∑ù‰∏§Âú∞È°πÁõÆÂêà‰ΩúÊ°ÜÊû∂ÂçèËÆÆ.pdf\n",
      "  - ÂÆâÊ¥µ‰ø°ÊÅØ20220228.pdf\n",
      "  - ÂâçÁ´ØÈîÄÂîÆÂèçÈ¶àÈóÆÈ¢ò.doc\n",
      "  - ‰∏Ä‰ΩìÂåñÂÆâÂÖ®È°πÁõÆÂàùÊ≠•ËÆæËÆ°ÊñáÊ°£2b723eaa7742869ff370fd42f5b572f8.pdf\n",
      "  - ÈîÄÂîÆ‰ΩìÁ≥ªÈòü‰ºçË∞ÉÊï¥ÊñπÊ°à.docx\n",
      "  - ÁâπÊÆä‰∫∫Áæ§Êô∫ÊÖßÁÆ°ÁêÜ‰∫ßÂìÅÁÆÄ‰ªã2022.pdf\n",
      "  - Âè∏Ê≥ïÊô∫ÊÖßÁü´Ê≠£‰∫ßÂìÅ‰ªãÁªç2022.pdf\n",
      "  - v1.0.ppt.pdf\n",
      "  - Êô∫ÊÖßÁü´Ê≠£‰∫ßÂìÅÊä•‰ª∑Âçï202206-Êµ∑Âçó-Â∏ÇÂú∫ÊåáÂØº‰ª∑.pdf\n",
      "19.md:\n",
      "  - 6848748d-2881-4c26-b153-fcd5373d2f1c.png\n",
      "  - 0-6848748d-2881-4c26-b153-fcd5373d2f1c.png\n",
      "4.md:\n",
      "  - 330f554f-a3e6-4bd3-8b1b-d5949e1f30e8.png\n",
      "  - 0-330f554f-a3e6-4bd3-8b1b-d5949e1f30e8.png\n",
      "  - dd5b6a38-dc17-4122-a242-32006b381b3a.png\n",
      "  - 0-dd5b6a38-dc17-4122-a242-32006b381b3a.png\n",
      "  - 62ff30cf-de5f-4388-82aa-b69b0fd0f07c.png\n",
      "  - 0-62ff30cf-de5f-4388-82aa-b69b0fd0f07c.png\n",
      "  - Ë∂äÂçó‰∫∫Ê∞ëÂÖ¨ÂÆâÁîµËßÜANTV.docx\n",
      "  - f41b7574-57b4-4c9f-907c-2a3c48a56157.png\n",
      "  - 0-f41b7574-57b4-4c9f-907c-2a3c48a56157.png\n",
      "  - bcad4fdf-3771-4873-92fa-23240654118a.png\n",
      "  - 0-bcad4fdf-3771-4873-92fa-23240654118a.png\n",
      "  - fc27ce32-9c96-416c-9c38-84977255e0ba.png\n",
      "  - 0-fc27ce32-9c96-416c-9c38-84977255e0ba.png\n",
      "22.md:\n",
      "  - b0a4acaa-d768-4f6d-8e54-6d20f271bb7c.png\n",
      "  - 0-b0a4acaa-d768-4f6d-8e54-6d20f271bb7c.png\n",
      "  - 493542fc-495f-4756-8451-c4ed084d8bf7.png\n",
      "  - 0-493542fc-495f-4756-8451-c4ed084d8bf7.png\n",
      "26.md:\n",
      "  - ÂâçÁ´ØÈîÄÂîÆÂèçÈ¶àÈóÆÈ¢ò.doc\n",
      "  - ÂâçÁ´ØÈîÄÂîÆÂèçÈ¶àÈóÆÈ¢ò.doc\n",
      "36.md:\n",
      "  - ÊâãÊú∫Ë¥≠ÂΩ©ÂàÜÊûêÁÆÄÊä•.docx\n",
      "13.md:\n",
      "  - 987ba39a-cc1c-4367-8d6d-f5a49a940198.png\n",
      "  - 0-987ba39a-cc1c-4367-8d6d-f5a49a940198.png\n",
      "  - adaf869e-920a-4a17-91bd-e2ef3125c10e.png\n",
      "  - 0-adaf869e-920a-4a17-91bd-e2ef3125c10e.png\n",
      "  - 5ae9bdca-fdf9-4948-8c11-a9e400b331aa.png\n",
      "  - 0-5ae9bdca-fdf9-4948-8c11-a9e400b331aa.png\n",
      "  - 1b0dc208-d2bb-43ea-b744-534f3b759394.png\n",
      "  - 0-1b0dc208-d2bb-43ea-b744-534f3b759394.png\n",
      "  - 3556e54c-d418-447d-bb2a-43ac0408cc7a.png\n",
      "  - 0-3556e54c-d418-447d-bb2a-43ac0408cc7a.png\n",
      "37.md:\n",
      "  - Â§™ÊûÅÂÖ¨Âè∏Âü∫Êú¨ÊÉÖÂÜµ‰ªãÁªç20210809.ppt\n",
      "23.md:\n",
      "  - ÂæÆËΩØÈÇÆ‰ª∂ÂØÜÂèñÂπ≥Âè∞.7z\n",
      "  - 202301090144.pdf\n",
      "24.md:\n",
      "  - 96af60b3-299c-4e26-bca3-d9eb3e113b94.png\n",
      "  - 0-96af60b3-299c-4e26-bca3-d9eb3e113b94.png\n",
      "  - fcf90a92-794c-40c6-aa4f-8ea82f8bed51.png\n",
      "  - 0-fcf90a92-794c-40c6-aa4f-8ea82f8bed51.png\n",
      "  - 1afcf93d-50f1-4f1e-896d-87b0da7519f7.png\n",
      "  - 0-1afcf93d-50f1-4f1e-896d-87b0da7519f7.png\n",
      "  - fe221e78-67e4-4d88-b73d-e58a9943a036.png\n",
      "  - 0-fe221e78-67e4-4d88-b73d-e58a9943a036.png\n",
      "41.md:\n",
      "  - ÊÅ©‰ΩêÂ®±‰πê-14.2E-220726.docx\n",
      "10.md:\n",
      "  - e705d192-90ee-4fd1-9dcd-061958d1817f.png\n",
      "  - 0-e705d192-90ee-4fd1-9dcd-061958d1817f.png\n",
      "  - 5a84cde3-7175-4044-8c88-d4c883a8fd38.png\n",
      "  - 0-5a84cde3-7175-4044-8c88-d4c883a8fd38.png\n",
      "  - 4ea07c23-a1a6-411b-bcfb-552d095b66c9.png\n",
      "  - 0-4ea07c23-a1a6-411b-bcfb-552d095b66c9.png\n",
      "  - 79d9b7f2-cfe4-4615-9b75-8fea33fc0c9d.png\n",
      "  - 0-79d9b7f2-cfe4-4615-9b75-8fea33fc0c9d.png\n",
      "  - 6bcc0131-e4ad-421e-bb1f-d8ebe5eeec7b.png\n",
      "  - 0-6bcc0131-e4ad-421e-bb1f-d8ebe5eeec7b.png\n",
      "9.md:\n",
      "  - 32eb7662-f212-4811-a7c1-1cfeb121cd99.png\n",
      "  - 0-32eb7662-f212-4811-a7c1-1cfeb121cd99.png\n",
      "  - 5d4e3e02-1dfc-469e-8af9-8dbe2b9f1564.png\n",
      "  - 0-5d4e3e02-1dfc-469e-8af9-8dbe2b9f1564.png\n",
      "  - 70c63791-2797-4bf0-a778-ea08819aa9de.png\n",
      "  - 0-70c63791-2797-4bf0-a778-ea08819aa9de.png\n",
      "  - 0baba509-5e81-4b88-b509-843822d09e21.png\n",
      "  - 0-0baba509-5e81-4b88-b509-843822d09e21.png\n",
      "  - 129ac70f-8942-4ca7-b1f2-ddeaa3d984b5.png\n",
      "  - 0-129ac70f-8942-4ca7-b1f2-ddeaa3d984b5.png\n",
      "  - b9d9c584-5e21-4a49-952b-ffecca4eb91e.png\n",
      "  - 0-b9d9c584-5e21-4a49-952b-ffecca4eb91e.png\n",
      "  - ee47dfea-2626-4107-8ab3-4663167e0493.png\n",
      "  - 0-ee47dfea-2626-4107-8ab3-4663167e0493.png\n",
      "  - aa99f763-6849-4f6b-adf2-58f0cc2ed545.png\n",
      "  - 0-aa99f763-6849-4f6b-adf2-58f0cc2ed545.png\n",
      "  - b6eb1b15-cf99-475c-921f-f06e5c1019d4.png\n",
      "  - 0-b6eb1b15-cf99-475c-921f-f06e5c1019d4.png\n",
      "20.md:\n",
      "  - 785cc8c9-1225-4f93-b633-349bc5113512.png\n",
      "  - 0-785cc8c9-1225-4f93-b633-349bc5113512.png\n",
      "  - af93eff8-2973-4746-9041-b2223016b117.png\n",
      "  - 0-af93eff8-2973-4746-9041-b2223016b117.png\n",
      "  - b3ce4d51-6024-4b43-b0d2-d3faaf3c2879.png\n",
      "  - 0-b3ce4d51-6024-4b43-b0d2-d3faaf3c2879.png\n",
      "  - f313f521-80a1-4db5-a8a7-53d29ee09890.png\n",
      "  - 0-f313f521-80a1-4db5-a8a7-53d29ee09890.png\n",
      "15.md:\n",
      "  - 20211103-1.txt\n",
      "  - b8cea3b1-4dde-4438-9b1a-6faf690bbad0.png\n",
      "  - 0-b8cea3b1-4dde-4438-9b1a-6faf690bbad0.png\n",
      "21.md:\n",
      "  - 9c8c9989-2293-4e68-9ffe-6f7a5f14562f.png\n",
      "  - 0-9c8c9989-2293-4e68-9ffe-6f7a5f14562f.png\n",
      "11.md:\n",
      "  - 2bankinfo-5.zip\n",
      "7.md:\n",
      "  - 94b16e53-f035-4aa9-a76e-80bc6e936d10.png\n",
      "  - 0-94b16e53-f035-4aa9-a76e-80bc6e936d10.png\n",
      "  - 645dfc97-3268-4e1d-920d-4138545456fa.png\n",
      "  - 0-645dfc97-3268-4e1d-920d-4138545456fa.png\n",
      "  - 1cc570d8-cddb-401e-8c37-ef10c0e4841f.png\n",
      "  - 0-1cc570d8-cddb-401e-8c37-ef10c0e4841f.png\n",
      "2.md:\n",
      "  - 9a8077f5-ac41-491f-b192-6b4609324bda.png\n",
      "  - 0-9a8077f5-ac41-491f-b192-6b4609324bda.png\n",
      "  - de359f8d-0745-4a93-959a-d1a6c361e326.png\n",
      "  - 0-de359f8d-0745-4a93-959a-d1a6c361e326.png\n",
      "  - 383d824e-7588-4a92-84b7-fd953dd91cba.png\n",
      "  - 0-383d824e-7588-4a92-84b7-fd953dd91cba.png\n",
      "  - f0ce8a7b-909d-4fc5-ba13-ea66b2dc6448.png\n",
      "  - 0-f0ce8a7b-909d-4fc5-ba13-ea66b2dc6448.png\n",
      "  - b8b76b6d-a50e-4246-82ee-3c8a5dcd523e.png\n",
      "  - 0-b8b76b6d-a50e-4246-82ee-3c8a5dcd523e.png\n",
      "  - 4c74b697-0681-4223-9982-5ffaf4e98ed0.png\n",
      "  - 0-4c74b697-0681-4223-9982-5ffaf4e98ed0.png\n",
      "  - 300450bf-221e-4eeb-bdda-dc1115c947ea.png\n",
      "  - 0-300450bf-221e-4eeb-bdda-dc1115c947ea.png\n",
      "  - 0f319bf6-e667-4bac-a974-dfda1142e9ff.png\n",
      "  - 0-0f319bf6-e667-4bac-a974-dfda1142e9ff.png\n",
      "  - 1a20ded1-50fc-4153-9a95-e158eeb7199e.png\n",
      "  - 0-1a20ded1-50fc-4153-9a95-e158eeb7199e.png\n",
      "  - 5ef1d666-e19d-4570-b800-6693a4f680ee.png\n",
      "  - 0-5ef1d666-e19d-4570-b800-6693a4f680ee.png\n",
      "  - e07a9457-86f1-4f0f-86d7-8ea816b8d8d3.png\n",
      "  - 0-e07a9457-86f1-4f0f-86d7-8ea816b8d8d3.png\n",
      "  - 08a6bcd3-6477-4252-8f35-4f8f80d114f9.png\n",
      "  - 0-08a6bcd3-6477-4252-8f35-4f8f80d114f9.png\n",
      "  - 7150f512-e7a2-4f2c-86bc-58b671b25ba9.png\n",
      "  - 0-7150f512-e7a2-4f2c-86bc-58b671b25ba9.png\n",
      "  - 62583414-9e32-4d09-8989-b5fa32a98a81.png\n",
      "  - 0-62583414-9e32-4d09-8989-b5fa32a98a81.png\n",
      "  - 4ae9bf34-c16c-4684-aa92-fec65a151275.png\n",
      "  - 0-4ae9bf34-c16c-4684-aa92-fec65a151275.png\n",
      "  - c5f1d959-39d1-4176-9cb1-1fb6e8baedc3.png\n",
      "  - 0-c5f1d959-39d1-4176-9cb1-1fb6e8baedc3.png\n",
      "  - 6e9aced1-df28-4e57-b7c8-641609ff4450.png\n",
      "  - 0-6e9aced1-df28-4e57-b7c8-641609ff4450.png\n",
      "  - 6cbb3eeb-17e9-4af6-8da1-36eb6437f7bc.png\n",
      "  - 0-6cbb3eeb-17e9-4af6-8da1-36eb6437f7bc.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import ast\n",
    "from langchain.llms import Ollama\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "# Step 1: Initialize LLM\n",
    "llm2 = Ollama(model=\"llama3.1:8b\")\n",
    "\n",
    "# Step 2: Define the prompt template\n",
    "prompt_template_file_types = PromptTemplate(\n",
    "    input_variables=[\"content\"],\n",
    "    template=\"\"\"\n",
    "List the top 50 file extensions most commonly found in cybersecurity leaked data, including data from breaches, ransomware leaks, and dark web dumps. THINK LIKE A CYBERSECURITY EXPERT.\n",
    "Focus on file types that typically contain credentials, configurations, databases, personal data, internal documentation, archives, or images (e.g., screenshots of sensitive material). \n",
    "\n",
    "OUTPUT INSTRUCTIONS:\n",
    "ONLY OUTPUT the extensions as a clean Python list format, like [<'file_extension'>, <'file_extension'>, etc.] \n",
    "Don't include \".\" and ALWAYS use \"'\" in the list. \n",
    "Do not include any explanations, comments, or extra text. \n",
    "JUST GIVE THE LIST.\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# Step 3: Run the chain to get extensions\n",
    "chain = LLMChain(llm=llm2, prompt=prompt_template_file_types)\n",
    "llm_response = chain.run(content=\"\")\n",
    "\n",
    "# Step 4: Print the LLM output\n",
    "print(\"üîç LLM-generated file extensions list:\")\n",
    "print(llm_response)\n",
    "\n",
    "# Step 5: Parse LLM response into a Python list\n",
    "try:\n",
    "    # Extract only the list portion using regex\n",
    "    match = re.search(r\"\\[(.*?)\\]\", llm_response, re.DOTALL)\n",
    "    if match:\n",
    "        list_str = \"[\" + match.group(1) + \"]\"\n",
    "        common_extensions = ast.literal_eval(list_str)\n",
    "    else:\n",
    "        raise ValueError(\"‚ùå No list found in LLM response.\")\n",
    "except Exception as e:\n",
    "    raise ValueError(\"‚ùå Failed to parse LLM response into a list.\") from e\n",
    "\n",
    "# Step 6: Build dynamic regex\n",
    "ext_pattern = '|'.join(common_extensions)\n",
    "file_pattern = re.compile(r'[\\w\\-/\\.]{8,}\\.(?:' + ext_pattern + r')', re.IGNORECASE)\n",
    "\n",
    "# Step 7: Define chats path and extract files\n",
    "chats_path = 'I-Soon-data/md/chats'\n",
    "extracted_files_from_chats = {}\n",
    "\n",
    "for filename in os.listdir(chats_path):\n",
    "    if filename.endswith('.md'):\n",
    "        full_path = os.path.join(chats_path, filename)\n",
    "        with open(full_path, 'r', encoding='utf-8') as file:\n",
    "            content = file.read()\n",
    "            matches = file_pattern.findall(content)\n",
    "            if matches:\n",
    "                extracted_files_from_chats[filename] = matches\n",
    "\n",
    "# Step 8: Display results\n",
    "print(\"\\nüìÑ Extracted filenames from chats:\")\n",
    "for chat, files in extracted_files_from_chats.items():\n",
    "    print(f\"{chat}:\")\n",
    "    for f in files:\n",
    "        print(f\"  - {f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5857059",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "# *Search which files are in the leaked data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73d6162",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import Ollama\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "\n",
    "# Prepare data\n",
    "markdown_file_path = 'I-Soon-data/md/chats/2.md'\n",
    "with open(markdown_file_path, 'r', encoding='utf-8') as file:\n",
    "    lines = [line.strip() for line in file if line.strip()]\n",
    "\n",
    "# Prompt template\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"content\"],\n",
    "    template=\"\"\"\n",
    "You are a cybersecurity analyst with expert knowledge of file types and syntax used to reference files in markdown and related contexts.\n",
    "Your task is to analyze the given markdown content and extract all explicit file names with extensions (e.g., .exe, .pdf, .docx).\n",
    "Follow these guidelines:\n",
    "\t‚Ä¢\tOnly include file names that explicitly contain a valid extension.\n",
    "\t‚Ä¢\tConsider common patterns such as filename.ext, [text](filename.ext), src=\"filename.ext\", path/to/filename.ext, etc.\n",
    "\t‚Ä¢\tRecognize contextual clues like source, reference, include, or links that point to files.\n",
    "\t‚Ä¢\tUse your knowledge of the top 50 most common file extensions (e.g., .txt, .pdf, .jpg, .docx, .exe, .zip, etc.) to guide detection.\n",
    "\t‚Ä¢\tDo not infer or fabricate file names based on ambiguous text. Do not extract names without a clear extension.\n",
    "\t‚Ä¢\tOutput only: a single line list of the detected file names with extensions, separated by commas. No explanation or commentary.\n",
    "Content:\n",
    "{content}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# File name regex\n",
    "file_regex = re.compile(r'\\b[\\w\\-]+(?:\\.[\\w\\-]+)*\\.\\w{2,6}\\b')\n",
    "\n",
    "# Worker function\n",
    "def process_line(line_text):\n",
    "    try:\n",
    "        # Create LLM inside the process\n",
    "        llm = Ollama(model=\"llama3.1:70b\")\n",
    "        chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "        response = chain.run(content=line_text)\n",
    "        return file_regex.findall(response)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error: {e}\")\n",
    "        return []\n",
    "\n",
    "# Run with multiprocessing\n",
    "found_files = []\n",
    "max_workers = 4  # Based on CPU/RAM; try 2‚Äì8 depending on load\n",
    "\n",
    "with ProcessPoolExecutor(max_workers=max_workers) as executor:\n",
    "    futures = [executor.submit(process_line, line) for line in lines]\n",
    "\n",
    "    for future in as_completed(futures):\n",
    "        matches = future.result()\n",
    "        found_files.extend([m.lower() for m in matches])\n",
    "\n",
    "# Final output\n",
    "unique_files = sorted(set(found_files))\n",
    "print(\"\\nüéØ Unique filenames found:\")\n",
    "for f in unique_files:\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a55a603e-103a-46c0-9dcc-8c72023cacb8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory 'I-Soon-data' has been deleted.\n"
     ]
    }
   ],
   "source": [
    "# import shutil\n",
    "# import os\n",
    "\n",
    "# # Directory to delete\n",
    "# EXTRACT_DIR = 'I-Soon-data'\n",
    "\n",
    "# # Check if the directory exists and delete it\n",
    "# if os.path.isdir(EXTRACT_DIR):\n",
    "#     shutil.rmtree(EXTRACT_DIR)\n",
    "#     print(f\"Directory '{EXTRACT_DIR}' has been deleted.\")\n",
    "# else:\n",
    "#     print(f\"Directory '{EXTRACT_DIR}' does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c242f8e-af9c-488e-9a4a-92bdc06a8ec7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (IsoonAI)",
   "language": "python",
   "name": "isoonai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

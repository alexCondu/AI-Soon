{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08427a84-31f9-4bcf-875e-22b2e6497608",
   "metadata": {
    "user_expressions": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/IsoonAI/bin/python\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "144"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "\n",
    "import os\n",
    "os.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "879be4cb",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkout git\n",
      "kernel is working\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import subprocess\n",
    "import json\n",
    "import pandas as pd\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "import shutil\n",
    "\n",
    "ZIP_PATH = '0.zip'\n",
    "EXTRACT_DIR = 'I-Soon-data'     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e6feb79",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted archive to 'I-Soon-data'\n"
     ]
    }
   ],
   "source": [
    "if not os.path.isdir(EXTRACT_DIR):\n",
    "    with zipfile.ZipFile(ZIP_PATH, 'r') as zip_ref:\n",
    "        zip_ref.extractall(EXTRACT_DIR)\n",
    "    print(f\"Extracted archive to '{EXTRACT_DIR}'\")\n",
    "else:\n",
    "    print(f\"Extraction directory '{EXTRACT_DIR}' already exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325a01d8",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "# **DATA TYPE CATEGORIZATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dec65000",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted: I-Soon-data/__MACOSX\n"
     ]
    }
   ],
   "source": [
    "# Parent directory\n",
    "parent_directory = \"I-Soon-data\"\n",
    "\n",
    "# Full path to the __MACOSX folder\n",
    "macosx_folder = os.path.join(parent_directory, \"__MACOSX\")\n",
    "\n",
    "# Check if __MACOSX exists and remove it - creates issues when analyzing the data, and its not needed, made automatically by MacOS\n",
    "if os.path.exists(macosx_folder) and os.path.isdir(macosx_folder):\n",
    "    shutil.rmtree(macosx_folder)\n",
    "    print(f\"Deleted: {macosx_folder}\")\n",
    "else:\n",
    "    print(f\"Folder not found: {macosx_folder}\")\n",
    "\n",
    "# Organize files by extension into subfolders\n",
    "for root, dirs, files in os.walk(parent_directory):\n",
    "    for file in files:\n",
    "        # Skip hidden files and __MACOSX if any reappear\n",
    "        if file.startswith('.') or '__MACOSX' in root:\n",
    "            continue\n",
    "\n",
    "        # Get the file extension (in lowercase, without the dot)\n",
    "        file_extension = os.path.splitext(file)[1].lower().lstrip('.')\n",
    "        if not file_extension:\n",
    "            file_extension = \"no_extension\"\n",
    "\n",
    "        # Define the new subfolder path\n",
    "        subfolder_path = os.path.join(parent_directory, file_extension)\n",
    "\n",
    "        # Create the subfolder if it doesn't exist\n",
    "        os.makedirs(subfolder_path, exist_ok=True)\n",
    "\n",
    "        # Define source and destination paths\n",
    "        source_path = os.path.join(root, file)\n",
    "        destination_path = os.path.join(subfolder_path, file)\n",
    "\n",
    "        # Move the file if source and destination are not the same\n",
    "        if os.path.abspath(source_path) != os.path.abspath(destination_path):\n",
    "            shutil.move(source_path, destination_path)\n",
    "\n",
    "# Remove any empty folders within the parent directory\n",
    "for dirpath, dirnames, filenames in os.walk(parent_directory, topdown=False):\n",
    "    if not dirnames and not filenames:\n",
    "        try:\n",
    "            os.rmdir(dirpath)\n",
    "            print(f\"Removed empty folder: {dirpath}\")\n",
    "        except OSError:\n",
    "            pass  # Ignore errors (e.g., if directory is not empty due to permissions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75417f54",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "# **Markdown File Classification Using Local LLM (Ollama + LangChain)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9397264",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Classifying files: 0it [00:00, ?it/s]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "import concurrent.futures\n",
    "from langchain.llms import Ollama\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from tqdm import tqdm\n",
    "\n",
    "# LLM Prompt and model\n",
    "\n",
    "llm = Ollama(model=\"llama3.1:8b\")\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"content\"],\n",
    "    template=\"\"\"\n",
    "You are analyzing the content of a Markdown (.md) file.\n",
    "\n",
    "Markdown content:\n",
    "\\\"\\\"\\\"\n",
    "{content}\n",
    "\\\"\\\"\\\"\n",
    "\n",
    "1. Classify the content into one of the following categories ONLY: chats, images, other.\n",
    "2. State your confidence in the classification as one of: high, medium, or low.\n",
    "3. I will have to make a csv, please give me a list of headers based on the content. E.g. \"[<header_name>, <heaer_name2>, etc.]\n",
    "Respond in the following format:\n",
    "Category: <chats|images|other>\n",
    "Confidence: <high|medium|low>\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "\n",
    "# As the documents are long, the files are pre-processed to the first 20 lines so the AI can quickly draw a conclusion on its contents\n",
    "\n",
    "def preprocess_first_20_lines(file_path):\n",
    "    try:\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            lines = [line.strip() for _, line in zip(range(20), f)]\n",
    "            content = \" \".join(lines)\n",
    "        return os.path.basename(file_path), content\n",
    "    except Exception:\n",
    "        return os.path.basename(file_path), \"\"\n",
    "\n",
    "# Load .md Files \n",
    "\n",
    "md_dir = \"I-Soon-data/md\"\n",
    "md_files = glob.glob(os.path.join(md_dir, \"*.md\"))\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    file_data = list(executor.map(preprocess_first_20_lines, md_files))\n",
    "\n",
    "# Classify Each File and Move in Afferent Folders\n",
    "\n",
    "valid_categories = {\"chats\", \"images\", \"other\"}\n",
    "results_log = []\n",
    "\n",
    "for file_name, content in tqdm(file_data, desc=\"Classifying files\"):\n",
    "    if not content:\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        response = chain.run(content=content).strip().lower()\n",
    "        lines = response.splitlines()\n",
    "\n",
    "        category = next((line.replace(\"category:\", \"\").strip() for line in lines if line.startswith(\"category:\")), \"\")\n",
    "        confidence = next((line.replace(\"confidence:\", \"\").strip() for line in lines if line.startswith(\"confidence:\")), \"\")\n",
    "\n",
    "        if category not in valid_categories:\n",
    "            category = \"other\"\n",
    "\n",
    "        # Destination folder *within* the md_dir\n",
    "        category_path = os.path.join(md_dir, category)\n",
    "        os.makedirs(category_path, exist_ok=True)\n",
    "\n",
    "        # Move file into category folder\n",
    "        src_path = os.path.join(md_dir, file_name)\n",
    "        dst_path = os.path.join(category_path, file_name)\n",
    "\n",
    "        if os.path.exists(src_path):\n",
    "            shutil.move(src_path, dst_path)\n",
    "\n",
    "        results_log.append({\n",
    "            \"file\": file_name,\n",
    "            \"category\": category,\n",
    "            \"confidence\": confidence\n",
    "        })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process {file_name}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d774b090-41d0-4075-b1b7-300e14f15311",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "# **Identify CSV Headers from Chat Files with LLM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1544cd35-5830-4ede-b1a1-096fbadffe73",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_260/64538800.py:10: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.\n",
      "  llm = Ollama(model=\"llama3.1:8b\")\n",
      "/tmp/ipykernel_260/64538800.py:27: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chain = LLMChain(llm=llm, prompt=prompt_template)\n",
      "Processing Markdown Files:   0%|          | 0/39 [00:00<?, ?it/s]/tmp/ipykernel_260/64538800.py:51: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = chain.run(content=content).strip()\n",
      "Processing Markdown Files: 100%|██████████| 39/39 [01:08<00:00,  1.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Time', 'From', 'To', 'Message']\n",
      "['Time', 'From', 'To', 'Message']\n",
      "['Time', 'From', 'To', 'Message']\n",
      "['Time', 'From', 'To', 'Message']\n",
      "['Time', 'From', 'To', 'Message']\n",
      "['Time', 'From', 'To', 'Message']\n",
      "['Time', 'From', 'To', 'Message']\n",
      "['Time', 'From', 'To', 'Message']\n",
      "['Time', 'From', 'To', 'Message']\n",
      "['Time', 'From', 'To', 'Message']\n",
      "['Time', 'From', 'To', 'Message']\n",
      "['Time', 'From', 'To', 'Message']\n",
      "['Time', 'From', 'To', 'Message']\n",
      "['Time', 'From', 'To', 'Message']\n",
      "['Time', 'From', 'To', 'Message']\n",
      "['Time', 'From', 'To', 'Message']\n",
      "['Time', 'From', 'To', 'Message']\n",
      "['Time', 'From', 'To', 'Message']\n",
      "['Time', 'From', 'To', 'Message']\n",
      "['Time', 'From', 'To', 'Message']\n",
      "['Time', 'From', 'To', 'Message']\n",
      "['Time', 'From', 'To', 'Message']\n",
      "['Time', 'From', 'To', 'Message']\n",
      "['Time', 'From', 'To', 'Message']\n",
      "['Time', 'From', 'To', 'Message']\n",
      "['Time', 'From', 'To', 'Message']\n",
      "['Time', 'From', 'To', 'Message']\n",
      "['Time', 'From', 'To', 'Message']\n",
      "['Time', 'From', 'To', 'Message']\n",
      "['Time', 'From', 'To', 'Message']\n",
      "['Time', 'From', 'To', 'Message']\n",
      "['Time', 'From', 'To', 'Message']\n",
      "['Time', 'From', 'To', 'Message']\n",
      "['Time', 'From (ID)', 'To (ID)', 'Message']\n",
      "['Time', 'From', 'To', 'Message']\n",
      "['Time', 'From', 'To', 'Message']\n",
      "['Time', 'From', 'To', 'Message']\n",
      "['Time', 'From', 'To', 'Message']\n",
      "['Time', 'From', 'To', 'Message']\n",
      "Combined Headers:\n",
      " ['Time', 'From', 'To', 'Message']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "from langchain.llms import Ollama\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "# LLM prompt and model\n",
    "\n",
    "llm = Ollama(model=\"llama3.1:8b\")\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"content\"],\n",
    "    template=\"\"\"\n",
    "You are analyzing the content of a Markdown (.md) file.\n",
    "\n",
    "Markdown content:\n",
    "\\\"\\\"\\\"\n",
    "{content}\n",
    "\\\"\\\"\\\"\n",
    "\n",
    "Give a list of CSV headers that would best represent this data if stored in tabular form.\n",
    "Respond ONLY with a Python-style list, like this: [\"header1\", \"header2\", \"header3\"]\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "\n",
    "# Shortened to the first 20 lines\n",
    "def get_first_20_lines(filepath):\n",
    "    try:\n",
    "        with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "            return \" \".join([line.strip() for _, line in zip(range(20), f)])\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {filepath}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "# Process All Files with Progress Bar\n",
    "\n",
    "def extract_headers_from_folder(folder_path):\n",
    "    md_files = glob.glob(os.path.join(folder_path, \"*.md\"))\n",
    "    file_headers_map = {}\n",
    "\n",
    "    for file_path in tqdm(md_files, desc=\"Processing Markdown Files\"):\n",
    "        content = get_first_20_lines(file_path)\n",
    "        if not content:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            response = chain.run(content=content).strip()\n",
    "            headers = eval(response) if response.startswith(\"[\") else []\n",
    "            if isinstance(headers, list) and all(isinstance(h, str) for h in headers):\n",
    "                file_headers_map[os.path.basename(file_path)] = headers\n",
    "            else:\n",
    "                file_headers_map[os.path.basename(file_path)] = []\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to process {file_path}: {e}\")\n",
    "            file_headers_map[os.path.basename(file_path)] = []\n",
    "\n",
    "    return file_headers_map\n",
    "\n",
    "# Run on Folder\n",
    "\n",
    "folder_path = \"I-Soon-data/md/chats\"  # Update this path as needed\n",
    "results = extract_headers_from_folder(folder_path)\n",
    "\n",
    "# Display Header Lists \n",
    "for headers in results.values():\n",
    "    print(headers)\n",
    "\n",
    "    \n",
    "# Now we give the extarcted LLM headers to another LLM to create one combined list with headers for the MD to CSV transformation.\n",
    "combine_prompt_template = PromptTemplate(\n",
    "    input_variables=[\"lists\"],\n",
    "    template=\"\"\"\n",
    "You are given multiple Python lists of CSV headers.\n",
    "\n",
    "Here are the lists:\n",
    "{lists}\n",
    "\n",
    "Combine all the headers into a single Python-style list. Remove duplicates and keep it logically organized. \n",
    "Think if the headers mean the same thing, if they mean the same thing, just keep the one that is mostly common.\n",
    "Respond ONLY with a Python list, like this: [\"header1\", \"header2\", \"header3\"]\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# Create new chain\n",
    "combine_chain = LLMChain(llm=llm, prompt=combine_prompt_template)\n",
    "\n",
    "# Stringify the list for the LLM\n",
    "all_lists_str = str(list(results.values()))\n",
    "\n",
    "# Run the new prompt\n",
    "try:\n",
    "    combined_response = combine_chain.run(lists=all_lists_str).strip()\n",
    "    combined_headers = eval(combined_response) if combined_response.startswith(\"[\") else []\n",
    "    print(\"Combined Headers:\\n\", combined_headers)\n",
    "except Exception as e:\n",
    "    print(f\"Failed to combine headers: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7d796c-9397-44ea-b1b6-5ddd1b4bf5d6",
   "metadata": {},
   "source": [
    "# **Converting Chat Content to CSV with LLM-Generated Headers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73b726a9-26ea-453c-9df2-03923d988a8c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM prompt output from the above cell: ['Time', 'From', 'To', 'Message']\n",
      "📦 Processing 45 batches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches: 100%|██████████| 45/45 [08:04<00:00, 10.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ CSV saved to: I-Soon-data/md/chats/10.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "from langchain.llms import Ollama\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "# LLM prompt and model\n",
    "llm = Ollama(model=\"qwen2.5:14b\")\n",
    "\n",
    "csv_prompt = PromptTemplate(\n",
    "    input_variables=[\"content\", \"headers\"],\n",
    "    template=\"\"\"\n",
    "You are converting chat content into structured CSV format. Look at the headers provided below.\n",
    "\n",
    "Here is the full chat content:\n",
    "\\\"\\\"\\\"\n",
    "{content}\n",
    "\\\"\\\"\\\"\n",
    "\n",
    "Use the following CSV headers:\n",
    "{headers}\n",
    "\n",
    "Look at the content and see what the message is composed of.\n",
    "Based on its composition, spread the contents of the message into the {headers}. Sometimes messages might span multiple lines.\n",
    "ALWAYS look at the syntax of the file to determine where a message ends.\n",
    "Output ONLY valid CSV with the following format:\n",
    "header1,header2,header3\n",
    "value1,value2,value3\n",
    "value4,value5,value6\n",
    "and so on\n",
    "\n",
    "Do NOT include any explanation or extra text. Just the CSV content.\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "print(f\"LLM prompt output from the above cell: {combined_headers}\")\n",
    "csv_chain = LLMChain(llm=llm, prompt=csv_prompt)\n",
    "\n",
    "md_path = \"I-Soon-data/md/chats/10.md\"  \n",
    "headers = combined_headers\n",
    "\n",
    "# To speed up, we turn the document into batches. For future find a formula to split the batches according to the threads.\n",
    "def read_file_in_batches(filepath, batch_size=10):\n",
    "    try:\n",
    "        with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "            batch = []\n",
    "            for line in f:\n",
    "                batch.append(line.strip())\n",
    "                if len(batch) >= batch_size:\n",
    "                    yield \"\\n\".join(batch)\n",
    "                    batch = []\n",
    "            if batch:\n",
    "                yield \"\\n\".join(batch)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file: {e}\")\n",
    "\n",
    "# CSV creation\n",
    "def write_csv_to_same_folder(md_path, csv_content):\n",
    "    csv_path = md_path.replace(\".md\", \".csv\")\n",
    "    try:\n",
    "        with open(csv_path, \"w\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "            f.write(csv_content)\n",
    "        print(f\"✅ CSV saved to: {csv_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Failed to write CSV: {e}\")\n",
    "\n",
    "# Run the model - via the LLM chain\n",
    "if os.path.exists(md_path) and headers:\n",
    "    final_csv_output = []\n",
    "    batches = list(read_file_in_batches(md_path, batch_size=10))\n",
    "\n",
    "    print(f\"📦 Processing {len(batches)} batches...\")\n",
    "\n",
    "    for i, batch in enumerate(tqdm(batches, desc=\"Processing Batches\")):\n",
    "        try:\n",
    "            csv_output = csv_chain.run(content=batch, headers=\", \".join(headers)).strip()\n",
    "            # Remove header rows after the first batch\n",
    "            if i > 0:\n",
    "                csv_output = \"\\n\".join(csv_output.splitlines()[1:])\n",
    "            final_csv_output.append(csv_output)\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error processing batch {i+1}: {e}\")\n",
    "\n",
    "    full_csv = \"\\n\".join(final_csv_output)\n",
    "    write_csv_to_same_folder(md_path, full_csv)\n",
    "else:\n",
    "    print(\"⚠️ Missing file or headers. Cannot process the file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c65992-9317-4fe9-926c-5c9fd32bcbba",
   "metadata": {
    "tags": []
   },
   "source": [
    "# **Search for any Documents in the Chats (LLM + Threading) - Tested on Small to Medium Files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a73d6162",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔍 Processing:   0%|                                                         | 0/65 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Starting with 72 threads and batch size 7 on 449 lines...\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 80\u001b[39m\n\u001b[32m     79\u001b[39m futures = [executor.submit(process_batch, i, batch) \u001b[38;5;28;01mfor\u001b[39;00m i, batch \u001b[38;5;129;01min\u001b[39;00m batch_lines(lines, batch_size)]\n\u001b[32m---> \u001b[39m\u001b[32m80\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfuture\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mas_completed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     81\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfuture\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.11/concurrent/futures/_base.py:243\u001b[39m, in \u001b[36mas_completed\u001b[39m\u001b[34m(fs, timeout)\u001b[39m\n\u001b[32m    239\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m(\n\u001b[32m    240\u001b[39m                 \u001b[33m'\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m (of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m) futures unfinished\u001b[39m\u001b[33m'\u001b[39m % (\n\u001b[32m    241\u001b[39m                 \u001b[38;5;28mlen\u001b[39m(pending), total_futures))\n\u001b[32m--> \u001b[39m\u001b[32m243\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mevent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    245\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m waiter.lock:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.11/threading.py:629\u001b[39m, in \u001b[36mEvent.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    628\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[32m--> \u001b[39m\u001b[32m629\u001b[39m     signaled = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cond\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    630\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.11/threading.py:327\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    326\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m327\u001b[39m     \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    328\u001b[39m     gotit = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 78\u001b[39m\n\u001b[32m     75\u001b[39m \u001b[38;5;66;03m# Start threaded batch processing\u001b[39;00m\n\u001b[32m     76\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m🚀 Starting with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_threads\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m threads and batch size \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(lines)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m lines...\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m \u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mThreadPoolExecutor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_workers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_threads\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mexecutor\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mexecutor\u001b[49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_lines\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlines\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfuture\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mas_completed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.11/concurrent/futures/_base.py:647\u001b[39m, in \u001b[36mExecutor.__exit__\u001b[39m\u001b[34m(self, exc_type, exc_val, exc_tb)\u001b[39m\n\u001b[32m    646\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, exc_type, exc_val, exc_tb):\n\u001b[32m--> \u001b[39m\u001b[32m647\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mshutdown\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    648\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.11/concurrent/futures/thread.py:235\u001b[39m, in \u001b[36mThreadPoolExecutor.shutdown\u001b[39m\u001b[34m(self, wait, cancel_futures)\u001b[39m\n\u001b[32m    233\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m wait:\n\u001b[32m    234\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._threads:\n\u001b[32m--> \u001b[39m\u001b[32m235\u001b[39m         \u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.11/threading.py:1119\u001b[39m, in \u001b[36mThread.join\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   1116\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mcannot join current thread\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1118\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1119\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_wait_for_tstate_lock\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1120\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1121\u001b[39m     \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[32m   1122\u001b[39m     \u001b[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[32m   1123\u001b[39m     \u001b[38;5;28mself\u001b[39m._wait_for_tstate_lock(timeout=\u001b[38;5;28mmax\u001b[39m(timeout, \u001b[32m0\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.11/threading.py:1139\u001b[39m, in \u001b[36mThread._wait_for_tstate_lock\u001b[39m\u001b[34m(self, block, timeout)\u001b[39m\n\u001b[32m   1136\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m   1138\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1139\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mlock\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m   1140\u001b[39m         lock.release()\n\u001b[32m   1141\u001b[39m         \u001b[38;5;28mself\u001b[39m._stop()\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import re\n",
    "import threading\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from langchain.llms import Ollama\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "\n",
    "# Read the chat file\n",
    "with open('I-Soon-data/md/chats/10.md', 'r', encoding='utf-8') as f:\n",
    "    lines = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "# Split lines into batches\n",
    "def batch_lines(lines, batch_size):\n",
    "    for i in range(0, len(lines), batch_size):\n",
    "        yield i, lines[i:i+batch_size]\n",
    "\n",
    "n_threads = 72  \n",
    "batch_size = math.ceil(len(lines)/n_threads)\n",
    "        \n",
    "# Regex and shared resources to minimze hallucinations from the LLM\n",
    "file_regex = re.compile(r'\\b[\\w\\-]+(?:\\.[\\w\\-]+)*\\.\\w{2,6}\\b')\n",
    "found_files = []\n",
    "lock = threading.Lock()\n",
    "\n",
    "# Prompt template\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"content\"],\n",
    "    template=\"\"\"\n",
    "You are a cybersecurity analyst with expert knowledge of file types and syntax used to reference files in certain documents and related contexts.\n",
    "Your task is to analyze the given content and extract all explicit file names with extensions.\n",
    "Follow these guidelines:\n",
    "    • Only include file names that explicitly contain a valid extension.\n",
    "    • Consider common patterns such as filename.ext, [text](filename.ext), src=\"filename.ext\", path/to/filename.ext, etc.\n",
    "    • Recognize contextual clues like source, reference, include, or links that point to files.\n",
    "    • Do not infer or fabricate file names based on ambiguous text. Do not extract names without a clear extension.\n",
    "    • Use your knowledge of the top 50 most common file extensions to guide detection.\n",
    "    • Output only: a single line list of the detected file names with extensions, separated by commas. No explanation or commentary.\n",
    "Content:\n",
    "{content}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# Progress bar\n",
    "progress_bar = tqdm(total=(len(lines) // batch_size) + 1, desc=\"🔍 Processing\", ncols=100)\n",
    "\n",
    "# Worker function for each batch\n",
    "def process_batch(start_idx: int, lines_batch: list[str]):\n",
    "    thread_id = threading.get_ident()\n",
    "    try:\n",
    "        llm = Ollama(model=\"qwen2.5:14b\", temperature = 0.7)\n",
    "        chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "        \n",
    "        content = \"\\n\".join(lines_batch)\n",
    "        start_time = time.time()\n",
    "        response = chain.run(content=content)\n",
    "        duration = time.time() - start_time\n",
    "        \n",
    "        # To minimize hallucinations from the LLM, we call the RegEx defined above to ensure correct file formats\n",
    "        matches = file_regex.findall(response)\n",
    "        match_count = len(matches)\n",
    "\n",
    "        if matches:\n",
    "            with lock:\n",
    "                found_files.extend([m.strip().lower() for m in matches])\n",
    "\n",
    "        print(f\"[Thread-{thread_id}] ✅ Batch starting at line {start_idx + 1} done in {duration:.2f}s | Matches: {match_count}\")\n",
    "    except Exception as e:\n",
    "        print(f\"[Thread-{thread_id}] ❌ Error on batch starting at line {start_idx + 1}: {e}\")\n",
    "    finally:\n",
    "        progress_bar.update(1)\n",
    "\n",
    "# Start threaded batch processing\n",
    "print(f\"\\n🚀 Starting with {n_threads} threads and batch size {batch_size} on {len(lines)} lines...\\n\")\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=n_threads) as executor:\n",
    "    futures = [executor.submit(process_batch, i, batch) for i, batch in batch_lines(lines, batch_size)]\n",
    "    for future in as_completed(futures):\n",
    "        future.result()\n",
    "\n",
    "progress_bar.close()\n",
    "\n",
    "# Output results\n",
    "print(\"\\n🎯 Unique filenames found:\")\n",
    "unique_files = sorted(set(found_files))\n",
    "for f in unique_files:\n",
    "    print(f)\n",
    "\n",
    "print(f\"\\n✅ Total unique files found: {len(unique_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "840a5480-3e74-499f-b0ac-e2f1a3419ee5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Thread 2:\n",
      "Here's one!\n",
      "\n",
      "Did you know that there is a type of jellyfish that is immortal?! The Turritopsis dohrnii, also known as the \"immortal jellyfish,\" is a species of jellyfish that can transform its body into a younger state through a process called transdifferentiation. This means it can essentially revert back to its polyp stage, which is the juvenile form of a jellyfish, and then grow back into an adult again! This process can be repeated indefinitely, making Turritopsis dohrnii theoretically immortal!\n",
      "\n",
      "Isn't that just mind-blowing?\n",
      "\n",
      "\n",
      "Thread 1:\n",
      "I've got one!\n",
      "\n",
      "Here's a fun fact: Did you know that there is a type of jellyfish that is immortal?! The Turritopsis dohrnii, also known as the \"immortal jellyfish,\" is a species of jellyfish that can transform its body into a younger state through a process called transdifferentiation. This means it can essentially revert back to its polyp stage, which is the juvenile form of a jellyfish, and then grow back into an adult again! This process can be repeated indefinitely, making Turritopsis dohrnii theoretically immortal.\n",
      "\n",
      "Isn't that just mind-blowing?\n",
      "\n",
      "\n",
      "Thread 6:\n",
      "I've got one!\n",
      "\n",
      "Here's a fun fact: Did you know that there is a type of jellyfish that is immortal?!\n",
      "\n",
      "The Turritopsis dohrnii, also known as the \"immortal jellyfish,\" is a species of jellyfish that can transform its body into a younger state through a process called transdifferentiation. This means it can essentially revert back to its polyp stage, which is the juvenile form of a jellyfish, and then grow back into an adult again! This process can be repeated indefinitely, making Turritopsis dohrnii theoretically \"immortal.\"\n",
      "\n",
      "Isn't that mind-blowing?\n",
      "\n",
      "\n",
      "Thread 8:\n",
      "I've got a good one!\n",
      "\n",
      "Here's a fun fact about science:\n",
      "\n",
      "Did you know that there is a type of jellyfish that is immortal?! The Turritopsis dohrnii, also known as the \"immortal jellyfish,\" is a species of jellyfish that can transform its body into a younger state through a process called transdifferentiation. This means it can essentially revert back to its polyp stage, which is the juvenile form of a jellyfish, and then grow back into an adult again! It can do this an infinite number of times, making it theoretically \"immortal\"!\n",
      "\n",
      "Isn't that mind-blowing?\n",
      "\n",
      "\n",
      "Thread 7:\n",
      "I've got one!\n",
      "\n",
      "Here's a fun fact about science: Did you know that there is a type of jellyfish that is immortal?! The Turritopsis dohrnii, also known as the \"immortal jellyfish,\" is a species of jellyfish that can transform its body into a younger state through a process called transdifferentiation. This means that it can essentially revert back to its polyp stage, which is the juvenile form of a jellyfish, and then grow back into an adult again. This process can be repeated indefinitely, making the Turritopsis dohrnii theoretically immortal!\n",
      "\n",
      "Isn't that mind-blowing?\n",
      "\n",
      "\n",
      "Thread 5:\n",
      "Here's one!\n",
      "\n",
      "Did you know that there is a species of jellyfish that is immortal?! The Turritopsis dohrnii, also known as the \"immortal jellyfish,\" is a type of jellyfish that can transform its body into a younger state through a process called transdifferentiation. This means it can essentially revert back to its polyp stage, which is the juvenile form of a jellyfish, and then grow back into an adult again! This process can be repeated indefinitely, making Turritopsis dohrnii theoretically \"immortal\"!\n",
      "\n",
      "Isn't that just mind-blowing?\n",
      "\n",
      "Would you like more fun facts about science?\n",
      "\n",
      "\n",
      "Thread 4:\n",
      "Here's one:\n",
      "\n",
      "Did you know that there is a type of jellyfish that is immortal?\n",
      "\n",
      "The Turritopsis dohrnii, also known as the \"immortal jellyfish,\" is a species of jellyfish that can transform its body into a younger state through a process called transdifferentiation. This means that it can essentially revert back to its polyp stage, which is the juvenile form of a jellyfish, and then grow back into an adult again!\n",
      "\n",
      "This process allows Turritopsis dohrnii to bypass the normal process of aging and death, making it theoretically \"immortal.\" Isn't that mind-blowing?\n",
      "\n",
      "(Just a fun fact, not meant to be taken scientifically accurate - but still cool, right?)\n",
      "\n",
      "\n",
      "Thread 3:\n",
      "I've got one!\n",
      "\n",
      "Here's a fun fact: Did you know that there is a type of jellyfish that is immortal?!\n",
      "\n",
      "The Turritopsis dohrnii, also known as the \"immortal jellyfish,\" is a species of jellyfish that can transform its body into a younger state through a process called transdifferentiation. This means that it can essentially revert back to its polyp stage (the juvenile form) and then grow back into an adult again!\n",
      "\n",
      "This process allows Turritopsis dohrnii to bypass the normal process of aging and death, making it theoretically \"immortal.\" It's like they have a reset button built-in!\n",
      "\n",
      "Isn't that just mind-blowing?\n",
      "\n",
      "What do you think? Would you like to learn more about this amazing jellyfish or explore another fun science fact?\n",
      "\n",
      "\n",
      "Thread 9:\n",
      "Here's one:\n",
      "\n",
      "Did you know that there is a type of jellyfish that is immortal?! The Turritopsis dohrnii, also known as the \"immortal jellyfish,\" is a species of jellyfish that can transform its body into a younger state through a process called transdifferentiation. This means it can essentially revert back to its polyp stage, which is the juvenile form of a jellyfish, and then grow back into an adult again. This process can be repeated indefinitely, making Turritopsis dohrnii theoretically immortal!\n",
      "\n",
      "Isn't that mind-blowing?\n",
      "\n",
      "\n",
      "Thread 15:\n",
      "Here's one:\n",
      "\n",
      "Did you know that there is a type of jellyfish that is immortal?! The Turritopsis dohrnii, also known as the \"immortal jellyfish,\" is a species of jellyfish that can transform its body into a younger state through a process called transdifferentiation. This means that it can essentially revert back to its polyp stage, which is the juvenile form of a jellyfish, and then grow back into an adult again. This process can be repeated indefinitely, making Turritopsis dohrnii theoretically \"immortal\"!\n",
      "\n",
      "Isn't that just mind-blowing?\n",
      "\n",
      "\n",
      "Thread 14:\n",
      "Here's one!\n",
      "\n",
      "Did you know that there is a type of jellyfish that is immortal?! The Turritopsis dohrnii, also known as the \"immortal jellyfish,\" is a species of jellyfish that can transform its body into a younger state through a process called transdifferentiation. This means it can essentially revert back to its polyp stage, which is the juvenile form of a jellyfish, and then grow back into an adult again! This process can be repeated indefinitely, making Turritopsis dohrnii theoretically \"immortal.\"\n",
      "\n",
      "Isn't that mind-blowing?\n",
      "\n",
      "Want more fun science facts?\n",
      "\n",
      "\n",
      "Thread 13:\n",
      "Here's one:\n",
      "\n",
      "Did you know that there is a type of jellyfish that is immortal?! The Turritopsis dohrnii, also known as the \"immortal jellyfish,\" is a species of jellyfish that can transform its body into a younger state through a process called transdifferentiation. This means that it can essentially revert back to its polyp stage, which is the juvenile form of a jellyfish, and then grow back into an adult again. This process can be repeated indefinitely, making Turritopsis dohrnii theoretically immortal!\n",
      "\n",
      "Isn't that cool?\n",
      "\n",
      "\n",
      "Thread 10:\n",
      "I've got one!\n",
      "\n",
      "Here's a fun fact about science:\n",
      "\n",
      "Did you know that there is a type of jellyfish that is immortal?!\n",
      "\n",
      "The Turritopsis dohrnii, also known as the \"immortal jellyfish,\" is a species of jellyfish that can transform its body into a younger state through a process called transdifferentiation. This means that it can essentially revert back to its polyp stage, which is the juvenile form of a jellyfish, and then grow back into an adult again.\n",
      "\n",
      "This process allows the jellyfish to bypass the normal process of aging and death, making it theoretically \"immortal\"! Isn't that mind-blowing?\n",
      "\n",
      "Isn't science amazing?\n",
      "\n",
      "\n",
      "Thread 11:\n",
      "Here's one:\n",
      "\n",
      "**Did you know that there is a type of jellyfish that is immortal?!**\n",
      "\n",
      "The Turritopsis dohrnii, also known as the \"immortal jellyfish,\" is a species of jellyfish that can transform its body into a younger state through a process called transdifferentiation. This means that it can essentially revert back to its polyp stage (the juvenile form) and then grow back into an adult again!\n",
      "\n",
      "This process allows Turritopsis dohrnii to bypass the normal process of aging and death, making it theoretically \"immortal.\" While this doesn't mean it's invincible or immune to all harm, it does make it a fascinating example of how some species have evolved unique mechanisms to cheat death.\n",
      "\n",
      "Isn't that just mind-blowing?\n",
      "\n",
      "\n",
      "Thread 12:\n",
      "Here's one:\n",
      "\n",
      "**Did you know that there is a type of jellyfish that is immortal?!**\n",
      "\n",
      "The Turritopsis dohrnii, also known as the \"immortal jellyfish,\" is a species of jellyfish that can transform its body into a younger state through a process called transdifferentiation. This means it can essentially revert back to its polyp stage, which is the juvenile form of a jellyfish, and then grow back into an adult again.\n",
      "\n",
      "This process can be repeated indefinitely, making Turritopsis dohrnii theoretically \"immortal\" – it never truly dies! Scientists are still studying this phenomenon to understand how it works and whether it could have implications for human regenerative medicine.\n",
      "\n",
      "Isn't that just mind-blowing?\n",
      "\n",
      "\n",
      "Thread 20:\n",
      "I've got one!\n",
      "\n",
      "Here's a fun fact: Did you know that there is a type of jellyfish that is immortal?!\n",
      "\n",
      "The Turritopsis dohrnii, also known as the \"immortal jellyfish,\" is a species of jellyfish that can transform its body into a younger state through a process called transdifferentiation. This means that it can essentially revert back to its polyp stage, which is the juvenile form of a jellyfish, and then grow back into an adult again!\n",
      "\n",
      "This process can be repeated indefinitely, making Turritopsis dohrnii theoretically \"immortal\" in the sense that it can cheat death by transforming its body back to a younger state. Isn't that cool?\n",
      "\n",
      "\n",
      "Thread 18:\n",
      "I've got one!\n",
      "\n",
      "Did you know that there is a type of jellyfish that is immortal?! The Turritopsis dohrnii, also known as the \"immortal jellyfish,\" is a species of jellyfish that can transform its body into a younger state through a process called transdifferentiation. This means it can essentially revert back to its polyp stage, which is the juvenile form of a jellyfish, and then grow back into an adult again. This process can be repeated indefinitely, making the Turritopsis dohrnii theoretically \"immortal\"!\n",
      "\n",
      "Isn't that mind-blowing?\n",
      "\n",
      "\n",
      "Thread 19:\n",
      "Here's one:\n",
      "\n",
      "**Did you know that there is a type of jellyfish that is immortal?!**\n",
      "\n",
      "The Turritopsis dohrnii, also known as the \"immortal jellyfish,\" is a species of jellyfish that can transform its body into a younger state through a process called transdifferentiation. This means it can essentially revert back to its polyp stage, which is the juvenile form of a jellyfish, and then grow back into an adult again! This process can be repeated indefinitely, making Turritopsis dohrnii theoretically immortal.\n",
      "\n",
      "Isn't that mind-blowing?!\n",
      "\n",
      "\n",
      "Thread 17:\n",
      "Here's one:\n",
      "\n",
      "**Did you know that there is a type of jellyfish that is immortal?!**\n",
      "\n",
      "The Turritopsis dohrnii, also known as the \"immortal jellyfish,\" is a species of jellyfish that can transform its body into a younger state through a process called transdifferentiation. This means that it can essentially revert back to its polyp stage, which is the juvenile form of a jellyfish, and then grow back into an adult again! This process can be repeated indefinitely, making Turritopsis dohrnii theoretically \"immortal.\"\n",
      "\n",
      "This process is still not fully understood and is currently being studied by scientists, but it has potential applications in the field of regenerative medicine and could possibly lead to new ways of understanding aging and disease.\n",
      "\n",
      "Isn't that just mind-blowing?\n",
      "\n",
      "Want more fun science facts?\n",
      "\n",
      "\n",
      "Thread 16:\n",
      "Here's one:\n",
      "\n",
      "**Did you know that there is a type of jellyfish that is immortal?!**\n",
      "\n",
      "The Turritopsis dohrnii, also known as the \"immortal jellyfish,\" is a species of jellyfish that can transform its body into a younger state through a process called transdifferentiation. This means that it can essentially revert back to its polyp stage, which is the juvenile form of a jellyfish, and then grow back into an adult again.\n",
      "\n",
      "This process can be repeated indefinitely, making Turritopsis dohrnii theoretically \"immortal\" in the sense that it cannot die of natural causes. It's not invincible, of course - it can still be injured or killed by external factors like disease or predators. But from a biological standpoint, it's essentially immortal!\n",
      "\n",
      "Isn't that cool?\n",
      "\n",
      "\n",
      "All threads completed.\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "from langchain.chat_models import ChatOllama\n",
    "from langchain.schema import HumanMessage\n",
    "import sys\n",
    "\n",
    "# THREAD TEST WITH 20 THREADS - \n",
    "llm = ChatOllama(model=\"llama3:8b\", temperature=0.7)  # GPT recommened to use this to get rid of some errors\n",
    "\n",
    "prompt_text = \"What's a fun fact about science?\"\n",
    "\n",
    "def ask_llm_live(thread_id: int):\n",
    "    try:\n",
    "        response = llm([HumanMessage(content=prompt_text)])\n",
    "        answer = response.content.strip()\n",
    "        sys.stdout.write(f\"\\nThread {thread_id}:\\n{answer}\\n\\n\")\n",
    "        sys.stdout.flush()\n",
    "    except Exception as e:\n",
    "        sys.stdout.write(f\"\\nThread {thread_id} ERROR: {e}\\n\\n\")\n",
    "        sys.stdout.flush()\n",
    "\n",
    "threads = []\n",
    "for thread_id in range(1, 21):\n",
    "    t = threading.Thread(target=ask_llm_live, args=(thread_id,))\n",
    "    threads.append(t)\n",
    "    t.start()\n",
    "\n",
    "\n",
    "for t in threads:\n",
    "    t.join()\n",
    "\n",
    "print(\"\\nAll threads completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a55a603e-103a-46c0-9dcc-8c72023cacb8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory 'I-Soon-data' has been deleted.\n"
     ]
    }
   ],
   "source": [
    "# import shutil\n",
    "# import os\n",
    "\n",
    "# # Directory to delete\n",
    "# EXTRACT_DIR = 'I-Soon-data'\n",
    "\n",
    "# # Check if the directory exists and delete it\n",
    "# if os.path.isdir(EXTRACT_DIR):\n",
    "#     shutil.rmtree(EXTRACT_DIR)\n",
    "#     print(f\"Directory '{EXTRACT_DIR}' has been deleted.\")\n",
    "# else:\n",
    "#     print(f\"Directory '{EXTRACT_DIR}' does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c242f8e-af9c-488e-9a4a-92bdc06a8ec7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (IsoonAI)",
   "language": "python",
   "name": "isoonai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

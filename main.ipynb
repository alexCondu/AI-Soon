{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e6d6a8f",
   "metadata": {},
   "source": [
    "# **IMPORTS & PATHS** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "879be4cb",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import subprocess\n",
    "import json\n",
    "import pandas as pd\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "import shutil\n",
    "\n",
    "\n",
    "# Paths and model settings\\ nZIP_PATH = 'I-Soon-data.zip'      # Path to your downloaded zip file\n",
    "ZIP_PATH = '0.zip'    # Directory to extract contents\n",
    "EXTRACT_DIR = 'I-Soon-data'        # Directory to extract contents\n",
    "ORGANIZED_DIR = 'organized_data'  # Directory to group files by extension\n",
    "MODEL_NAME = 'llama3.2'             # Local Ollama model identifier\n",
    "OUTPUT_JSON = 'parsed_md.json'    # Aggregated JSON output\n",
    "OUTPUT_CSV = 'parsed_md.csv'      # CSV output for DataFrame\n",
    "\n",
    "# Initialize Ollama LLM via LangChain\n",
    "model = OllamaLLM(model=MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f9f3fd",
   "metadata": {},
   "source": [
    "# **ZIP FILE EXTRACTION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5e6feb79",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted archive to 'I-Soon-data'\n"
     ]
    }
   ],
   "source": [
    "if not os.path.isdir(EXTRACT_DIR):\n",
    "    with zipfile.ZipFile(ZIP_PATH, 'r') as zip_ref:\n",
    "        zip_ref.extractall(EXTRACT_DIR)\n",
    "    print(f\"Extracted archive to '{EXTRACT_DIR}'\")\n",
    "else:\n",
    "    print(f\"Extraction directory '{EXTRACT_DIR}' already exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325a01d8",
   "metadata": {},
   "source": [
    "# **DATA TYPE CATEGORIZATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "dec65000",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted: I-Soon-data/__MACOSX\n"
     ]
    }
   ],
   "source": [
    "# Define the parent directory\n",
    "parent_directory = \"I-Soon-data\"\n",
    "\n",
    "# Full path to the __MACOSX folder\n",
    "macosx_folder = os.path.join(parent_directory, \"__MACOSX\")\n",
    "\n",
    "# Check if __MACOSX exists and remove it\n",
    "if os.path.exists(macosx_folder) and os.path.isdir(macosx_folder):\n",
    "    shutil.rmtree(macosx_folder)\n",
    "    print(f\"Deleted: {macosx_folder}\")\n",
    "else:\n",
    "    print(f\"Folder not found: {macosx_folder}\")\n",
    "\n",
    "# Organize files by extension into subfolders\n",
    "for root, dirs, files in os.walk(parent_directory):\n",
    "    for file in files:\n",
    "        # Skip hidden files and __MACOSX if any reappear\n",
    "        if file.startswith('.') or '__MACOSX' in root:\n",
    "            continue\n",
    "\n",
    "        # Get the file extension (in lowercase, without the dot)\n",
    "        file_extension = os.path.splitext(file)[1].lower().lstrip('.')\n",
    "        if not file_extension:\n",
    "            file_extension = \"no_extension\"\n",
    "\n",
    "        # Define the new subfolder path\n",
    "        subfolder_path = os.path.join(parent_directory, file_extension)\n",
    "\n",
    "        # Create the subfolder if it doesn't exist\n",
    "        os.makedirs(subfolder_path, exist_ok=True)\n",
    "\n",
    "        # Define source and destination paths\n",
    "        source_path = os.path.join(root, file)\n",
    "        destination_path = os.path.join(subfolder_path, file)\n",
    "\n",
    "        # Move the file if source and destination are not the same\n",
    "        if os.path.abspath(source_path) != os.path.abspath(destination_path):\n",
    "            shutil.move(source_path, destination_path)\n",
    "\n",
    "# Remove any empty folders within the parent directory\n",
    "for dirpath, dirnames, filenames in os.walk(parent_directory, topdown=False):\n",
    "    if not dirnames and not filenames:\n",
    "        try:\n",
    "            os.rmdir(dirpath)\n",
    "            print(f\"Removed empty folder: {dirpath}\")\n",
    "        except OSError:\n",
    "            pass  # Ignore errors (e.g., if directory is not empty due to permissions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75417f54",
   "metadata": {},
   "source": [
    "# **Stage 1: Markdown File Classification Using Local LLM (Ollama + LangChain)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b9397264",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying files: 100%|██████████| 70/70 [01:24<00:00,  1.21s/it]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "import concurrent.futures\n",
    "from langchain.llms import Ollama\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === Step 1: Set up LLM and Prompt ===\n",
    "\n",
    "# Initialize a local LLM using Ollama (e.g., llama3.2)\n",
    "llm = Ollama(model=\"llama3.2\")  # Replace with the model of your choice\n",
    "\n",
    "# Define a structured prompt to:\n",
    "# - Summarize Markdown file content\n",
    "# - Classify it into one of three categories\n",
    "# - Provide confidence level\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"content\"],\n",
    "    template=\"\"\"\n",
    "You are analyzing the content of a Markdown (.md) file.\n",
    "\n",
    "Markdown content:\n",
    "\\\"\\\"\\\"\n",
    "{content}\n",
    "\\\"\\\"\\\"\n",
    "\n",
    "1. Summarize the file in one short and precise sentence.\n",
    "2. Classify it into one of the following categories ONLY: chats, images, other.\n",
    "3. State your confidence in the classification as one of: high, medium, or low.\n",
    "\n",
    "Respond in the following format:\n",
    "Summary: <your summary>\n",
    "Category: <chats|images|other>\n",
    "Confidence: <high|medium|low>\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# Create the LangChain chain that will run the LLM with the above prompt\n",
    "chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "\n",
    "# === Step 2: Preprocessing Function ===\n",
    "\n",
    "# Reads the first 20 lines of a Markdown file and joins them into a single string\n",
    "def preprocess_first_20_lines(file_path):\n",
    "    try:\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            lines = [line.strip() for _, line in zip(range(20), f)]\n",
    "            content = \" \".join(lines)\n",
    "        return os.path.basename(file_path), content\n",
    "    except Exception:\n",
    "        return os.path.basename(file_path), \"\"\n",
    "\n",
    "# === Step 3: Load .md Files ===\n",
    "\n",
    "# Directory containing original Markdown files\n",
    "md_dir = \"I-Soon-data/md\"\n",
    "\n",
    "# Get all .md file paths\n",
    "md_files = glob.glob(os.path.join(md_dir, \"*.md\"))\n",
    "\n",
    "# Use multithreading to preprocess the Markdown files\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    file_data = list(executor.map(preprocess_first_20_lines, md_files))\n",
    "\n",
    "# === Step 4: Classify Each File with LLM ===\n",
    "\n",
    "# Directory to store the filtered and organized files\n",
    "filtered_dir = \"Filtered-markdowns\"\n",
    "os.makedirs(filtered_dir, exist_ok=True)\n",
    "\n",
    "# Allow only these categories for folder placement\n",
    "valid_categories = {\"chats\", \"images\", \"other\"}\n",
    "\n",
    "# This will store a structured log of the results\n",
    "results_log = []\n",
    "\n",
    "# Iterate over all files and classify each one\n",
    "for file_name, content in tqdm(file_data, desc=\"Classifying files\"):\n",
    "    if not content:\n",
    "        continue  # Skip empty files or failed reads\n",
    "\n",
    "    try:\n",
    "        # Run the LLM prompt with the extracted content\n",
    "        response = chain.run(content=content).strip().lower()\n",
    "        lines = response.splitlines()\n",
    "\n",
    "        # Parse the LLM's structured response\n",
    "        summary = next((line.replace(\"summary:\", \"\").strip() for line in lines if line.startswith(\"summary:\")), \"\")\n",
    "        category = next((line.replace(\"category:\", \"\").strip() for line in lines if line.startswith(\"category:\")), \"\")\n",
    "        confidence = next((line.replace(\"confidence:\", \"\").strip() for line in lines if line.startswith(\"confidence:\")), \"\")\n",
    "\n",
    "        # Normalize category (fallback to 'other' if invalid)\n",
    "        if category not in valid_categories:\n",
    "            category = \"other\"\n",
    "\n",
    "        # Create subfolder for this category if it doesn't exist\n",
    "        category_path = os.path.join(filtered_dir, category)\n",
    "        os.makedirs(category_path, exist_ok=True)\n",
    "\n",
    "        # Copy the original .md file to the appropriate category folder\n",
    "        src_path = os.path.join(md_dir, file_name)\n",
    "        dst_path = os.path.join(category_path, file_name)\n",
    "        if os.path.exists(src_path):\n",
    "            shutil.copy2(src_path, dst_path)\n",
    "\n",
    "        # Append results to the log\n",
    "        results_log.append({\n",
    "            \"file\": file_name,\n",
    "            \"summary\": summary,\n",
    "            \"category\": category,\n",
    "            \"confidence\": confidence\n",
    "        })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process {file_name}: {e}\")\n",
    "\n",
    "# === Optional Step: Save log as JSON or CSV ===\n",
    "# Uncomment the below lines to save results for auditing\n",
    "\n",
    "# import json\n",
    "# with open(\"classification_results.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "#     json.dump(results_log, f, indent=2)\n",
    "\n",
    "# import csv\n",
    "# with open(\"classification_results.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "#     writer = csv.DictWriter(f, fieldnames=[\"file\", \"summary\", \"category\", \"confidence\"])\n",
    "#     writer.writeheader()\n",
    "#     writer.writerows(results_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57fe507e",
   "metadata": {},
   "source": [
    "# **Stage 2: LLM-Based Categorization and File Organization by Description**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "29857281",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [00:47<00:00,  1.47it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import Ollama\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Initialize second LLM\n",
    "llm2 = Ollama(model=\"taozhiyuai/llama-3-refueled:q4_k_m\")\n",
    "\n",
    "# Prompt for classification based on description\n",
    "prompt_template_stage2 = PromptTemplate(\n",
    "    input_variables=[\"description\"],\n",
    "    template=\"\"\"\n",
    "You are a strict content classifier.\n",
    "\n",
    "Given the following short description of a Markdown (.md) file:\n",
    "\n",
    "\\\"\\\"\\\"\n",
    "{description}\n",
    "\\\"\\\"\\\"\n",
    "\n",
    "Classify the content into one of these categories only:\n",
    "- chats\n",
    "- images\n",
    "- other\n",
    "\n",
    "Return only one of those three exact words (in lowercase). Do not use synonyms or explanations. Do not make up new categories.\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# Set up LangChain chain\n",
    "chain2 = LLMChain(llm=llm2, prompt=prompt_template_stage2)\n",
    "\n",
    "# Directories\n",
    "original_dir = \"I-Soon-data/md\"\n",
    "filtered_dir = \"Filtered-markdowns\"\n",
    "os.makedirs(filtered_dir, exist_ok=True)\n",
    "\n",
    "# Allowed categories\n",
    "valid_categories = {\"chats\", \"images\", \"other\"}\n",
    "\n",
    "# Reclassify and copy files\n",
    "for file_name, description in tqdm(results.items()):\n",
    "    try:\n",
    "        category = chain2.run(description=description).strip().lower()\n",
    "        if category not in valid_categories:\n",
    "            category = \"other\"  # fallback to default\n",
    "\n",
    "        # Create destination folder\n",
    "        category_path = os.path.join(filtered_dir, category)\n",
    "        os.makedirs(category_path, exist_ok=True)\n",
    "\n",
    "        # Copy the file\n",
    "        src_path = os.path.join(original_dir, file_name)\n",
    "        dst_path = os.path.join(category_path, file_name)\n",
    "\n",
    "        if os.path.exists(src_path):\n",
    "            shutil.copy2(src_path, dst_path)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to classify or copy {file_name}: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ISoonAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

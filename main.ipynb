{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e6d6a8f",
   "metadata": {},
   "source": [
    "# **IMPORTS & PATHS** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "879be4cb",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import subprocess\n",
    "import json\n",
    "import pandas as pd\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "import shutil\n",
    "\n",
    "\n",
    "# Paths and model settings\\ nZIP_PATH = 'I-Soon-data.zip'      # Path to your downloaded zip file\n",
    "ZIP_PATH = '0.zip'    # Directory to extract contents\n",
    "EXTRACT_DIR = 'I-Soon-data'        # Directory to extract contents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f9f3fd",
   "metadata": {},
   "source": [
    "# **ZIP FILE EXTRACTION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "5e6feb79",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted archive to 'I-Soon-data'\n"
     ]
    }
   ],
   "source": [
    "if not os.path.isdir(EXTRACT_DIR):\n",
    "    with zipfile.ZipFile(ZIP_PATH, 'r') as zip_ref:\n",
    "        zip_ref.extractall(EXTRACT_DIR)\n",
    "    print(f\"Extracted archive to '{EXTRACT_DIR}'\")\n",
    "else:\n",
    "    print(f\"Extraction directory '{EXTRACT_DIR}' already exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325a01d8",
   "metadata": {},
   "source": [
    "# **DATA TYPE CATEGORIZATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "dec65000",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted: I-Soon-data/__MACOSX\n"
     ]
    }
   ],
   "source": [
    "# Define the parent directory\n",
    "parent_directory = \"I-Soon-data\"\n",
    "\n",
    "# Full path to the __MACOSX folder\n",
    "macosx_folder = os.path.join(parent_directory, \"__MACOSX\")\n",
    "\n",
    "# Check if __MACOSX exists and remove it\n",
    "if os.path.exists(macosx_folder) and os.path.isdir(macosx_folder):\n",
    "    shutil.rmtree(macosx_folder)\n",
    "    print(f\"Deleted: {macosx_folder}\")\n",
    "else:\n",
    "    print(f\"Folder not found: {macosx_folder}\")\n",
    "\n",
    "# Organize files by extension into subfolders\n",
    "for root, dirs, files in os.walk(parent_directory):\n",
    "    for file in files:\n",
    "        # Skip hidden files and __MACOSX if any reappear\n",
    "        if file.startswith('.') or '__MACOSX' in root:\n",
    "            continue\n",
    "\n",
    "        # Get the file extension (in lowercase, without the dot)\n",
    "        file_extension = os.path.splitext(file)[1].lower().lstrip('.')\n",
    "        if not file_extension:\n",
    "            file_extension = \"no_extension\"\n",
    "\n",
    "        # Define the new subfolder path\n",
    "        subfolder_path = os.path.join(parent_directory, file_extension)\n",
    "\n",
    "        # Create the subfolder if it doesn't exist\n",
    "        os.makedirs(subfolder_path, exist_ok=True)\n",
    "\n",
    "        # Define source and destination paths\n",
    "        source_path = os.path.join(root, file)\n",
    "        destination_path = os.path.join(subfolder_path, file)\n",
    "\n",
    "        # Move the file if source and destination are not the same\n",
    "        if os.path.abspath(source_path) != os.path.abspath(destination_path):\n",
    "            shutil.move(source_path, destination_path)\n",
    "\n",
    "# Remove any empty folders within the parent directory\n",
    "for dirpath, dirnames, filenames in os.walk(parent_directory, topdown=False):\n",
    "    if not dirnames and not filenames:\n",
    "        try:\n",
    "            os.rmdir(dirpath)\n",
    "            print(f\"Removed empty folder: {dirpath}\")\n",
    "        except OSError:\n",
    "            pass  # Ignore errors (e.g., if directory is not empty due to permissions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75417f54",
   "metadata": {},
   "source": [
    "# **Markdown File Classification Using Local LLM (Ollama + LangChain)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "b9397264",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 70/70 [02:36<00:00,  2.24s/it]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "import concurrent.futures\n",
    "from langchain.llms import Ollama\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === Step 1: Set up LLM and Prompt ===\n",
    "\n",
    "llm = Ollama(model=\"llama3.1:8b\")\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"content\"],\n",
    "    template=\"\"\"\n",
    "You are analyzing the content of a Markdown (.md) file.\n",
    "\n",
    "Markdown content:\n",
    "\\\"\\\"\\\"\n",
    "{content}\n",
    "\\\"\\\"\\\"\n",
    "\n",
    "1. Classify the content into one of the following categories ONLY: chats, images, other.\n",
    "2. State your confidence in the classification as one of: high, medium, or low.\n",
    "\n",
    "Respond in the following format:\n",
    "Category: <chats|images|other>\n",
    "Confidence: <high|medium|low>\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "\n",
    "# === Step 2: Preprocessing Function ===\n",
    "\n",
    "def preprocess_first_20_lines(file_path):\n",
    "    try:\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            lines = [line.strip() for _, line in zip(range(20), f)]\n",
    "            content = \" \".join(lines)\n",
    "        return os.path.basename(file_path), content\n",
    "    except Exception:\n",
    "        return os.path.basename(file_path), \"\"\n",
    "\n",
    "# === Step 3: Load .md Files ===\n",
    "\n",
    "md_dir = \"I-Soon-data/md\"\n",
    "md_files = glob.glob(os.path.join(md_dir, \"*.md\"))\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    file_data = list(executor.map(preprocess_first_20_lines, md_files))\n",
    "\n",
    "# === Step 4: Classify Each File and Move ===\n",
    "\n",
    "valid_categories = {\"chats\", \"images\", \"other\"}\n",
    "results_log = []\n",
    "\n",
    "for file_name, content in tqdm(file_data, desc=\"Classifying files\"):\n",
    "    if not content:\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        response = chain.run(content=content).strip().lower()\n",
    "        lines = response.splitlines()\n",
    "\n",
    "        category = next((line.replace(\"category:\", \"\").strip() for line in lines if line.startswith(\"category:\")), \"\")\n",
    "        confidence = next((line.replace(\"confidence:\", \"\").strip() for line in lines if line.startswith(\"confidence:\")), \"\")\n",
    "\n",
    "        if category not in valid_categories:\n",
    "            category = \"other\"\n",
    "\n",
    "        # Destination folder *within* the md_dir\n",
    "        category_path = os.path.join(md_dir, category)\n",
    "        os.makedirs(category_path, exist_ok=True)\n",
    "\n",
    "        # Move file into category folder\n",
    "        src_path = os.path.join(md_dir, file_name)\n",
    "        dst_path = os.path.join(category_path, file_name)\n",
    "\n",
    "        if os.path.exists(src_path):\n",
    "            shutil.move(src_path, dst_path)\n",
    "\n",
    "        results_log.append({\n",
    "            \"file\": file_name,\n",
    "            \"category\": category,\n",
    "            \"confidence\": confidence\n",
    "        })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process {file_name}: {e}\")\n",
    "\n",
    "# === Optional: Save results to file ===\n",
    "\n",
    "# import json\n",
    "# with open(\"classification_results.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "#     json.dump(results_log, f, indent=2)\n",
    "\n",
    "# import csv\n",
    "# with open(\"classification_results.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "#     writer = csv.DictWriter(f, fieldnames=[\"file\", \"category\", \"confidence\"])\n",
    "#     writer.writeheader()\n",
    "#     writer.writerows(results_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57fe507e",
   "metadata": {},
   "source": [
    "# **Stage 2: LLM-Based Categorization and File Organization by Description**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "29857281",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# import shutil\n",
    "# from langchain.prompts import PromptTemplate\n",
    "# from langchain.chains import LLMChain\n",
    "# from langchain.llms import Ollama\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# # Initialize second LLM\n",
    "# llm2 = Ollama(model=\"taozhiyuai/llama-3-refueled:q4_k_m\")\n",
    "\n",
    "# # Prompt for classification based on description\n",
    "# prompt_template_stage2 = PromptTemplate(\n",
    "#     input_variables=[\"description\"],\n",
    "#     template=\"\"\"\n",
    "# You are a strict content classifier.\n",
    "\n",
    "# Given the following short description of a Markdown (.md) file:\n",
    "\n",
    "# \\\"\\\"\\\"\n",
    "# {description}\n",
    "# \\\"\\\"\\\"\n",
    "\n",
    "# Classify the content into one of these categories only:\n",
    "# - chats\n",
    "# - images\n",
    "# - other\n",
    "\n",
    "# Return only one of those three exact words (in lowercase). Do not use synonyms or explanations. Do not make up new categories.\n",
    "# \"\"\"\n",
    "# )\n",
    "\n",
    "# # Set up LangChain chain\n",
    "# chain2 = LLMChain(llm=llm2, prompt=prompt_template_stage2)\n",
    "\n",
    "# # Directories\n",
    "# original_dir = \"I-Soon-data/md\"\n",
    "# filtered_dir = \"Filtered-markdowns\"\n",
    "# os.makedirs(filtered_dir, exist_ok=True)\n",
    "\n",
    "# # Allowed categories\n",
    "# valid_categories = {\"chats\", \"images\", \"other\"}\n",
    "\n",
    "# # Reclassify and copy files\n",
    "# for file_name, description in tqdm(results.items()):\n",
    "#     try:\n",
    "#         category = chain2.run(description=description).strip().lower()\n",
    "#         if category not in valid_categories:\n",
    "#             category = \"other\"  # fallback to default\n",
    "\n",
    "#         # Create destination folder\n",
    "#         category_path = os.path.join(filtered_dir, category)\n",
    "#         os.makedirs(category_path, exist_ok=True)\n",
    "\n",
    "#         # Copy the file\n",
    "#         src_path = os.path.join(original_dir, file_name)\n",
    "#         dst_path = os.path.join(category_path, file_name)\n",
    "\n",
    "#         if os.path.exists(src_path):\n",
    "#             shutil.copy2(src_path, dst_path)\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"Failed to classify or copy {file_name}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c72754",
   "metadata": {},
   "source": [
    "# **Finding connetions between the MD files - reduced size due to performance issues**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65d0463",
   "metadata": {},
   "source": [
    "Idea: Have the LLM search the markdown files and look for any files linked outside the chats."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf991dca",
   "metadata": {},
   "source": [
    "# *RegEx based identification of linked files within the chat*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0e93fe",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç LLM-generated file extensions list:\n",
      "['mdb', 'accdb', 'xml', 'config', 'ini', 'properties', 'json', 'yaml', 'csv', 'ods', 'xls', 'xlsx', 'xlsm', 'txt', 'log', 'bak', 'sql', 'dbf', 'dbt', 'kdbx', 'odb', 'sqlite3', 'dat', 'pem', 'key', 'crt', 'cer', 'crl', 'csr', 'jks', 'keystore', 'enc', 'aes', 'zip', 'rar', '7z', 'tar', 'gz', 'bz2', 'xz', 'lzma', 'jpg', 'jpeg', 'png', 'gif', 'bmp', 'tiff', 'tif', 'psd', 'ai', 'cdr', 'indd', 'docx', 'doc', 'pdf', 'ods', 'xlsx', 'pptx', 'ppt', 'mp4', 'mov', 'avi', 'flv', 'wmv', 'mpg', 'mpeg', 'srt', 'sub']\n",
      "\n",
      "üìÑ Extracted filenames from chats:\n",
      "1.md:\n",
      "  - ÂÆâÊ¥µÈ°πÁõÆ-ÊäïËµÑÊÑèÂêë‰π¶-200730.DOCX\n",
      "  - ËØæÁ®ãË°®2020_Ë•øÂÆâ_ÂÜÖÁâà.docx\n",
      "  - c404_indictment_0.docx\n",
      "  - wong_indictment_redacted_0.docx\n",
      "  - zhr_indictment_redacted_0.docx\n",
      "  - ‰∫ßÊïôËûçÂêàÂª∫ËÆæÈ°πÁõÆÁî≥Êä•‰π¶20201028.docx\n",
      "  - tpyrced_ÊâìÂáªÊï¥Ê≤ªÊ∂âÁΩëÁäØÁΩ™ÊäÄÊúØÊúçÂä°ÂêàÂêå0201-Â§ßÁêÜ.docx\n",
      "  - 202063ÁÆÄÊä•-Ê®°ÊùøÂ±ïÁ§∫.pdf\n",
      "  - ÊØîÁâπ‰ø°ÂÆâÊï∞ÊçÆËÑ±ÊïèÁ≥ªÁªüsaasÊúçÂä°‰∏öÂä°Ê®°Âºè‰∏ªÊâìËÉ∂Áâá.pdf\n",
      "  - ‰∏™‰∫∫ÁÆÄÂéÜË°®-ÂæêÂ≠êËØë.docx\n",
      "  - Â§™ÊûÅÂÖ¨Âè∏Âü∫Êú¨ÊÉÖÂÜµ‰ªãÁªç20210809.pptx\n",
      "  - 20220110.doc\n",
      "  - -2021Âπ¥1ÊúàÁâà.pdf\n",
      "  - Â∏ÇÂú∫ÂØπÂ§ñ2022-Êµ∑ÂçóÂÆâÊ¥µ.pptx\n",
      "  - ÂõõÂ∑ù‰∏§Âú∞È°πÁõÆÂêà‰ΩúÊ°ÜÊû∂ÂçèËÆÆ.pdf\n",
      "  - ÂõõÂ∑ù‰∏§Âú∞È°πÁõÆÂêà‰ΩúÊ°ÜÊû∂ÂçèËÆÆ.pdf\n",
      "  - ÂÆâÊ¥µ‰ø°ÊÅØ20220228.pdf\n",
      "  - ÂâçÁ´ØÈîÄÂîÆÂèçÈ¶àÈóÆÈ¢ò.doc\n",
      "  - ‰∏Ä‰ΩìÂåñÂÆâÂÖ®È°πÁõÆÂàùÊ≠•ËÆæËÆ°ÊñáÊ°£2b723eaa7742869ff370fd42f5b572f8.pdf\n",
      "  - ÈîÄÂîÆ‰ΩìÁ≥ªÈòü‰ºçË∞ÉÊï¥ÊñπÊ°à.docx\n",
      "  - ÁâπÊÆä‰∫∫Áæ§Êô∫ÊÖßÁÆ°ÁêÜ‰∫ßÂìÅÁÆÄ‰ªã2022.pdf\n",
      "  - Âè∏Ê≥ïÊô∫ÊÖßÁü´Ê≠£‰∫ßÂìÅ‰ªãÁªç2022.pdf\n",
      "  - v1.0.ppt.pdf\n",
      "  - Êô∫ÊÖßÁü´Ê≠£‰∫ßÂìÅÊä•‰ª∑Âçï202206-Êµ∑Âçó-Â∏ÇÂú∫ÊåáÂØº‰ª∑.pdf\n",
      "19.md:\n",
      "  - 6848748d-2881-4c26-b153-fcd5373d2f1c.png\n",
      "  - 0-6848748d-2881-4c26-b153-fcd5373d2f1c.png\n",
      "4.md:\n",
      "  - 330f554f-a3e6-4bd3-8b1b-d5949e1f30e8.png\n",
      "  - 0-330f554f-a3e6-4bd3-8b1b-d5949e1f30e8.png\n",
      "  - dd5b6a38-dc17-4122-a242-32006b381b3a.png\n",
      "  - 0-dd5b6a38-dc17-4122-a242-32006b381b3a.png\n",
      "  - 62ff30cf-de5f-4388-82aa-b69b0fd0f07c.png\n",
      "  - 0-62ff30cf-de5f-4388-82aa-b69b0fd0f07c.png\n",
      "  - Ë∂äÂçó‰∫∫Ê∞ëÂÖ¨ÂÆâÁîµËßÜANTV.docx\n",
      "  - f41b7574-57b4-4c9f-907c-2a3c48a56157.png\n",
      "  - 0-f41b7574-57b4-4c9f-907c-2a3c48a56157.png\n",
      "  - bcad4fdf-3771-4873-92fa-23240654118a.png\n",
      "  - 0-bcad4fdf-3771-4873-92fa-23240654118a.png\n",
      "  - fc27ce32-9c96-416c-9c38-84977255e0ba.png\n",
      "  - 0-fc27ce32-9c96-416c-9c38-84977255e0ba.png\n",
      "22.md:\n",
      "  - b0a4acaa-d768-4f6d-8e54-6d20f271bb7c.png\n",
      "  - 0-b0a4acaa-d768-4f6d-8e54-6d20f271bb7c.png\n",
      "  - 493542fc-495f-4756-8451-c4ed084d8bf7.png\n",
      "  - 0-493542fc-495f-4756-8451-c4ed084d8bf7.png\n",
      "26.md:\n",
      "  - ÂâçÁ´ØÈîÄÂîÆÂèçÈ¶àÈóÆÈ¢ò.doc\n",
      "  - ÂâçÁ´ØÈîÄÂîÆÂèçÈ¶àÈóÆÈ¢ò.doc\n",
      "36.md:\n",
      "  - ÊâãÊú∫Ë¥≠ÂΩ©ÂàÜÊûêÁÆÄÊä•.docx\n",
      "13.md:\n",
      "  - 987ba39a-cc1c-4367-8d6d-f5a49a940198.png\n",
      "  - 0-987ba39a-cc1c-4367-8d6d-f5a49a940198.png\n",
      "  - adaf869e-920a-4a17-91bd-e2ef3125c10e.png\n",
      "  - 0-adaf869e-920a-4a17-91bd-e2ef3125c10e.png\n",
      "  - 5ae9bdca-fdf9-4948-8c11-a9e400b331aa.png\n",
      "  - 0-5ae9bdca-fdf9-4948-8c11-a9e400b331aa.png\n",
      "  - 1b0dc208-d2bb-43ea-b744-534f3b759394.png\n",
      "  - 0-1b0dc208-d2bb-43ea-b744-534f3b759394.png\n",
      "  - 3556e54c-d418-447d-bb2a-43ac0408cc7a.png\n",
      "  - 0-3556e54c-d418-447d-bb2a-43ac0408cc7a.png\n",
      "37.md:\n",
      "  - Â§™ÊûÅÂÖ¨Âè∏Âü∫Êú¨ÊÉÖÂÜµ‰ªãÁªç20210809.pptx\n",
      "23.md:\n",
      "  - ÂæÆËΩØÈÇÆ‰ª∂ÂØÜÂèñÂπ≥Âè∞.7z\n",
      "  - 202301090144.pdf\n",
      "24.md:\n",
      "  - 96af60b3-299c-4e26-bca3-d9eb3e113b94.png\n",
      "  - 0-96af60b3-299c-4e26-bca3-d9eb3e113b94.png\n",
      "  - fcf90a92-794c-40c6-aa4f-8ea82f8bed51.png\n",
      "  - 0-fcf90a92-794c-40c6-aa4f-8ea82f8bed51.png\n",
      "  - 1afcf93d-50f1-4f1e-896d-87b0da7519f7.png\n",
      "  - 0-1afcf93d-50f1-4f1e-896d-87b0da7519f7.png\n",
      "  - fe221e78-67e4-4d88-b73d-e58a9943a036.png\n",
      "  - 0-fe221e78-67e4-4d88-b73d-e58a9943a036.png\n",
      "41.md:\n",
      "  - ÊÅ©‰ΩêÂ®±‰πê-14.2E-220726.docx\n",
      "10.md:\n",
      "  - e705d192-90ee-4fd1-9dcd-061958d1817f.png\n",
      "  - 0-e705d192-90ee-4fd1-9dcd-061958d1817f.png\n",
      "  - 5a84cde3-7175-4044-8c88-d4c883a8fd38.png\n",
      "  - 0-5a84cde3-7175-4044-8c88-d4c883a8fd38.png\n",
      "  - 4ea07c23-a1a6-411b-bcfb-552d095b66c9.png\n",
      "  - 0-4ea07c23-a1a6-411b-bcfb-552d095b66c9.png\n",
      "  - 79d9b7f2-cfe4-4615-9b75-8fea33fc0c9d.png\n",
      "  - 0-79d9b7f2-cfe4-4615-9b75-8fea33fc0c9d.png\n",
      "  - 6bcc0131-e4ad-421e-bb1f-d8ebe5eeec7b.png\n",
      "  - 0-6bcc0131-e4ad-421e-bb1f-d8ebe5eeec7b.png\n",
      "9.md:\n",
      "  - 32eb7662-f212-4811-a7c1-1cfeb121cd99.png\n",
      "  - 0-32eb7662-f212-4811-a7c1-1cfeb121cd99.png\n",
      "  - 5d4e3e02-1dfc-469e-8af9-8dbe2b9f1564.png\n",
      "  - 0-5d4e3e02-1dfc-469e-8af9-8dbe2b9f1564.png\n",
      "  - 70c63791-2797-4bf0-a778-ea08819aa9de.png\n",
      "  - 0-70c63791-2797-4bf0-a778-ea08819aa9de.png\n",
      "  - 0baba509-5e81-4b88-b509-843822d09e21.png\n",
      "  - 0-0baba509-5e81-4b88-b509-843822d09e21.png\n",
      "  - 129ac70f-8942-4ca7-b1f2-ddeaa3d984b5.png\n",
      "  - 0-129ac70f-8942-4ca7-b1f2-ddeaa3d984b5.png\n",
      "  - b9d9c584-5e21-4a49-952b-ffecca4eb91e.png\n",
      "  - 0-b9d9c584-5e21-4a49-952b-ffecca4eb91e.png\n",
      "  - ee47dfea-2626-4107-8ab3-4663167e0493.png\n",
      "  - 0-ee47dfea-2626-4107-8ab3-4663167e0493.png\n",
      "  - aa99f763-6849-4f6b-adf2-58f0cc2ed545.png\n",
      "  - 0-aa99f763-6849-4f6b-adf2-58f0cc2ed545.png\n",
      "  - b6eb1b15-cf99-475c-921f-f06e5c1019d4.png\n",
      "  - 0-b6eb1b15-cf99-475c-921f-f06e5c1019d4.png\n",
      "20.md:\n",
      "  - 785cc8c9-1225-4f93-b633-349bc5113512.png\n",
      "  - 0-785cc8c9-1225-4f93-b633-349bc5113512.png\n",
      "  - af93eff8-2973-4746-9041-b2223016b117.png\n",
      "  - 0-af93eff8-2973-4746-9041-b2223016b117.png\n",
      "  - b3ce4d51-6024-4b43-b0d2-d3faaf3c2879.png\n",
      "  - 0-b3ce4d51-6024-4b43-b0d2-d3faaf3c2879.png\n",
      "  - f313f521-80a1-4db5-a8a7-53d29ee09890.png\n",
      "  - 0-f313f521-80a1-4db5-a8a7-53d29ee09890.png\n",
      "15.md:\n",
      "  - 20211103-1.txt\n",
      "  - b8cea3b1-4dde-4438-9b1a-6faf690bbad0.png\n",
      "  - 0-b8cea3b1-4dde-4438-9b1a-6faf690bbad0.png\n",
      "21.md:\n",
      "  - 9c8c9989-2293-4e68-9ffe-6f7a5f14562f.png\n",
      "  - 0-9c8c9989-2293-4e68-9ffe-6f7a5f14562f.png\n",
      "11.md:\n",
      "  - 2bankinfo-5.zip\n",
      "7.md:\n",
      "  - 94b16e53-f035-4aa9-a76e-80bc6e936d10.png\n",
      "  - 0-94b16e53-f035-4aa9-a76e-80bc6e936d10.png\n",
      "  - 645dfc97-3268-4e1d-920d-4138545456fa.png\n",
      "  - 0-645dfc97-3268-4e1d-920d-4138545456fa.png\n",
      "  - 1cc570d8-cddb-401e-8c37-ef10c0e4841f.png\n",
      "  - 0-1cc570d8-cddb-401e-8c37-ef10c0e4841f.png\n",
      "2.md:\n",
      "  - 9a8077f5-ac41-491f-b192-6b4609324bda.png\n",
      "  - 0-9a8077f5-ac41-491f-b192-6b4609324bda.png\n",
      "  - de359f8d-0745-4a93-959a-d1a6c361e326.png\n",
      "  - 0-de359f8d-0745-4a93-959a-d1a6c361e326.png\n",
      "  - 383d824e-7588-4a92-84b7-fd953dd91cba.png\n",
      "  - 0-383d824e-7588-4a92-84b7-fd953dd91cba.png\n",
      "  - f0ce8a7b-909d-4fc5-ba13-ea66b2dc6448.png\n",
      "  - 0-f0ce8a7b-909d-4fc5-ba13-ea66b2dc6448.png\n",
      "  - b8b76b6d-a50e-4246-82ee-3c8a5dcd523e.png\n",
      "  - 0-b8b76b6d-a50e-4246-82ee-3c8a5dcd523e.png\n",
      "  - 4c74b697-0681-4223-9982-5ffaf4e98ed0.png\n",
      "  - 0-4c74b697-0681-4223-9982-5ffaf4e98ed0.png\n",
      "  - 300450bf-221e-4eeb-bdda-dc1115c947ea.png\n",
      "  - 0-300450bf-221e-4eeb-bdda-dc1115c947ea.png\n",
      "  - 0f319bf6-e667-4bac-a974-dfda1142e9ff.png\n",
      "  - 0-0f319bf6-e667-4bac-a974-dfda1142e9ff.png\n",
      "  - 1a20ded1-50fc-4153-9a95-e158eeb7199e.png\n",
      "  - 0-1a20ded1-50fc-4153-9a95-e158eeb7199e.png\n",
      "  - 5ef1d666-e19d-4570-b800-6693a4f680ee.png\n",
      "  - 0-5ef1d666-e19d-4570-b800-6693a4f680ee.png\n",
      "  - e07a9457-86f1-4f0f-86d7-8ea816b8d8d3.png\n",
      "  - 0-e07a9457-86f1-4f0f-86d7-8ea816b8d8d3.png\n",
      "  - 08a6bcd3-6477-4252-8f35-4f8f80d114f9.png\n",
      "  - 0-08a6bcd3-6477-4252-8f35-4f8f80d114f9.png\n",
      "  - 7150f512-e7a2-4f2c-86bc-58b671b25ba9.png\n",
      "  - 0-7150f512-e7a2-4f2c-86bc-58b671b25ba9.png\n",
      "  - 62583414-9e32-4d09-8989-b5fa32a98a81.png\n",
      "  - 0-62583414-9e32-4d09-8989-b5fa32a98a81.png\n",
      "  - 4ae9bf34-c16c-4684-aa92-fec65a151275.png\n",
      "  - 0-4ae9bf34-c16c-4684-aa92-fec65a151275.png\n",
      "  - c5f1d959-39d1-4176-9cb1-1fb6e8baedc3.png\n",
      "  - 0-c5f1d959-39d1-4176-9cb1-1fb6e8baedc3.png\n",
      "  - 6e9aced1-df28-4e57-b7c8-641609ff4450.png\n",
      "  - 0-6e9aced1-df28-4e57-b7c8-641609ff4450.png\n",
      "  - 6cbb3eeb-17e9-4af6-8da1-36eb6437f7bc.png\n",
      "  - 0-6cbb3eeb-17e9-4af6-8da1-36eb6437f7bc.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import ast\n",
    "from langchain.llms import Ollama\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "# Step 1: Initialize LLM\n",
    "llm2 = Ollama(model=\"llama3.1:8b\")\n",
    "\n",
    "# Step 2: Define the prompt template\n",
    "prompt_template_file_types = PromptTemplate(\n",
    "    input_variables=[\"content\"],\n",
    "    template=\"\"\"\n",
    "List the top 50 file extensions most commonly found in cybersecurity leaked data, including data from breaches, ransomware leaks, and dark web dumps. THINK LIKE A CYBERSECURITY EXPERT.\n",
    "Focus on file types that typically contain credentials, configurations, databases, personal data, internal documentation, archives, or images (e.g., screenshots of sensitive material). \n",
    "\n",
    "OUTPUT INSTRUCTIONS:\n",
    "ONLY OUTPUT the extensions as a clean Python list format, like [<'file_extension'>, <'file_extension'>, etc.] \n",
    "Don't include \".\" and ALWAYS use \"'\" in the list. \n",
    "Do not include any explanations, comments, or extra text. \n",
    "JUST GIVE THE LIST.\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# Step 3: Run the chain to get extensions\n",
    "chain = LLMChain(llm=llm2, prompt=prompt_template_file_types)\n",
    "llm_response = chain.run(content=\"\")\n",
    "\n",
    "# Step 4: Print the LLM output\n",
    "print(\"üîç LLM-generated file extensions list:\")\n",
    "print(llm_response)\n",
    "\n",
    "# Step 5: Parse LLM response into a Python list\n",
    "try:\n",
    "    # Extract only the list portion using regex\n",
    "    match = re.search(r\"\\[(.*?)\\]\", llm_response, re.DOTALL)\n",
    "    if match:\n",
    "        list_str = \"[\" + match.group(1) + \"]\"\n",
    "        common_extensions = ast.literal_eval(list_str)\n",
    "    else:\n",
    "        raise ValueError(\"‚ùå No list found in LLM response.\")\n",
    "except Exception as e:\n",
    "    raise ValueError(\"‚ùå Failed to parse LLM response into a list.\") from e\n",
    "\n",
    "# Step 6: Build dynamic regex\n",
    "ext_pattern = '|'.join(common_extensions)\n",
    "file_pattern = re.compile(r'[\\w\\-/\\.]{8,}\\.(?:' + ext_pattern + r')', re.IGNORECASE)\n",
    "\n",
    "# Step 7: Define chats path and extract files\n",
    "chats_path = 'I-Soon-data/md/chats'\n",
    "extracted_files_from_chats = {}\n",
    "\n",
    "for filename in os.listdir(chats_path):\n",
    "    if filename.endswith('.md'):\n",
    "        full_path = os.path.join(chats_path, filename)\n",
    "        with open(full_path, 'r', encoding='utf-8') as file:\n",
    "            content = file.read()\n",
    "            matches = file_pattern.findall(content)\n",
    "            if matches:\n",
    "                extracted_files_from_chats[filename] = matches\n",
    "\n",
    "# Step 8: Display results\n",
    "print(\"\\nüìÑ Extracted filenames from chats:\")\n",
    "for chat, files in extracted_files_from_chats.items():\n",
    "    print(f\"{chat}:\")\n",
    "    for f in files:\n",
    "        print(f\"  - {f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5857059",
   "metadata": {},
   "source": [
    "# *Search which files are in the leaked data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a73d6162",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Processing chunk 1/49...\n",
      "LLM Response: 9a8077f5-ac41-491f-b192-6b4609324bda.png, 0-9a8077f5-ac41-491f-b192-6b4609324bda.png\n",
      "\n",
      "üîç Processing chunk 2/49...\n",
      "LLM Response: wxid_7p054rmzkhqf21.gzp1991101.gzp1991101.gzp1991101.gzp1991101.gzp1991101.gzp1991101.gzp1991101.gzp1991101.gzp1991101.gzp1991101\n",
      "\n",
      "üîç Processing chunk 3/49...\n",
      "LLM Response: wxid_7p054rmzkhqf21.gzp1991101,gzp1991101,wxid_7p054rmzkhqf21\n",
      "\n",
      "üîç Processing chunk 4/49...\n",
      "LLM Response: wxid_7p054rmzkhqf21.gzp1991101, gzp1991101.wxp1991101, wxid_7p054rmzkhqf21.wxp1991101, gzp1991101\n",
      "\n",
      "üîç Processing chunk 5/49...\n",
      "LLM Response: wxid_7p054rmzkhqf21.gzp, wxid_7p054rmzkhqf21.gzp, gzp1991101.gzp, gzp1991101.gzp, gzp1991101.gzp, gzp1991101.gzp, gzp1991101.gzp, gzp1991101.gzp, gzp1991101.gzp\n",
      "\n",
      "üîç Processing chunk 6/49...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 45\u001b[39m\n\u001b[32m     43\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33müîç Processing chunk \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(chunks)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m     response = \u001b[43mchain\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     46\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mLLM Response:\u001b[39m\u001b[33m\"\u001b[39m, response)\n\u001b[32m     48\u001b[39m     \u001b[38;5;66;03m# Use regex to extract file names only\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/ISoonAI/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:191\u001b[39m, in \u001b[36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    189\u001b[39m     warned = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    190\u001b[39m     emit_warning()\n\u001b[32m--> \u001b[39m\u001b[32m191\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/ISoonAI/lib/python3.11/site-packages/langchain/chains/base.py:608\u001b[39m, in \u001b[36mChain.run\u001b[39m\u001b[34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[39m\n\u001b[32m    603\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m(args[\u001b[32m0\u001b[39m], callbacks=callbacks, tags=tags, metadata=metadata)[\n\u001b[32m    604\u001b[39m         _output_key\n\u001b[32m    605\u001b[39m     ]\n\u001b[32m    607\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[32m--> \u001b[39m\u001b[32m608\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m[\n\u001b[32m    609\u001b[39m         _output_key\n\u001b[32m    610\u001b[39m     ]\n\u001b[32m    612\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[32m    613\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    614\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m`run` supported with either positional arguments or keyword arguments,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    615\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m but none were provided.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    616\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/ISoonAI/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:191\u001b[39m, in \u001b[36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    189\u001b[39m     warned = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    190\u001b[39m     emit_warning()\n\u001b[32m--> \u001b[39m\u001b[32m191\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/ISoonAI/lib/python3.11/site-packages/langchain/chains/base.py:386\u001b[39m, in \u001b[36mChain.__call__\u001b[39m\u001b[34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[39m\n\u001b[32m    354\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[32m    355\u001b[39m \n\u001b[32m    356\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    377\u001b[39m \u001b[33;03m        `Chain.output_keys`.\u001b[39;00m\n\u001b[32m    378\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    379\u001b[39m config = {\n\u001b[32m    380\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcallbacks\u001b[39m\u001b[33m\"\u001b[39m: callbacks,\n\u001b[32m    381\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtags\u001b[39m\u001b[33m\"\u001b[39m: tags,\n\u001b[32m    382\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: metadata,\n\u001b[32m    383\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mrun_name\u001b[39m\u001b[33m\"\u001b[39m: run_name,\n\u001b[32m    384\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m386\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    388\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRunnableConfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    389\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    390\u001b[39m \u001b[43m    \u001b[49m\u001b[43minclude_run_info\u001b[49m\u001b[43m=\u001b[49m\u001b[43minclude_run_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    391\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/ISoonAI/lib/python3.11/site-packages/langchain/chains/base.py:167\u001b[39m, in \u001b[36mChain.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    166\u001b[39m     run_manager.on_chain_error(e)\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    168\u001b[39m run_manager.on_chain_end(outputs)\n\u001b[32m    170\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/ISoonAI/lib/python3.11/site-packages/langchain/chains/base.py:157\u001b[39m, in \u001b[36mChain.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    155\u001b[39m     \u001b[38;5;28mself\u001b[39m._validate_inputs(inputs)\n\u001b[32m    156\u001b[39m     outputs = (\n\u001b[32m--> \u001b[39m\u001b[32m157\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    158\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[32m    159\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call(inputs)\n\u001b[32m    160\u001b[39m     )\n\u001b[32m    162\u001b[39m     final_outputs: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] = \u001b[38;5;28mself\u001b[39m.prep_outputs(\n\u001b[32m    163\u001b[39m         inputs, outputs, return_only_outputs\n\u001b[32m    164\u001b[39m     )\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/ISoonAI/lib/python3.11/site-packages/langchain/chains/llm.py:127\u001b[39m, in \u001b[36mLLMChain._call\u001b[39m\u001b[34m(self, inputs, run_manager)\u001b[39m\n\u001b[32m    122\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_call\u001b[39m(\n\u001b[32m    123\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    124\u001b[39m     inputs: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[32m    125\u001b[39m     run_manager: Optional[CallbackManagerForChainRun] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    126\u001b[39m ) -> \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m127\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    128\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.create_outputs(response)[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/ISoonAI/lib/python3.11/site-packages/langchain/chains/llm.py:139\u001b[39m, in \u001b[36mLLMChain.generate\u001b[39m\u001b[34m(self, input_list, run_manager)\u001b[39m\n\u001b[32m    137\u001b[39m callbacks = run_manager.get_child() \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.llm, BaseLanguageModel):\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mllm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    140\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    142\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    143\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mllm_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    144\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    146\u001b[39m     results = \u001b[38;5;28mself\u001b[39m.llm.bind(stop=stop, **\u001b[38;5;28mself\u001b[39m.llm_kwargs).batch(\n\u001b[32m    147\u001b[39m         cast(\u001b[38;5;28mlist\u001b[39m, prompts), {\u001b[33m\"\u001b[39m\u001b[33mcallbacks\u001b[39m\u001b[33m\"\u001b[39m: callbacks}\n\u001b[32m    148\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/ISoonAI/lib/python3.11/site-packages/langchain_core/language_models/llms.py:764\u001b[39m, in \u001b[36mBaseLLM.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m    755\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    756\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m    757\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    761\u001b[39m     **kwargs: Any,\n\u001b[32m    762\u001b[39m ) -> LLMResult:\n\u001b[32m    763\u001b[39m     prompt_strings = [p.to_string() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m--> \u001b[39m\u001b[32m764\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_strings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/ISoonAI/lib/python3.11/site-packages/langchain_core/language_models/llms.py:971\u001b[39m, in \u001b[36mBaseLLM.generate\u001b[39m\u001b[34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    956\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m.cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m get_llm_cache() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[32m    957\u001b[39m     run_managers = [\n\u001b[32m    958\u001b[39m         callback_manager.on_llm_start(\n\u001b[32m    959\u001b[39m             \u001b[38;5;28mself\u001b[39m._serialized,\n\u001b[32m   (...)\u001b[39m\u001b[32m    969\u001b[39m         )\n\u001b[32m    970\u001b[39m     ]\n\u001b[32m--> \u001b[39m\u001b[32m971\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    972\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    973\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    974\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    975\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnew_arg_supported\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnew_arg_supported\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    976\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    977\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    978\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(missing_prompts) > \u001b[32m0\u001b[39m:\n\u001b[32m    979\u001b[39m     run_managers = [\n\u001b[32m    980\u001b[39m         callback_managers[idx].on_llm_start(\n\u001b[32m    981\u001b[39m             \u001b[38;5;28mself\u001b[39m._serialized,\n\u001b[32m   (...)\u001b[39m\u001b[32m    988\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m missing_prompt_idxs\n\u001b[32m    989\u001b[39m     ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/ISoonAI/lib/python3.11/site-packages/langchain_core/language_models/llms.py:790\u001b[39m, in \u001b[36mBaseLLM._generate_helper\u001b[39m\u001b[34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[39m\n\u001b[32m    779\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_generate_helper\u001b[39m(\n\u001b[32m    780\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    781\u001b[39m     prompts: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m    786\u001b[39m     **kwargs: Any,\n\u001b[32m    787\u001b[39m ) -> LLMResult:\n\u001b[32m    788\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    789\u001b[39m         output = (\n\u001b[32m--> \u001b[39m\u001b[32m790\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m                \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m                \u001b[49m\u001b[38;5;66;43;03m# TODO: support multiple run managers\u001b[39;49;00m\n\u001b[32m    794\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    797\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[32m    798\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._generate(prompts, stop=stop)\n\u001b[32m    799\u001b[39m         )\n\u001b[32m    800\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    801\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/ISoonAI/lib/python3.11/site-packages/langchain_community/llms/ollama.py:437\u001b[39m, in \u001b[36mOllama._generate\u001b[39m\u001b[34m(self, prompts, stop, images, run_manager, **kwargs)\u001b[39m\n\u001b[32m    435\u001b[39m generations = []\n\u001b[32m    436\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m prompts:\n\u001b[32m--> \u001b[39m\u001b[32m437\u001b[39m     final_chunk = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_stream_with_aggregation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    438\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    439\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    440\u001b[39m \u001b[43m        \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    441\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    442\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    443\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    444\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    445\u001b[39m     generations.append([final_chunk])\n\u001b[32m    446\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m LLMResult(generations=generations)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/ISoonAI/lib/python3.11/site-packages/langchain_community/llms/ollama.py:349\u001b[39m, in \u001b[36m_OllamaCommon._stream_with_aggregation\u001b[39m\u001b[34m(self, prompt, stop, run_manager, verbose, **kwargs)\u001b[39m\n\u001b[32m    340\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_stream_with_aggregation\u001b[39m(\n\u001b[32m    341\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    342\u001b[39m     prompt: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    346\u001b[39m     **kwargs: Any,\n\u001b[32m    347\u001b[39m ) -> GenerationChunk:\n\u001b[32m    348\u001b[39m     final_chunk: Optional[GenerationChunk] = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m349\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create_generate_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m            \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stream_response_to_generation_chunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/ISoonAI/lib/python3.11/site-packages/langchain_community/llms/ollama.py:194\u001b[39m, in \u001b[36m_OllamaCommon._create_generate_stream\u001b[39m\u001b[34m(self, prompt, stop, images, **kwargs)\u001b[39m\n\u001b[32m    186\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_create_generate_stream\u001b[39m(\n\u001b[32m    187\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    188\u001b[39m     prompt: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    191\u001b[39m     **kwargs: Any,\n\u001b[32m    192\u001b[39m ) -> Iterator[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m    193\u001b[39m     payload = {\u001b[33m\"\u001b[39m\u001b[33mprompt\u001b[39m\u001b[33m\"\u001b[39m: prompt, \u001b[33m\"\u001b[39m\u001b[33mimages\u001b[39m\u001b[33m\"\u001b[39m: images}\n\u001b[32m--> \u001b[39m\u001b[32m194\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create_stream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    196\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[43m        \u001b[49m\u001b[43mapi_url\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbase_url\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m/api/generate\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/ISoonAI/lib/python3.11/site-packages/langchain_community/llms/ollama.py:252\u001b[39m, in \u001b[36m_OllamaCommon._create_stream\u001b[39m\u001b[34m(self, api_url, payload, stop, **kwargs)\u001b[39m\n\u001b[32m    246\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    247\u001b[39m     request_payload = {\n\u001b[32m    248\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mprompt\u001b[39m\u001b[33m\"\u001b[39m: payload.get(\u001b[33m\"\u001b[39m\u001b[33mprompt\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    249\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mimages\u001b[39m\u001b[33m\"\u001b[39m: payload.get(\u001b[33m\"\u001b[39m\u001b[33mimages\u001b[39m\u001b[33m\"\u001b[39m, []),\n\u001b[32m    250\u001b[39m         **params,\n\u001b[32m    251\u001b[39m     }\n\u001b[32m--> \u001b[39m\u001b[32m252\u001b[39m response = \u001b[43mrequests\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43mapi_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mContent-Type\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mapplication/json\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m    \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest_payload\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    263\u001b[39m response.encoding = \u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    264\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m response.status_code != \u001b[32m200\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/ISoonAI/lib/python3.11/site-packages/requests/api.py:115\u001b[39m, in \u001b[36mpost\u001b[39m\u001b[34m(url, data, json, **kwargs)\u001b[39m\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(url, data=\u001b[38;5;28;01mNone\u001b[39;00m, json=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m    104\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[32m    105\u001b[39m \n\u001b[32m    106\u001b[39m \u001b[33;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    112\u001b[39m \u001b[33;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[32m    113\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpost\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/ISoonAI/lib/python3.11/site-packages/requests/api.py:59\u001b[39m, in \u001b[36mrequest\u001b[39m\u001b[34m(method, url, **kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m sessions.Session() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/ISoonAI/lib/python3.11/site-packages/requests/sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/ISoonAI/lib/python3.11/site-packages/requests/sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    700\u001b[39m start = preferred_clock()\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[32m    706\u001b[39m elapsed = preferred_clock() - start\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/ISoonAI/lib/python3.11/site-packages/requests/adapters.py:667\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    664\u001b[39m     timeout = TimeoutSauce(connect=timeout, read=timeout)\n\u001b[32m    666\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m667\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    668\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    669\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    671\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    682\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request=request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/ISoonAI/lib/python3.11/site-packages/urllib3/connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    784\u001b[39m response_conn = conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[32m    803\u001b[39m clean_exit = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/ISoonAI/lib/python3.11/site-packages/urllib3/connectionpool.py:534\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    532\u001b[39m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m534\u001b[39m     response = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    536\u001b[39m     \u001b[38;5;28mself\u001b[39m._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/ISoonAI/lib/python3.11/site-packages/urllib3/connection.py:516\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    513\u001b[39m _shutdown = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.sock, \u001b[33m\"\u001b[39m\u001b[33mshutdown\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    515\u001b[39m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m516\u001b[39m httplib_response = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    518\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    519\u001b[39m     assert_header_parsing(httplib_response.msg)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/ISoonAI/lib/python3.11/http/client.py:1395\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1393\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1394\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1395\u001b[39m         \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1396\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[32m   1397\u001b[39m         \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/ISoonAI/lib/python3.11/http/client.py:325\u001b[39m, in \u001b[36mHTTPResponse.begin\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    323\u001b[39m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[32m    324\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m325\u001b[39m     version, status, reason = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    326\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m status != CONTINUE:\n\u001b[32m    327\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/ISoonAI/lib/python3.11/http/client.py:286\u001b[39m, in \u001b[36mHTTPResponse._read_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    285\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m     line = \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m.fp.readline(_MAXLINE + \u001b[32m1\u001b[39m), \u001b[33m\"\u001b[39m\u001b[33miso-8859-1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    287\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) > _MAXLINE:\n\u001b[32m    288\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[33m\"\u001b[39m\u001b[33mstatus line\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/ISoonAI/lib/python3.11/socket.py:718\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    716\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    717\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m718\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    719\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    720\u001b[39m         \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from langchain.llms import Ollama\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Step 1: Load markdown file\n",
    "markdown_file_path = 'I-Soon-data/md/chats/2.md'\n",
    "with open(markdown_file_path, 'r', encoding='utf-8') as file:\n",
    "    md_content = file.read()\n",
    "\n",
    "# Step 2: Split into overlapping chunks\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=200)\n",
    "chunks = splitter.split_text(md_content)\n",
    "\n",
    "# Step 3: Define the prompt\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"content\"],\n",
    "    template=\"\"\"\n",
    "You are a cybersecurity analyst. Think of the top 50 most common file types.\n",
    "Analyze the following markdown content and extract all the file names mentioned. \n",
    "Think based on the structure of the document how could a file be referenced. \n",
    "Look for syntax that indicates a file name (source, reference, \".\" and extension name) or how it can be refenced to another location from the document.\n",
    "ONLY OUTPUT a list of file names with extensions, separated by commas. Do not explain. No additional commentary.\n",
    "\n",
    "Content:\n",
    "{content}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# Step 4: Set up the LLM chain\n",
    "llm = Ollama(model=\"llama3.1:8b\")\n",
    "chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "\n",
    "# Step 5: Collect only valid filenames using regex\n",
    "found_files = []\n",
    "\n",
    "# Basic file name pattern: alphanumerics, dashes, underscores, ending in .ext (2‚Äì6 chars)\n",
    "file_regex = re.compile(r'\\b[\\w\\-]+(?:\\.[\\w\\-]+)*\\.\\w{2,6}\\b')\n",
    "\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"\\nüîç Processing chunk {i+1}/{len(chunks)}...\")\n",
    "    try:\n",
    "        response = chain.run(content=chunk)\n",
    "        print(\"LLM Response:\", response)\n",
    "\n",
    "        # Use regex to extract file names only\n",
    "        matches = file_regex.findall(response)\n",
    "        found_files.extend([m.strip().lower() for m in matches])\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error processing chunk {i+1}: {e}\")\n",
    "\n",
    "# Step 6: Final clean result\n",
    "unique_files = sorted(set(found_files))\n",
    "\n",
    "print(\"\\nüéØ Unique filenames found across all chunks:\")\n",
    "for f in unique_files:\n",
    "    print(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ISoonAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
